{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# used to load text\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "# used to create the retriever\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "# used to create the retrieval tool\n",
        "from langchain.agents import tool\n",
        "\n",
        "# used to create the memory\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# used to create the prompt template\n",
        "from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\n",
        "from langchain.schema import SystemMessage\n",
        "from langchain.prompts import MessagesPlaceholder\n",
        "\n",
        "# used to create the agent executor\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import AgentExecutor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "openai.api_key = #insert api key here\n",
        "\n",
        "\n",
        "# This is needed for both the memory and the prompt\n",
        "openai.api_key =  memory_key = \"history\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Created a chunk of size 2731, which is longer than the specified 1000\n",
            "Created a chunk of size 1538, which is longer than the specified 1000\n",
            "Created a chunk of size 1380, which is longer than the specified 1000\n",
            "Created a chunk of size 2352, which is longer than the specified 1000\n",
            "Created a chunk of size 1953, which is longer than the specified 1000\n",
            "Created a chunk of size 1067, which is longer than the specified 1000\n",
            "Created a chunk of size 1475, which is longer than the specified 1000\n",
            "Created a chunk of size 2881, which is longer than the specified 1000\n",
            "Created a chunk of size 1980, which is longer than the specified 1000\n",
            "Created a chunk of size 4145, which is longer than the specified 1000\n",
            "Created a chunk of size 2528, which is longer than the specified 1000\n"
          ]
        }
      ],
      "source": [
        "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
        "data = loader.load()\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=Insert API Key)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Retriever Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "db = FAISS.from_documents(texts, embeddings)\n",
        "retriever = db.as_retriever()\n",
        "@tool\n",
        "def tool(query):\n",
        "    \"Searches and returns documents regarding the llm powered autonomous agents blog\"\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "    return docs\n",
        "\n",
        "tools = [tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory(memory_key=memory_key, return_messages=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Prompt Template\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message = SystemMessage(\n",
        "        content=(\n",
        "            \"Do your best to answer the questions. \"\n",
        "            \"Feel free to use any tools available to look up \"\n",
        "            \"relevant information, only if neccessary\"\n",
        "        )\n",
        ")\n",
        "prompt = OpenAIFunctionsAgent.create_prompt(\n",
        "        system_message=system_message,\n",
        "        extra_prompt_messages=[MessagesPlaceholder(variable_name=memory_key)]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#llm = ChatOpenAI(temperature = 0, openai_api_key=openai_api_key)\n",
        "llm = ChatOpenAI(temperature = 0, openai_api_key=API Key here)\n",
        "agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agent Executer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
