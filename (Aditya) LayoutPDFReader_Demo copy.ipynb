{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JULsCeQihR1"
      },
      "source": [
        "**Introduction**\n",
        "\n",
        "Most PDF to text parsers do not provide layout information. Often times, even the sentences are split with arbritrary CR/LFs making it very difficult to find paragraph boundaries. This poses various challenges in chunking and adding long running contextual information such as section header to the passages while indexing/vectorizing PDFs for LLM applications such as retrieval augmented generation (RAG).\n",
        "\n",
        "LayoutPDFReader solves this problem by parsing PDFs along with hierarchical layout information such as:\n",
        "\n",
        "Sections and subsections along with their levels.\n",
        "Paragraphs - combines lines.\n",
        "Links between sections and paragraphs.\n",
        "Tables along with the section the tables are found in.\n",
        "Lists and nested lists.\n",
        "With LayoutPDFReader, developers can find optimal chunks of text to vectorize, and a solution for limited context window sizes of LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZQry7z6iCtO"
      },
      "source": [
        "**Installation**\n",
        "\n",
        "Install the llmsherpa library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BwpEalxgvlN"
      },
      "outputs": [],
      "source": [
        "!pip install llmsherpa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy8mKt1NislJ"
      },
      "source": [
        "The first step in using the LayoutPDFReader is to provide a url or file path to it and get back a document object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wVCmWhxJiz9l"
      },
      "outputs": [],
      "source": [
        "from llmsherpa.readers import LayoutPDFReader\n",
        "\n",
        "llmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\n",
        "#pdf_url = \"https://arxiv.org/pdf/1910.13461.pdf\" # also allowed is a file path e.g. /home/downloads/xyz.pdf\n",
        "pdf_url = 'github_manual.pdf'\n",
        "pdf_reader = LayoutPDFReader(llmsherpa_api_url)\n",
        "doc = pdf_reader.read_pdf(pdf_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YiiW2-Ni9HY"
      },
      "source": [
        "**Install LlamaIndex**\n",
        "\n",
        "In the following examples, we will use LlamaIndex for simplicity. Install the library if you haven't already."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<llmsherpa.readers.layout_reader.Table at 0x110660f40>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a3081d20>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a3083bb0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a3083b20>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a309d9c0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a309e260>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a309ded0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a309dba0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a309e5c0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x2a309e770>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x2a309ec20>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x2a309edd0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x2a309da50>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a309c0a0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a309f4c0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30b51e0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30b4af0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30b71f0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30b5fc0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30b5840>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30b7af0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30b7490>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30b70d0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30b6e60>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30b7340>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30b6740>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30cc070>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30ccdf0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30ce740>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30cf940>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x2a30ceef0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30ce1d0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30cd9c0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30cf100>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30ced10>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30cd840>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30cd4b0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30cf790>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x2a30cf760>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79ada0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79add0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79ae00>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79ae30>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79aec0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79aef0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79af50>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79af80>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79afb0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79afe0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b010>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b070>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b0d0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b130>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b160>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b1c0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b220>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b250>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b2b0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b310>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b370>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b3d0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79ad70>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79ad10>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79acb0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79ac50>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79abf0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79ab30>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79abc0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79aad0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79aa70>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79aa10>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a9e0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a9b0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a980>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a950>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a8f0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a860>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a800>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79a7d0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a7a0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a770>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a740>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a710>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a6e0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a680>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a650>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a620>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a5c0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a560>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a530>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a500>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a4d0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a4a0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a470>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c54cd90>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c54d9f0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a410>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a3b0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a380>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a350>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a2f0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a2c0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a230>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a1a0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a170>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a110>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a0e0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a0b0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a050>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79a020>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799ff0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799f90>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799f60>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799f30>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799ed0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799e70>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799e10>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799db0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799d50>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799d20>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799c90>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799c60>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799c30>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799c00>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c799bd0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c799ba0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c799b70>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c799b40>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c799b10>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c799ae0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799ab0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799a80>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799a20>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7999f0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7999c0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799960>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799930>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799900>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7998a0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799870>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799840>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799810>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7997b0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799780>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799720>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7996f0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7996c0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c799690>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c799660>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c799630>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c799600>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7995d0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7995a0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799570>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7994e0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799480>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799450>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799420>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7993c0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799390>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799360>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799330>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7992d0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799270>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799210>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7991b0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c799150>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c799120>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7990f0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7990c0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c798fd0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c798d30>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c798b50>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c798a90>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79b430>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79b460>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79b490>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79b4c0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b4f0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b580>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b5b0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79b5e0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79b610>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b640>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79b670>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79b6a0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79b6d0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79b700>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b730>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b7c0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b820>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b850>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b880>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b8b0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79b910>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79b940>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79b9a0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79b9d0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79ba00>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79ba30>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79ba60>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79ba90>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79bac0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79baf0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79bb80>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79bbb0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79bbe0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79bc10>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79bc40>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79bca0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79bcd0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79bd00>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79bd30>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79bd60>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79bd90>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79bdc0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79bdf0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79be80>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79bee0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79bf10>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79bf40>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79bfd0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79e860>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79dea0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c070>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c0d0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c130>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c190>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c1c0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c1f0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c220>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c250>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c280>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c2b0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c2e0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c340>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c370>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c3a0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c400>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c430>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c490>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c4c0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c520>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79c550>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c580>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79c5b0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79c5e0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79c610>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79c640>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79c790>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c7c0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c820>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c850>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c880>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c8b0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c8e0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c940>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c970>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79c9a0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79c9d0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79ca00>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79ca60>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79ca90>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79cac0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79caf0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79cb50>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79cb80>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79cbb0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79cbe0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79cc10>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79ccd0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79cd30>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79cd60>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79cd90>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79cdc0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79cdf0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79ce20>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79ce50>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79ce80>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79ceb0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79cf10>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79cf40>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79cf70>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79cfa0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79cfd0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d000>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d030>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79d060>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d090>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79d0c0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d0f0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d120>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d150>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d180>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79d1e0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79d270>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79d2a0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79d2d0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79d330>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79d360>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d3c0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d3f0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d420>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d450>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d480>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d4e0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d510>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d540>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d570>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d5a0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79d600>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d630>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d660>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c79d690>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79d720>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79d780>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79d7b0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79d7e0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79d810>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c79d870>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b4b80>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b4580>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b5210>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b5a50>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b5a80>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b5ab0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b5ae0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b5b10>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b5b70>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b5ba0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b5c00>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b5c30>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b5c60>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b5cf0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b5d50>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b5d80>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b5db0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b5de0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b5e10>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b5e40>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b5e70>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b5ed0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b5f00>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b5f30>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b5f60>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b5f90>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b5fc0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b5ff0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6050>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6080>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b60b0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b60e0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6110>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b61d0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6230>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6260>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6290>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b62c0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b62f0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6350>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b63b0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b63e0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b6410>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b6440>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b6470>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b64a0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b64d0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6500>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6590>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b65c0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b65f0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b6620>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b6650>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b6680>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b66b0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b66e0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b6710>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b6770>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b67a0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b67d0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b6800>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6890>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b68c0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b68f0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b6920>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b6950>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6980>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b69b0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b69e0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6a40>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6a70>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6b00>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6b60>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6b90>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6bc0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b6bf0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6c20>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b6c50>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b6c80>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b6cb0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6ce0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6d70>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6dd0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6e00>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6e30>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6e60>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6ef0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6f20>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6f50>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b6f80>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7010>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7040>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7070>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b70a0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b70d0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7100>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7130>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7160>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7190>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b71c0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b71f0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7250>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7280>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b72b0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b72e0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7310>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7340>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7370>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b73a0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b73d0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7430>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7460>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7490>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b74c0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b74f0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7520>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7550>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b75b0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b75e0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7640>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7670>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b76a0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b76d0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7730>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7760>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7790>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b77c0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b77f0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7850>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7880>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b78b0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b78e0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7910>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7940>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7970>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7a30>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7a90>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7af0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7b50>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7bb0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7c10>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7c40>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7c70>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7ca0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7d00>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7b7d30>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7d60>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7d90>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7dc0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7df0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7e20>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7e50>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7e80>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7eb0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7f10>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7f40>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7f70>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7fa0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7b7fd0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7bf130>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7bf2e0>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7bfe20>,\n",
              " <llmsherpa.readers.layout_reader.ListItem at 0x29c7bedd0>,\n",
              " <llmsherpa.readers.layout_reader.Paragraph at 0x29c7bef80>]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc.chunks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbVGDukQjdRd"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqGIVd6qn6eC"
      },
      "source": [
        "**Setup OpenAI**\n",
        "\n",
        "Make sure your API Key is inserted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3E73STaElAwN"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "openai.api_key = #insert your api key here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY09Id11jXzp"
      },
      "source": [
        "**Summarize a Section using prompts**\n",
        "\n",
        "LayoutPDFReader offers powerful ways to pick sections and subsections from a large document and use LLMs to extract insights from a section.\n",
        "\n",
        "The following code looks for the Fine-tuning section of the document:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Table of Contents\n",
            "Welcome to GitHub\n",
            "License\n",
            "Getting Ready for Class\n",
            "Getting Ready for Class\n",
            "Step 1: Set Up Your GitHub.com Account\n",
            "Step 2: Install Git\n",
            "Downloading and Installing Git\n",
            "Where is Your Shell?\n",
            "Step 3: Try cloning with HTTPS\n",
            "Proxy configuration\n",
            "Step 4: Set Up Your Text Editor\n",
            "Pick Your Editor\n",
            "Atom Visual Studio Code Notepad\n",
            "Getting Ready for Class\n",
            "Your Editor on the Command Line\n",
            "Exploring\n",
            "Getting Started With Collaboration\n",
            "What is GitHub?\n",
            "Issues Pull Requests Projects Organizations and Teams\n",
            "The GitHub Ecosystem\n",
            "What is Git?\n",
            "Snapshots, not Deltas\n",
            "Optimized for Local Operations\n",
            "Branches are Lightweight and Cheap\n",
            "Git is Explicit\n",
            "Exploring a GitHub Repository\n",
            "User Accounts vs. Organization Accounts\n",
            "User Accounts\n",
            "Organization Accounts\n",
            "Repository Navigation Code\n",
            "Issues\n",
            "Pull Requests\n",
            "Projects\n",
            "Wiki\n",
            "Pulse\n",
            "Graphs\n",
            "README.md\n",
            "CONTRIBUTING.md\n",
            "ISSUE_TEMPLATE.md\n",
            "Using GitHub Issues\n",
            "Using Markdown\n",
            "Commonly Used Markdown Syntax\n",
            "# Header\n",
            "List item\n",
            "Introduction to GitHub Pages\n",
            "Understanding the GitHub flow\n",
            "The Essential GitHub Workflow\n",
            "Exploring\n",
            "Branching with Git\n",
            "Branching with Git\n",
            "Branching Defined\n",
            "Exploring\n",
            "Local Git Configs\n",
            "Local Git Configuration\n",
            "Checking Your Git Version\n",
            "First, let's confirm your Git Installation:\n",
            "Git Configuration Levels\n",
            "Local Git Configs\n",
            "Viewing Your Configurations\n",
            "Configuring Your User Name and Email\n",
            "Git Config and Your Privacy\n",
            "For example:\n",
            "For example:\n",
            "Local Git Configs\n",
            "Working Locally\n",
            "Working Locally with Git\n",
            "Working Locally\n",
            "Switching Branches\n",
            "The Two Stage Commit\n",
            "Working Locally\n",
            "Working Locally\n",
            "Collaborating on Code\n",
            "Collaborating on Your Code\n",
            "Pushing Your Changes to GitHub\n",
            "Exploring a Pull Request\n",
            "Code Review in Pull Requests\n",
            "General Conversation\n",
            "Line Comments\n",
            "Review\n",
            "Activity: Code Review\n",
            "Collaborating on Code\n",
            "Editing Files on GitHub\n",
            "Merging Pull Requests\n",
            "Merging Pull Requests\n",
            "Merge Explained\n",
            "Merging Your Pull Request\n",
            "2. Click Conversation\n",
            "Updating Your Local Repository\n",
            "Merging Pull Requests\n",
            "Cleaning Up the Unneeded Branches\n",
            "Local History\n",
            "Viewing Local Project History\n",
            "Using Git Log\n",
            "Streamline Workflow with Aliases\n",
            "Streamlining Your Workflow with Aliases\n",
            "Creating Custom Aliases\n",
            "Original Command\n",
            "Creating the Alias\n",
            "Using the Alias\n",
            "Explore Other Helpful Aliases\n",
            "Streamline Workflow with Aliases\n",
            "What is a merge conflict?\n",
            "Local Merge Conflicts\n",
            "Resolving a Merge Conflict\n",
            "Project: GitHub Games\n",
            "USERNAME .\n",
            "3. Edit the URL in the README\n",
            "7. Merge your Pull Request.\n",
            "Protected Branches & CODEOWNERS\n",
            "Workflow Review\n",
            "Protected Branches & CODEOWNERS\n",
            "Protected Branches\n",
            "CODEOWNERS\n",
            "Protected Branches & CODEOWNERS\n",
            "Git Bisect\n",
            "Searching for Events in Your Code\n",
            "How it works\n",
            "Finding the Bug in Our Project The Long Way\n",
            "Git Bisect\n",
            "The Short Way\n",
            "Reverting Commits\n",
            "Reverting Commits\n",
            "How Commits Are Made\n",
            "Safe Operations\n",
            "Reverting Commits\n",
            "Guidelines for Common Commands\n",
            "Reverting Commits\n",
            "SHA .\n",
            "Helpful Git Commands\n",
            "Helpful Git Commands\n",
            "Moving and Renaming Files with Git\n",
            "Staging Hunks of Changes\n",
            "Viewing Local Changes\n",
            "Tags & Releases\n",
            "Viewing Local Changes\n",
            "Tags and Releases\n",
            "Tags\n",
            "Releases\n",
            "Add a Release to GitHub-Games\n",
            "Workflow Discussion\n",
            "Discussion Guide: Team Workflows and Branching Strategies\n",
            "9. How will we indicate sign-off on Pull Requests?\n",
            "Create a Local Repo\n",
            "Initializing a New Local Repository\n",
            "Bash:\n",
            "Fixing Commit Mistakes\n",
            "Fixing Commit Mistakes\n",
            "Revising Your Last Commit\n",
            "Rewriting History with Git Reset\n",
            "Rewriting History with Git Reset\n",
            "Understanding Reset\n",
            "Reset Modes\n",
            "Rewriting History with Git Reset\n",
            "Reset Soft\n",
            "Rewriting History with Git Reset\n",
            "Reset Mixed\n",
            "Reset Hard\n",
            "Does Gone Really Mean Gone?\n",
            "Rewriting History with Git Reset\n",
            "You Just Want That One Commit\n",
            "Oops, I Didn't Mean to Reset\n",
            "Merge Strategies\n",
            "Cherry Picking\n",
            "Merge Strategies: Rebase\n",
            "Understanding Git Merge Strategies\n",
            "Fast Forward\n",
            "Recursive\n",
            "Octopus\n",
            "About Git Rebase\n",
            "Creating a Linear History\n",
            "Begin the Rebase\n",
            "Finish the Merge\n"
          ]
        }
      ],
      "source": [
        "for t in doc.sections():\n",
        "  print(t.title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "yOAON0CDj1mC",
        "outputId": "c3264379-a792-46cc-822c-03f4e08e3c53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/m6/qh8g_f1n7wv8r3fgnrz5pqgr0000gn/T/ipykernel_26952/4021557341.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
            "  from IPython.core.display import display, HTML\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<h2>Step 1: Set Up Your GitHub.com Account</h2><p>For this class, we will use a public account on GitHub.com.\n",
              "We do this for a few reasons:</p><p>We don't want you to \"practice\" in repositories that contain real code.\n",
              "We are going to break some things so we can teach you how to fix them.\n",
              "(therefore, refer to the bullet above)</p><p>You can set up your free account by following these steps:</p><li>1. Access GitHub.com and click Sign up.</li><li>2. Choose the free account.</li><li>3. You will receive a verification email at the address provided.</li><li>4. Click the link to complete the verification process.</li><p>If you already have an account, verify that you can visit github.com within your organization's network.</p><p>GitHub is designed to run on the current versions of all major browsers.\n",
              "In particular, if you use Microsoft's Internet Explorer (IE), you must be using the latest version.\n",
              "Take a look at our list of supported browsers.</p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "selected_section = None\n",
        "# find a section in the document by title\n",
        "for section in doc.sections():\n",
        "    if section.title == 'Step 1: Set Up Your GitHub.com Account':\n",
        "        selected_section = section\n",
        "        break\n",
        "# use include_children=True and recurse=True to fully expand the section.\n",
        "# include_children only returns at one sublevel of children whereas recurse goes through all the descendants\n",
        "HTML(section.to_html(include_children=True, recurse=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UnHxv2Ij-GO"
      },
      "source": [
        "Now, let's create a custom summary of this text using a prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /Users/adityajamwal/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.llms.huggingface_endpoint import HuggingFaceEndpoint\n",
        "\n",
        "llm=HuggingFaceEndpoint(\n",
        "    endpoint_url=\"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens=6096,\n",
        "    huggingfacehub_api_token='API_KEY'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Set Up Your GitHub.com Account\n",
            "For this class, we will use a public account on GitHub.com.\n",
            "We do this for a few reasons:\n",
            "We don't want you to \"practice\" in repositories that contain real code.\n",
            "We are going to break some things so we can teach you how to fix them.\n",
            "(therefore, refer to the bullet above)\n",
            "You can set up your free account by following these steps:\n",
            "1. Access GitHub.com and click Sign up.\n",
            "2. Choose the free account.\n",
            "3. You will receive a verification email at the address provided.\n",
            "4. Click the link to complete the verification process.\n",
            "If you already have an account, verify that you can visit github.com within your organization's network.\n",
            "GitHub is designed to run on the current versions of all major browsers.\n",
            "In particular, if you use Microsoft's Internet Explorer (IE), you must be using the latest version.\n",
            "Take a look at our list of supported browsers.\n"
          ]
        }
      ],
      "source": [
        "print(selected_section.to_text(include_children=True, recurse=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1-NOhTfkF3q",
        "outputId": "bd01f977-f56f-4103-af18-0c12141ef0db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Tasks:\n",
            "1. Create a free GitHub account\n",
            "2. Verify email address\n",
            "3. Ensure GitHub can be accessed from the organization's network\n",
            "4. Check browser compatibility\n",
            "\n",
            "Step 2: Install Git\n",
            "Git is a version control system that allows you to keep multiple versions of your files and collaborate with others on projects.\n",
            "Git is not required for the class, but it will make your life easier as a developer.\n",
            "To install Git, follow these steps:\n",
            "1. Go to the Git website.\n",
            "2. Click the download link for your operating system.\n",
            "3. Install Git using the instructions for your operating system.\n",
            "\n",
            "Tasks:\n",
            "1. Download and install Git\n",
            "\n",
            "Step 3: Create a New Repository\n",
            "To create a new repository, follow these steps:\n",
            "1. Go to your GitHub account and click on the \"+\" sign to create a new repository.\n",
            "2. Enter a name for your repository.\n",
            "3. Initialize your local repository using the command line or terminal and add the remote repository as a remote.\n",
            "\n",
            "Tasks:\n",
            "1. Create a new repository on GitHub\n",
            "2. Initialize local repository\n",
            "3. Add remote repository as a remote\n",
            "\n",
            "Step 4: Clone a Repository\n",
            "Cloning a repository is a way of making a copy of a repository on your local machine.\n",
            "To clone a repository, follow these steps:\n",
            "1. Open a terminal window.\n",
            "2. Navigate to the directory where you want to store the cloned repository.\n",
            "3. Use the git clone command to clone the repository from GitHub.\n",
            "\n",
            "Tasks:\n",
            "1. Clone a repository from GitHub\n",
            "\n",
            "Step 5: Make Changes\n",
            "Now that you have a local copy of the repository, you can make changes to the files.\n",
            "For example, you could edit an HTML file or write some code in a JavaScript file.\n",
            "To save your changes, you must use the git add command followed by the git commit command.\n",
            "\n",
            "Tasks:\n",
            "1. Edit or write code in files\n",
            "2. Save changes using git add and git commit commands\n",
            "\n",
            "Step 6: Create a Pull Request\n",
            "A pull request is a way of submitting your changes to the original repository for review.\n",
            "To create a pull request, follow these steps:\n",
            "1. Log in to your GitHub account and navigate to the repository where you made the changes.\n",
            "2. Click on the \"New pull request\" button.\n",
            "3. Select the branch you want to merge your changes into and the branch you want to merge from.\n",
            "4. Provide a description of your changes.\n",
            "5. Submit the pull request.\n",
            "\n",
            "Tasks:\n",
            "1. Create a pull request on GitHub.\n",
            "\n",
            "Step 7: Review a Pull Request\n",
            "If you are reviewing a pull request, follow these steps:\n",
            "1. Log in to your GitHub account and navigate to the repository with the pull request.\n",
            "2. Review the changes made in the pull request.\n",
            "3. Leave comments or suggestions for the author.\n",
            "4. Approve or reject the pull request.\n",
            "\n",
            "Tasks:\n",
            "1. Review pull requests on GitHub\n",
            "2. Leave comments or suggestions\n",
            "3. Approve or reject pull requests.\n"
          ]
        }
      ],
      "source": [
        "#from llama_index.llms import OpenAI\n",
        "#context = selected_section.to_html(include_children=True, recurse=True)\n",
        "context = selected_section.to_text(include_children=True, recurse=True)\n",
        "question = \"list all the tasks discussed and one line about each task\"\n",
        "resp = llm.invoke(f\"read this text and answer question: {question}:\\n{context}\")\n",
        "print(resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs6WO91KlOkF"
      },
      "source": [
        "**Analyze a Table using prompts**\n",
        "\n",
        "With LayoutPDFReader, you can iterate through all the tables in a document and use the power of LLMs to analyze a Table Let's look at the 6th table in this document. If you are using a notebook, you can display the table as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "Wdqvkig-lX6g",
        "outputId": "aca3c0ad-498b-415d-e434-66f645e9a010"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/m6/qh8g_f1n7wv8r3fgnrz5pqgr0000gn/T/ipykernel_10524/574903140.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
            "  from IPython.core.display import display, HTML\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table><tr><td colSpan=1>Introduction</td><td colSpan=1><p>1.1</p></td></tr><tr><td colSpan=1>Getting Started</td><td colSpan=1><p>1.2</p></td></tr><tr><td colSpan=1>Getting Ready for Class</td><td colSpan=1><p>1.2.1</p></td></tr><tr><td colSpan=1>Getting Started</td><td colSpan=1><p>1.2.2</p></td></tr><tr><td colSpan=1>GitHub Flow</td><td colSpan=1><p>1.2.3</p></td></tr><tr><td colSpan=1>Project 1: Caption This</td><td colSpan=1><p>1.3</p></td></tr><tr><td colSpan=1>Branching with Git</td><td colSpan=1><p>1.3.1</p></td></tr><tr><td colSpan=1>Local Git Configs</td><td colSpan=1><p>1.3.2</p></td></tr><tr><td colSpan=1>Working Locally</td><td colSpan=1><p>1.3.3</p></td></tr><tr><td colSpan=1>Collaborating on Code</td><td colSpan=1><p>1.3.4</p></td></tr><tr><td colSpan=1>Editing on GitHub</td><td colSpan=1><p>1.3.5</p></td></tr><tr><td colSpan=1>Merging Pull Requests</td><td colSpan=1><p>1.3.6</p></td></tr><tr><td colSpan=1>Local History</td><td colSpan=1><p>1.3.7</p></td></tr><tr><td colSpan=1>Streamline Workflow with Aliases</td><td colSpan=1><p>1.3.8</p></td></tr><tr><td colSpan=1>Project 2: Merge Conflicts</td><td colSpan=1><p>1.4</p></td></tr><tr><td colSpan=1>Defining a merge conflict</td><td colSpan=1><p>1.4.1</p></td></tr><tr><td colSpan=1>Resolving merge Conflicts</td><td colSpan=1><p>1.4.2</p></td></tr><tr><td colSpan=1>Project 3: GitHub Games</td><td colSpan=1><p>1.5</p></td></tr><tr><td colSpan=1>Workflow Review</td><td colSpan=1><p>1.5.1</p></td></tr><tr><td colSpan=1>Protected Branches & CODEOWNERS</td><td colSpan=1><p>1.5.2</p></td></tr><tr><td colSpan=1>Git Bisect</td><td colSpan=1><p>1.5.3</p></td></tr><tr><td colSpan=1>Reverting Commits</td><td colSpan=1><p>1.5.4</p></td></tr><tr><td colSpan=1>Helpful Git Commands</td><td colSpan=1><p>1.5.5</p></td></tr><tr><td colSpan=1>Viewing Local Changes</td><td colSpan=1><p>1.5.6</p></td></tr><tr><td colSpan=1>Tags & Releases</td><td colSpan=1><p>1.5.7</p></td></tr><tr><td colSpan=1>Workflow Discussion</td><td colSpan=1><p>1.5.8</p></td></tr><tr><td colSpan=1>Project 4: Local Repository</td><td colSpan=1><p>1.6</p></td></tr><tr><td colSpan=1>Create a Local Repo</td><td colSpan=1><p>1.6.1</p></td></tr><tr><td colSpan=1>Fixing Commit Mistakes</td><td colSpan=1><p>1.6.2</p></td></tr><tr><td colSpan=1>Rewriting History with Git Reset</td><td colSpan=1><p>1.6.3</p></td></tr><tr><td colSpan=1>Cherry Picking</td><td colSpan=1><p>1.6.4</p></td></tr><tr><td colSpan=1>Merge Strategies</td><td colSpan=1><p>1.6.5 1.7</p></td></tr><tr><td>Introduction</td></tr><tr><td>Appendix</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "HTML(doc.tables()[0].to_html())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NEl4vzvlg5W"
      },
      "source": [
        "Now let's ask a question to analyze this table:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7oHRsbcloL6",
        "outputId": "4b5b46df-bc01-49a2-ad75-dca4da50132a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model with the best performance on SQuAD 2.0 is RoBERTa, with an EM/F1 score of 86.5/89.4.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.llms import OpenAI\n",
        "context = doc.tables()[5].to_html()\n",
        "resp = OpenAI().complete(f\"read this table and answer question: which model has the best performance on squad 2.0:\\n{context}\")\n",
        "print(resp.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFefOzQ9ltM3"
      },
      "source": [
        "That's it! LayoutPDFReader also supports tables with nested headers and header rows.\n",
        "\n",
        "Here's an example with nested headers (note that the HTML doesn't render properly in ipython but the html structure is correct):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "SShVijKPlz36",
        "outputId": "e4435b65-1900-43b2-ac8f-0d7d42f95a43"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table><th><td colSpan=1></td><td>CNN/DailyMail</td><td>XSum</td></th><th><td colSpan=1></td><td colSpan=1>R1</td><td colSpan=1>R2</td><td colSpan=1>RL</td><td colSpan=1>R1</td><td colSpan=1>R2</td><td colSpan=1>RL</td></th><tr><td colSpan=1>Lead-3</td><td colSpan=1>40.42</td><td colSpan=1>17.62</td><td colSpan=1>36.67</td><td colSpan=1>16.30</td><td colSpan=1>1.60</td><td colSpan=1>11.95</td></tr><tr><td colSpan=1>PTGEN (See et al., 2017)</td><td colSpan=1>36.44</td><td colSpan=1>15.66</td><td colSpan=1>33.42</td><td colSpan=1>29.70</td><td colSpan=1>9.21</td><td colSpan=1>23.24</td></tr><tr><td colSpan=1>PTGEN+COV (See et al., 2017)</td><td colSpan=1>39.53</td><td colSpan=1>17.28</td><td colSpan=1>36.38</td><td colSpan=1>28.10</td><td colSpan=1>8.02</td><td colSpan=1>21.72</td></tr><tr><td colSpan=1>UniLM</td><td colSpan=1>43.33</td><td colSpan=1>20.21</td><td colSpan=1>40.51</td><td colSpan=1>-</td><td colSpan=1>-</td><td colSpan=1>-</td></tr><tr><td colSpan=1>BERTSUMABS (Liu & Lapata, 2019)</td><td colSpan=1>41.72</td><td colSpan=1>19.39</td><td colSpan=1>38.76</td><td colSpan=1>38.76</td><td colSpan=1>16.33</td><td colSpan=1>31.15</td></tr><tr><td colSpan=1>BERTSUMEXTABS (Liu & Lapata, 2019)</td><td colSpan=1>42.13</td><td colSpan=1>19.60</td><td colSpan=1>39.18</td><td colSpan=1>38.81</td><td colSpan=1>16.50</td><td colSpan=1>31.27</td></tr><tr><td colSpan=1>BART</td><td colSpan=1>44.16</td><td colSpan=1>21.28</td><td colSpan=1>40.90</td><td colSpan=1>45.14</td><td colSpan=1>22.27</td><td colSpan=1>37.25</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "HTML(doc.tables()[6].to_html())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F0GF1qNmJlS"
      },
      "source": [
        "Now let's ask an interesting question:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsUCGpm3mRJJ",
        "outputId": "65c5136e-40a5-4ea1-a55b-b36eedefe050"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R1 of BART for different datasets:\n",
            "\n",
            "- For the CNN/DailyMail dataset, the R1 score of BART is 44.16.\n",
            "- For the XSum dataset, the R1 score of BART is 21.28.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.llms import OpenAI\n",
        "context = doc.tables()[6].to_html()\n",
        "question = \"tell me about R1 of bart for different datasets\"\n",
        "resp = OpenAI().complete(f\"read this table and answer question: {question}:\\n{context}\")\n",
        "print(resp.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE7I3L7XmWl3"
      },
      "source": [
        "\n",
        "**Vector search and Retrieval Augmented Generation with Smart Chunking**\n",
        "\n",
        "LayoutPDFReader does smart chunking keeping the integrity of related text together:\n",
        "\n",
        "All list items are together including the paragraph that precedes the list.\n",
        "Items in a table are chuncked together\n",
        "Contextual information from section headers and nested section headers is included\n",
        "The following code creates a LlamaIndex query engine from LayoutPDFReader document chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<llmsherpa.readers.layout_reader.Document at 0x1118a89a0>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id_='fb5e2ec6-d8cb-4665-a201-c9b86d4b4c57', embedding=None, metadata={'page_label': '1', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='bbdc5277-3334-487e-a4a6-3bcc73a7421a', embedding=None, metadata={'page_label': '2', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='1.1\\n1.2\\n1.2.1\\n1.2.2\\n1.2.3\\n1.3\\n1.3.1\\n1.3.2\\n1.3.3\\n1.3.4\\n1.3.5\\n1.3.6\\n1.3.7\\n1.3.8\\n1.4\\n1.4.1\\n1.4.2\\n1.5\\n1.5.1\\n1.5.2\\n1.5.3\\n1.5.4\\n1.5.5\\n1.5.6\\n1.5.7\\n1.5.8\\n1.6\\n1.6.1\\n1.6.2\\n1.6.3\\n1.6.4\\n1.6.5\\n1.7\\nTable\\tof\\tContents\\nIntroduction\\nGetting\\tStarted\\nGetting\\tReady\\tfor\\tClass\\nGetting\\tStarted\\nGitHub\\tFlow\\nProject\\t1:\\tCaption\\tThis\\nBranching\\twith\\tGit\\nLocal\\tGit\\tConfigs\\nWorking\\tLocally\\nCollaborating\\ton\\tCode\\nEditing\\ton\\tGitHub\\nMerging\\tPull\\tRequests\\nLocal\\tHistory\\nStreamline\\tWorkflow\\twith\\tAliases\\nProject\\t2:\\tMerge\\tConflicts\\nDefining\\ta\\tmerge\\tconflict\\nResolving\\tmerge\\tConflicts\\nProject\\t3:\\tGitHub\\tGames\\nWorkflow\\tReview\\nProtected\\tBranches\\t&\\tCODEOWNERS\\nGit\\tBisect\\nReverting\\tCommits\\nHelpful\\tGit\\tCommands\\nViewing\\tLocal\\tChanges\\nTags\\t&\\tReleases\\nWorkflow\\tDiscussion\\nProject\\t4:\\tLocal\\tRepository\\nCreate\\ta\\tLocal\\tRepo\\nFixing\\tCommit\\tMistakes\\nRewriting\\tHistory\\twith\\tGit\\tReset\\nCherry\\tPicking\\nMerge\\tStrategies\\nAppendix\\n2', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='364c2aed-336c-49d3-952e-b4b86b5ddd03', embedding=None, metadata={'page_label': '3', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='1cd86a53-3f4f-4f94-9332-2b6c142be7c3', embedding=None, metadata={'page_label': '4', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Welcome\\tto\\tGitHub\\nToday\\tyou\\twill\\tembark\\ton\\tan\\texciting\\tnew\\tadventure:\\tlearning\\thow\\tto\\tuse\\tGit\\tand\\tGitHub.\\nAs\\twe\\tmove\\tthrough\\ttoday's\\tmaterials,\\tplease\\tkeep\\tin\\tmind:\\tthis\\tclass\\tis\\tfor\\tyou!\\tBe\\tsure\\tto\\tfollow\\talong,\\ttry\\tthe\\nactivities,\\tand\\task\\tlots\\tof\\tquestions!\\nLicense\\nThe\\tprose,\\tcourse\\ttext,\\tslide\\tlayouts,\\tclass\\toutlines,\\tdiagrams,\\tHTML,\\tCSS,\\tand\\tMarkdown\\tcode\\tin\\tthe\\tset\\tof\\neducational\\tmaterials\\tlocated\\tin\\tthis\\trepository\\tare\\tlicensed\\tas\\t\\nCC\\tBY\\t4.0\\n.\\tThe\\tOctocat,\\tGitHub\\tlogo\\tand\\tother\\nalready-copyrighted\\tand\\talready-reserved\\ttrademarks\\tand\\timages\\tare\\tnot\\tcovered\\tby\\tthis\\tlicense.\\nFor\\tmore\\tinformation,\\tvisit:\\t\\nhttp://creativecommons.org/licenses/by/4.0/\\nIntroduction\\n4\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e9c2b786-28e2-43f0-b55d-6980b8dd7758', embedding=None, metadata={'page_label': '5', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Getting\\tReady\\tfor\\tClass\\nWhile\\tyou\\tare\\twaiting\\tfor\\tclass\\tto\\tbegin,\\tplease\\ttake\\ta\\tfew\\tminutes\\tto\\tset\\tup\\tyour\\tlocal\\twork\\tenvironment.\\nStep\\t1:\\tSet\\tUp\\tYour\\tGitHub.com\\tAccount\\nFor\\tthis\\tclass,\\twe\\twill\\tuse\\ta\\tpublic\\taccount\\ton\\tGitHub.com.\\tWe\\tdo\\tthis\\tfor\\ta\\tfew\\treasons:\\nWe\\tdon\\'t\\twant\\tyou\\tto\\t\"practice\"\\tin\\trepositories\\tthat\\tcontain\\treal\\tcode.\\nWe\\tare\\tgoing\\tto\\tbreak\\tsome\\tthings\\tso\\twe\\tcan\\tteach\\tyou\\thow\\tto\\tfix\\tthem.\\t(therefore,\\trefer\\tto\\tthe\\tbullet\\tabove)\\nYou\\tcan\\tset\\tup\\tyour\\tfree\\taccount\\tby\\tfollowing\\tthese\\tsteps:\\n1\\n.\\t\\nAccess\\tGitHub.com\\tand\\tclick\\tSign\\tup.\\n2\\n.\\t\\nChoose\\tthe\\tfree\\taccount.\\n3\\n.\\t\\nYou\\twill\\treceive\\ta\\tverification\\temail\\tat\\tthe\\taddress\\tprovided.\\n4\\n.\\t\\nClick\\tthe\\tlink\\tto\\tcomplete\\tthe\\tverification\\tprocess.\\nIf\\tyou\\talready\\thave\\tan\\taccount,\\tverify\\tthat\\tyou\\tcan\\tvisit\\tgithub.com\\twithin\\tyour\\torganization\\'s\\tnetwork.\\nGitHub\\tis\\tdesigned\\tto\\trun\\ton\\tthe\\tcurrent\\tversions\\tof\\tall\\tmajor\\tbrowsers.\\tIn\\tparticular,\\tif\\tyou\\tuse\\tMicrosoft\\'s\\tInternet\\nExplorer\\t(IE),\\tyou\\tmust\\tbe\\tusing\\tthe\\tlatest\\tversion.\\tTake\\ta\\tlook\\tat\\tour\\tlist\\tof\\t\\nsupported\\tbrowsers\\n.\\nStep\\t2:\\tInstall\\tGit\\nGit\\tis\\tan\\topen\\tsource\\tversion\\tcontrol\\tapplication.\\tYou\\twill\\tneed\\tGit\\tinstalled\\tfor\\tthis\\tclass.\\nYou\\tmay\\talready\\thave\\tGit\\tinstalled\\tso\\tlet\\'s\\tcheck!\\tOpen\\tTerminal\\tif\\tyou\\tare\\ton\\ta\\tMac,\\tor\\tPowerShell\\tif\\tyou\\tare\\ton\\ta\\nWindows\\tmachine,\\tand\\ttype:\\n$\\tgit\\t--version\\nYou\\tshould\\tsee\\tsomething\\tlike\\tthis:\\n$\\tgit\\t--version\\ngit\\tversion\\t2.11.0\\nAnything\\tover\\t2.0\\twill\\twork\\tfor\\tthis\\tclass!\\nDownloading\\tand\\tInstalling\\tGit\\nIf\\tyou\\tdon\\'t\\talready\\thave\\tGit\\tinstalled,\\tyou\\tcan\\tdownload\\tGit\\tat\\twww.git-scm.com.\\nIf\\tyou\\tneed\\tadditional\\tassistance\\tinstalling\\tGit,\\tyou\\tcan\\tfind\\tmore\\tinformation\\tin\\tthe\\tProGit\\tchapter\\ton\\tinstalling\\tGit:\\n\\t\\nhttp://git-scm.com/book/en/v2/Getting-Started-Installing-Git\\n\\t\\n.\\nWhere\\tis\\tYour\\tShell?\\nNow\\tis\\ta\\tgood\\ttime\\tto\\tcreate\\ta\\tshortcut\\tto\\tthe\\tcommand\\tline\\tapplication\\tyou\\twill\\twant\\tto\\tuse\\twith\\tGit:\\nIf\\tyou\\tare\\tworking\\ton\\tWindows,\\twe\\trecommend\\t\\n\\t\\nGit\\tBash\\n\\t\\n\\twhich\\tis\\tinstalled\\twith\\tthe\\tGit\\tpackage,\\tso\\tthat\\tyou\\tcan\\nfollow\\talong\\twith\\tthe\\tfacilitator\\twho\\twill\\tbe\\tusing\\tBash.\\nIf\\tyou\\tare\\tworking\\ton\\ta\\tMac\\tor\\tother\\tUnix-based\\tsystem,\\tyou\\tcan\\tuse\\tthe\\tbuilt-in\\tTerminal\\tapplication.\\nGetting\\tReady\\tfor\\tClass\\n5', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='c2d120f9-ebd9-4427-a048-5fe310a33711', embedding=None, metadata={'page_label': '6', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Step\\t3:\\tTry\\tcloning\\twith\\tHTTPS\\nOpen\\tyour\\tchosen\\tshell,\\tand\\ttype:\\ngit\\t\\nclone\\n\\thttps://github.com/githubschool/scratch\\nIf\\tthe\\tclone\\tis\\tsuccessful\\tyou'll\\tsee:\\n$\\tgit\\t\\nclone\\n\\thttps://github.com/githubschool/scratch\\nCloning\\tinto\\t\\n'scratch'\\n...\\nremote:\\tCounting\\tobjects:\\t6,\\tdone.\\nremote:\\tCompressing\\tobjects:\\t100%\\t(2/2),\\tdone.\\nremote:\\tTotal\\t6\\t(delta\\t0),\\treused\\t0\\t(delta\\t0),\\tpack-reused\\t0\\nUnpacking\\tobjects:\\t100%\\t(6/6),\\tdone.\\nIf\\tyour\\tclone\\tis\\tunsuccessful,\\tread\\tabout\\t\\nauthenticating\\twith\\tGitHub\\tfrom\\tGit\\n.\\tPlease\\tnote:\\tmany\\tcorporate\\tnetworks\\nrestrict\\tSSH\\ttraffic,\\tso\\twe\\thighly\\trecommend\\tusing\\tHTTPS\\tand\\tverifying\\tthe\\tclone\\tworks\\tbefore\\tclass.\\tAlso,\\tif\\tyou\\nhave\\ttwo-factor\\tauthentication\\tenabled\\tand\\twish\\tto\\tuse\\tHTTPS,\\tyou\\twill\\tneed\\tto\\t\\nset\\tup\\ta\\tpersonal\\taccess\\ttoken\\n.\\nProxy\\tconfiguration\\nIf\\tyour\\torganization\\tuses\\ta\\tproxy,\\tyou\\twill\\tneed\\tto\\tconfigure\\tthe\\tproxy\\tsettings\\tin\\tGit.\\tOpen\\tGit\\tBash\\t(on\\tWindows)\\tor\\nTerminal\\t(on\\tMac\\tor\\t*nix)\\tand\\tcomplete\\tthe\\tappropriate\\tsteps\\tbelow:\\nIf\\tyour\\tproxy\\tdoes\\tnot\\trequire\\tauthentication:\\ngit\\tconfig\\t--global\\thttp.proxy\\thttps://YOUR.PROXY.SERVER:8080\\nReplace\\t\\n\\t\\nYOUR.PROXY.SERVER\\n\\t\\n\\twith\\tyour\\tproxy's\\tURL.\\nIf\\tyour\\tproxy\\tdoes\\trequire\\tauthentication:\\ngit\\tconfig\\t--global\\thttp.proxy\\thttps://YOUR_PROXY_USERNAME:YOUR_PROXY_PASSWORD@YOUR.PROXY.SERVER:8080\\nReplace\\t\\n\\t\\nYOUR_PROXY_USERNAME\\n\\t\\n\\twith\\tthe\\tusername\\tused\\tto\\tauthenticate\\tinto\\tyour\\tproxy,\\t\\n\\t\\nYOUR_PROXY_PASSWORD\\n\\t\\n\\twith\\tthe\\npassword\\tused\\tto\\tauthenticate\\tinto\\tyour\\tproxy,\\tand\\t\\n\\t\\nYOUR.PROXY.SERVER\\n\\t\\n\\twith\\tyour\\tproxy's\\tURL.\\nStep\\t4:\\tSet\\tUp\\tYour\\tText\\tEditor\\nFor\\tthis\\tclass,\\twe\\twill\\tuse\\ta\\tbasic\\ttext\\teditor\\tto\\tinteract\\twith\\tour\\tcode.\\tLet's\\tmake\\tsure\\tyou\\thave\\tone\\tinstalled\\tand\\nready\\tto\\twork\\tfrom\\tthe\\tcommand\\tline.\\nPick\\tYour\\tEditor\\nYou\\tcan\\tuse\\talmost\\tany\\ttext\\teditor,\\tbut\\twe\\thave\\tthe\\tbest\\tsuccess\\twith\\tthe\\tfollowing:\\nAtom\\nVisual\\tStudio\\tCode\\nNotepad\\nVi\\tor\\tVim\\nSublime\\nNotepad++\\nGitPad\\nGetting\\tReady\\tfor\\tClass\\n6\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='382a1856-cdd1-4f2e-bd0a-3a8d01c8f33f', embedding=None, metadata={'page_label': '7', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='If\\tyou\\tdo\\tnot\\talready\\thave\\ta\\ttext\\teditor\\tinstalled,\\tgo\\tahead\\tand\\tdownload\\tand\\tinstall\\tone\\tof\\tthe\\tabove\\teditors\\tnow!\\nYou\\tcan\\talso\\tconfigure\\tAtom\\tas\\tyour\\tdefault\\ttext\\teditor\\tfor\\tGit\\tcommands\\tusing\\tthe\\t\\ninstructions\\tat\\thelp.github.com\\n.\\nYour\\tEditor\\ton\\tthe\\tCommand\\tLine\\nAfter\\tyou\\thave\\tinstalled\\tan\\teditor,\\tconfirm\\tyou\\tcan\\topen\\tit\\tfrom\\tthe\\tcommand\\tline.\\nIf\\tinstalled\\tproperly,\\tthe\\tfollowing\\tcommand\\twill\\topen\\tthe\\tAtom\\ttext\\teditor:\\n$\\tatom\\t.\\nIf\\tyou\\tare\\tworking\\ton\\ta\\tMac,\\tyou\\twill\\tneed\\tto\\tInstall\\tShell\\tCommands\\tfrom\\tthe\\tAtom\\tmenu,\\tthis\\thappens\\tas\\tpart\\nof\\tthe\\tinstallation\\tprocess\\tfor\\tWindows.\\nExploring\\nCongratulations!\\tYou\\tshould\\tnow\\thave\\ta\\tworking\\tversion\\tof\\tGit\\tand\\ta\\ttext\\teditor\\ton\\tyour\\tsystem.\\tIf\\tyou\\tstill\\thave\\tsome\\ntime\\tbefore\\tclass\\tbegins,\\there\\tare\\tsome\\tinteresting\\tresources\\tyou\\tcan\\tcheck\\tout:\\ngithub.com/explore\\n\\tExplore\\tis\\ta\\tshowcase\\tof\\tinteresting\\tprojects\\tin\\tthe\\tGitHub\\tUniverse.\\tSee\\tsomething\\tyou\\nwant\\tto\\tre-visit?\\tStar\\tthe\\trepository\\tto\\tmake\\tit\\teasier\\tto\\tfind\\tlater.\\nlab.github.com\\n\\tThe\\tLearning\\tLab\\tbot\\twill\\tguide\\tyou\\tthrough\\tprojects\\tand\\tprovide\\tfeedback\\tright\\tfrom\\tyour\\tGitHub\\nrepository,\\thelping\\tyou\\tbuild\\tevery\\tstep\\tof\\tthe\\tway.\\nGetting\\tReady\\tfor\\tClass\\n7', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='53af44fe-411c-4e77-adf7-24aaa37db509', embedding=None, metadata={'page_label': '8', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Getting\\tStarted\\tWith\\tCollaboration\\nWe\\twill\\tstart\\tby\\tintroducing\\tyou\\tto\\tGit,\\tGitHub,\\tand\\tthe\\tcollaboration\\tfeatures\\twe\\twill\\tuse\\tthroughout\\tthe\\tclass.\\tEven\\tif\\nyou\\thave\\tused\\tGitHub\\tin\\tthe\\tpast,\\twe\\thope\\tthis\\tinformation\\twill\\tprovide\\ta\\tbaseline\\tunderstanding\\tof\\thow\\tto\\tuse\\tit\\tto\\nbuild\\tbetter\\tsoftware!\\nWhat\\tis\\tGitHub?\\nGitHub\\tis\\ta\\tcollaboration\\tplatform\\tbuilt\\ton\\ttop\\tof\\ta\\tdistributed\\tversion\\tcontrol\\tsystem\\tcalled\\tGit.\\tGitHub\\tis\\tfocused\\ton\\ndevelopers,\\tthe\\tpeople\\twho\\tcode\\tand\\tcreate\\tsoftware.\\tOur\\tfocus\\tis\\talso\\tthe\\tpeople\\twho\\tpartner\\twith\\tand\\temploy\\ndevelopers,\\twho\\tare\\tencouraging\\tthem\\tto\\tbuild\\tamazing\\tthings.\\nWe\\tdo\\tall\\twe\\tcan\\tto\\thelp\\tunlock\\tthe\\tcreativity\\tof\\tdevelopers\\tand\\tto\\tfoster\\ta\\tcommunity\\tof\\tdevelopers\\tthat\\tcan\\tcome\\ntogether—as\\tindividuals\\tand\\tin\\tteams—to\\tcreate\\tthe\\tfuture\\tof\\tsoftware\\tand\\tmake\\ta\\tdifference\\tin\\tthe\\tworld.\\nGitHub\\tconcentrates\\ton\\tthree\\tthings:\\nBuilding\\ta\\ttechnology\\tplatform\\tthat\\tis\\tlike\\tno\\tother,\\ton\\twhich\\tdevelopers\\tcan\\tcreate,\\tshare\\tand\\tgrow\\tthe\\tbest\\ncode\\tpossible\\nNurturing\\ta\\tcommunity\\tfor\\tdevelopers;\\ta\\tsafe\\tand\\tcollaborative\\tplace\\tthat\\tfacilitates\\tsharing,\\tamplifies\\tcreativity,\\nand\\tsupports\\tthe\\tprinciples\\tof\\topen\\tsource\\nProviding\\taccess,\\topening\\tup\\ta\\tcommunity\\tof\\topportunity,\\twhere\\tnew\\tdevelopers\\tcan\\tbe\\tborn\\tand\\twhere\\nexperienced\\tdevelopers\\tcan\\thone\\ttheir\\tskills\\tand\\texpand\\ttheir\\tknowledge\\nIn\\taddition\\tto\\tbeing\\ta\\tplace\\tto\\thost\\tand\\tshare\\tyour\\tGit\\tprojects,\\tGitHub\\tprovides\\ta\\tnumber\\tof\\tfeatures\\tto\\thelp\\tyou\\tand\\nyour\\tteam\\tcollaborate\\tmore\\teffectively.\\tThese\\tfeatures\\tinclude:\\nIssues\\nPull\\tRequests\\nProjects\\nOrganizations\\tand\\tTeams\\nGetting\\tStarted\\n8', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='10de6596-a0b6-4d9a-8d31-5c5fcb31a705', embedding=None, metadata={'page_label': '9', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The\\tGitHub\\tEcosystem\\nRather\\tthan\\tforce\\tyou\\tinto\\ta\\t\"one\\tsize\\tfits\\tall\"\\tecosystem,\\tGitHub\\tstrives\\tto\\tbe\\tthe\\tplace\\tthat\\tbrings\\tall\\tof\\tyour\\tfavorite\\ntools\\ttogether.\\tFor\\tmore\\tinformation\\ton\\tintegrations,\\tcheck\\tout\\t\\nhttps://github.com/integrations\\n.\\nYou\\tmay\\teven\\tfind\\tsome\\tnew,\\tindispensable\\ttools\\tto\\thelp\\twith\\tcontinuous\\tintegration,\\tdependency\\tmanagement,\\ncode\\tquality\\tand\\tmuch\\tmore.\\nWhat\\tis\\tGit?\\nGit\\tis:\\na\\tdistributed\\tversion\\tcontrol\\tsystem\\tor\\tDVCS.\\nGetting\\tStarted\\n9', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='01c31018-1cbe-40b2-8c4e-23702cabab88', embedding=None, metadata={'page_label': '10', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"free\\tand\\topen\\tsource.\\ndesigned\\tto\\thandle\\teverything\\tfrom\\tsmall\\tto\\tvery\\tlarge\\tprojects\\twith\\tspeed\\tand\\tefficiency.\\neasy\\tto\\tlearn\\tand\\thas\\ta\\ttiny\\tfootprint\\twith\\tlightning\\tfast\\tperformance.\\nGit\\tfeatures\\tcheap\\tlocal\\tbranching,\\tconvenient\\tstaging\\tareas,\\tand\\tmultiple\\tworkflows.\\nAs\\twe\\tbegin\\tto\\tdiscuss\\tGit\\t(and\\twhat\\tmakes\\tit\\tspecial)\\tit\\twould\\tbe\\thelpful\\tif\\tyou\\tcould\\tforget\\teverything\\tyou\\tknow\\nabout\\tother\\tversion\\tcontrol\\tsystems\\t(VCSs)\\tfor\\tjust\\ta\\tmoment.\\tGit\\tstores\\tand\\tthinks\\tabout\\tinformation\\tvery\\tdifferently\\nthan\\tother\\tVCSs.\\nWe\\twill\\tlearn\\tmore\\tabout\\thow\\tGit\\tstores\\tyour\\tcode\\tas\\twe\\tgo\\tthrough\\tthis\\tclass,\\tbut\\tthe\\tfirst\\tthing\\tyou\\twill\\tneed\\tto\\nunderstand\\tis\\thow\\tGit\\tworks\\twith\\tyour\\tcontent.\\nSnapshots,\\tnot\\tDeltas\\nOne\\tof\\tthe\\tfirst\\tideas\\tyou\\twill\\tneed\\tunderstand\\tis\\tthat\\tGit\\tdoes\\tnot\\tstore\\tyour\\tinformation\\tas\\tseries\\tof\\tchanges.\\nInstead\\tGit\\ttakes\\ta\\tsnapshot\\tof\\tyour\\trepository\\tat\\ta\\tgiven\\tpoint\\tin\\ttime.\\tThis\\tsnapshot\\tis\\tcalled\\ta\\tcommit.\\nOptimized\\tfor\\tLocal\\tOperations\\nGit\\tis\\toptimized\\tfor\\tlocal\\toperation.\\tWhen\\tyou\\tclone\\ta\\tcopy\\tof\\ta\\trepository\\tto\\tyour\\tlocal\\tmachine,\\tyou\\treceive\\ta\\tcopy\\nof\\tthe\\tentire\\trepository\\tand\\tits\\thistory.\\tThis\\tmeans\\tyou\\tcan\\twork\\ton\\tthe\\tplane,\\ton\\tthe\\ttrain,\\tor\\tanywhere\\telse\\tyour\\nadventures\\tfind\\tyou!\\nBranches\\tare\\tLightweight\\tand\\tCheap\\nBranches\\tare\\tan\\tessential\\tconcept\\tin\\tGit.\\nWhen\\tyou\\tcreate\\ta\\tnew\\tbranch\\tin\\tGit,\\tyou\\tare\\tactually\\tjust\\tcreating\\ta\\tpointer\\tthat\\tcorresponds\\tto\\tthe\\tmost\\trecent\\ncommit\\tin\\ta\\tline\\tof\\twork.\\tGit\\tkeeps\\tthe\\tcommits\\tfor\\teach\\tbranch\\tseparate\\tuntil\\tyou\\texplicitly\\ttell\\tit\\tto\\tmerge\\tthose\\ncommits\\tinto\\tthe\\tmain\\tline\\tof\\twork.\\nGit\\tis\\tExplicit\\nWhich\\tbrings\\tus\\tto\\tour\\tfinal\\tpoint\\tfor\\tnow;\\tGit\\tis\\tvery\\texplicit.\\tIt\\tdoes\\tnot\\tdo\\tanything\\tuntil\\tyou\\ttell\\tit\\tto.\\tNo\\tauto-saves\\nor\\tauto-syncing\\twith\\tthe\\tremote,\\tGit\\twaits\\tfor\\tyou\\tto\\ttell\\tit\\twhen\\tto\\ttake\\ta\\tsnapshot\\tand\\twhen\\tto\\tsend\\tthat\\tsnapshot\\tto\\nthe\\tremote.\\nExploring\\ta\\tGitHub\\tRepository\\nA\\trepository\\tis\\tthe\\tmost\\tbasic\\telement\\tof\\tGitHub.\\tIt\\tis\\teasiest\\tto\\timagine\\tas\\ta\\tproject's\\tfolder.\\tHowever,\\tunlike\\tan\\nordinary\\tfolder\\ton\\tyour\\tlaptop,\\ta\\tGitHub\\trepository\\toffers\\tsimple\\tyet\\tpowerful\\ttools\\tfor\\tcollaborating\\twith\\tothers.\\nA\\trepository\\tcontains\\tall\\tof\\tthe\\tproject\\tfiles\\t(including\\tdocumentation),\\tand\\tstores\\teach\\tfile's\\trevision\\thistory.\\tWhether\\nyou\\tare\\tjust\\tcurious\\tor\\tyou\\tare\\ta\\tmajor\\tcontributor,\\tknowing\\tyour\\tway\\taround\\ta\\trepository\\tis\\tessential!\\nGetting\\tStarted\\n10\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='69bf9b9a-dca4-4426-add6-c182a20170c3', embedding=None, metadata={'page_label': '11', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='User\\tAccounts\\tvs.\\tOrganization\\tAccounts\\nThere\\tare\\ttwo\\taccount\\ttypes\\tin\\tGitHub,\\tuser\\taccounts\\tand\\torganization\\taccounts.\\tWhile\\tthere\\tare\\tmany\\tdifferences\\tin\\nthese\\taccount\\ttypes,\\tone\\tof\\tthe\\tmore\\tnotable\\tdifferences\\tis\\thow\\tyou\\thandle\\tpermissions.\\nUser\\tAccounts\\nWhen\\tyou\\tsigned\\tup\\tfor\\tGitHub,\\tyou\\twere\\tautomatically\\tgiven\\ta\\tuser\\taccount.\\tPermissions\\tfor\\ta\\tuser\\taccount\\tare\\nsimple,\\tyou\\tadd\\tpeople\\tas\\tcollaborators\\tto\\tspecific\\trepositories\\tto\\tgive\\tthem\\tfull\\tread-write\\taccess\\tto\\tthe\\tproject.\\nOrganization\\tAccounts\\nOrganization\\taccounts\\tprovide\\tmore\\tgranular\\tcontrol\\tover\\trepository\\tpermissions.\\tIn\\tan\\torganization\\taccount\\tyou\\ncreate\\tteams\\tof\\tpeople\\tand\\tthen\\tgive\\tthose\\tteams\\taccess\\tto\\tspecific\\trepositories.\\tPermissions\\tcan\\tbe\\tassigned\\tat\\tthe\\nteam\\tlevel\\t(e.g,\\tread,\\twrite,\\tor\\tadmin).\\nRepository\\tNavigation\\nCode\\nThe\\tcode\\tview\\tis\\twhere\\tyou\\twill\\tfind\\tthe\\tfiles\\tincluded\\tin\\tthe\\trepository.\\tThese\\tfiles\\tmay\\tcontain\\tthe\\tproject\\tcode,\\ndocumentation,\\tand\\tother\\timportant\\tfiles.\\tWe\\talso\\tcall\\tthis\\tview\\tthe\\troot\\tof\\tthe\\tproject.\\tAny\\tchanges\\tto\\tthese\\tfiles\\twill\\nbe\\ttracked\\tvia\\tGit\\tversion\\tcontrol.\\nIssues\\nIssues\\tare\\tused\\tto\\ttrack\\tbugs\\tand\\tfeature\\trequests.\\tIssues\\tcan\\tbe\\tassigned\\tto\\tspecific\\tteam\\tmembers\\tand\\tare\\ndesigned\\tto\\tencourage\\tdiscussion\\tand\\tcollaboration.\\nGetting\\tStarted\\n11', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ca71a4b0-c878-438c-9739-10695d0fc55d', embedding=None, metadata={'page_label': '12', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Pull\\tRequests\\nA\\tPull\\tRequest\\trepresents\\ta\\tchange,\\tsuch\\tas\\tadding,\\tmodifying,\\tor\\tdeleting\\tfiles,\\twhich\\tthe\\tauthor\\twould\\tlike\\tto\\tmake\\nto\\tthe\\trepository.\\tPull\\tRequests\\thelp\\tyou\\twrite\\tbetter\\tsoftware\\tby\\tfacilitating\\tcode\\treview\\tand\\tshowing\\tthe\\tstatus\\tof\\nany\\tautomated\\ttests.\\nProjects\\nProjects\\tallow\\tyou\\tto\\tvisualize\\tyour\\twork\\twith\\tKanban\\tstyle\\tboards.\\tProjects\\tcan\\tbe\\tcreated\\tat\\tthe\\trepository\\tor\\norganization\\tlevel.\\nWiki\\nWikis\\tin\\tGitHub\\tcan\\tbe\\tused\\tto\\tcommunicate\\tproject\\tdetails,\\tdisplay\\tuser\\tdocumentation,\\tor\\talmost\\tanything\\tyour\\nheart\\tdesires.\\tAnd\\tof\\tcourse,\\tGitHub\\thelps\\tyou\\tkeep\\ttrack\\tof\\tthe\\tedits\\tto\\tyour\\tWiki!\\nPulse\\nPulse\\tis\\tyour\\tproject's\\tdash\\tboard.\\tIt\\tcontains\\tinformation\\ton\\tthe\\twork\\tthat\\thas\\tbeen\\tcompleted\\tand\\tthe\\twork\\tin\\nprogress.\\nGraphs\\nGraphs\\tprovide\\ta\\tmore\\tgranular\\tview\\tinto\\tthe\\trepository\\tactivity,\\tincluding\\twho\\thas\\tcontributed,\\twhen\\tthe\\twork\\tis\\nbeing\\tdone,\\tand\\twho\\thas\\tforked\\tthe\\trepository.\\nREADME.md\\nThe\\tREADME.md\\tis\\ta\\tspecial\\tfile\\tthat\\twe\\trecommend\\tall\\trepositories\\tcontain.\\tGitHub\\tlooks\\tfor\\tthis\\tfile\\tand\\thelpfully\\ndisplays\\tit\\tbelow\\tthe\\trepository.\\tThe\\tREADME\\tshould\\texplain\\tthe\\tproject\\tand\\tpoint\\treaders\\tto\\thelpful\\tinformation\\nwithin\\tthe\\tproject.\\nCONTRIBUTING.md\\nThe\\tCONTRIBUTING.md\\tis\\tanother\\tspecial\\tfile\\tthat\\tis\\tused\\tto\\tdescribe\\tthe\\tprocess\\tfor\\tcollaborating\\ton\\tthe\\nrepository.\\tThe\\tlink\\tto\\tthe\\tCONTRIBUTING.md\\tfile\\tis\\tshown\\twhen\\ta\\tuser\\tattempts\\tto\\tcreate\\ta\\tnew\\tissue\\tor\\tpull\\nrequest.\\nISSUE_TEMPLATE.md\\nThe\\tISSUE_TEMPLATE.md\\t(and\\tits\\ttwin\\tthe\\tpull\\trequest\\ttemplate)\\tare\\tused\\tto\\tgenerate\\ttemplated\\tstarter\\ttext\\tfor\\nyour\\tproject\\tissues.\\tAny\\ttime\\tsomeone\\topens\\tan\\tissue,\\tthe\\tcontent\\tin\\tthe\\ttemplate\\twill\\tbe\\tpre-populated\\tin\\tthe\\tissue\\nbody.\\nUsing\\tGitHub\\tIssues\\nIn\\tGitHub,\\tyou\\twill\\tuse\\tissues\\tto\\trecord\\tand\\tdiscuss\\tideas,\\tenhancements,\\ttasks,\\tand\\tbugs.\\tIssues\\tmake\\ncollaboration\\teasier\\tby:\\nReplacing\\temail\\tfor\\tproject\\tdiscussions,\\tensuring\\teveryone\\ton\\tthe\\tteam\\thas\\tthe\\tcomplete\\tstory,\\tboth\\tnow\\tand\\tin\\nthe\\tfuture.\\nAllowing\\tyou\\tto\\tcross-link\\tto\\trelated\\tissues\\tand\\tpull\\trequests.\\nCreating\\ta\\tsingle,\\tcomprehensive\\trecord\\tof\\thow\\tand\\twhy\\tyou\\tmade\\tcertain\\tdecisions.\\nGetting\\tStarted\\n12\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b9f22eab-d7bc-41f6-9311-0bf183762645', embedding=None, metadata={'page_label': '13', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Allowing\\tyou\\tto\\teasily\\tpull\\tthe\\tright\\tpeople\\tinto\\ta\\tconversation\\twith\\t@\\tmentions\\tand\\tteam\\tmentions.\\ninclude\\nUsing\\tMarkdown\\nGitHub\\tuses\\ta\\tsyntax\\tcalled\\t\\nMarkdown\\n\\tto\\thelp\\tyou\\tadd\\tbasic\\ttext\\tformatting\\tto\\tIssues,\\tPull\\tRequests,\\tand\\tfiles\\twith\\nthe\\t\\n\\t\\n.md\\n\\t\\n\\textension.\\nCommonly\\tUsed\\tMarkdown\\tSyntax\\n\\t\\n#\\tHeader\\n\\t\\nThe\\t\\n\\t\\n#\\n\\t\\n\\tindicates\\ta\\tHeader.\\t#\\t=\\tHeader\\t1,\\t##\\t\\n=\\tHeader\\t2,\\tetc.\\n\\t\\n*\\tList\\titem\\n\\t\\nA\\tsingle\\t\\n\\t\\n*\\n\\t\\n\\tor\\t\\n\\t\\n-\\n\\t\\n\\tfollowed\\tby\\ta\\tspace\\twill\\tcreate\\ta\\tbulleted\\tlist.\\n\\t\\n**Bold\\titem**\\n\\t\\nTwo\\tasterix\\t\\n\\t\\n**\\n\\t\\n\\ton\\teither\\tside\\tof\\ta\\tstring\\twill\\tmake\\tthat\\ttext\\tbold.\\n\\t\\n-\\t[\\t]\\tChecklist\\n\\t\\nA\\t\\n\\t\\n-\\n\\t\\n\\tfollowed\\tby\\ta\\tspace\\tand\\t\\n\\t\\n[\\t]\\n\\t\\n\\twill\\tcreate\\ta\\thandy\\tchecklist\\tin\\tyour\\tissue\\tor\\tpull\\trequest.\\n\\t\\n@mention\\n\\t\\nWhen\\tyou\\t@mention\\tsomeone\\tin\\tan\\tissue,\\tthey\\twill\\treceive\\ta\\tnotification\\t-\\teven\\tif\\tthey\\tare\\tnot\\tcurrently\\tsubscribed\\tto\\nthe\\tissue\\tor\\twatching\\tthe\\trepository.\\n\\t\\n#975\\n\\t\\nA\\t\\n\\t\\n#\\n\\t\\n\\tfollowed\\tby\\tthe\\tnumber\\tof\\tan\\tissue\\tor\\tpull\\trequest\\t(without\\ta\\tspace)\\tin\\tthe\\tsame\\trepository\\twill\\tcreate\\ta\\tcross-\\nlink.\\n\\t\\n:smiley:\\n\\t\\nTone\\tis\\teasily\\tlost\\tin\\twritten\\tcommunication.\\tTo\\thelp,\\tGitHub\\tallows\\tyou\\tto\\tdrop\\temoji\\tinto\\tyour\\tcomments.\\tSimply\\nsurround\\tthe\\temoji\\tid\\twith\\t\\n\\t\\n:\\n\\t\\n.\\nIntroduction\\tto\\tGitHub\\tPages\\nGitHub\\tPages\\tenable\\tyou\\tto\\thost\\tfree,\\tstatic\\tweb\\tpages\\tdirectly\\tfrom\\tyour\\tGitHub\\trepositories.\\tSeveral\\tof\\tthe\\tprojects\\nwe\\tuse\\tin\\tclass\\twill\\tuse\\tGitHub\\tPages\\tas\\tthe\\tdeployment\\tstrategy.\\tWe\\twill\\tbarely\\tscratch\\tthe\\tsurface\\tin\\tthis\\tclass,\\tbut\\nthere\\tare\\ta\\tfew\\tthings\\tyou\\tneed\\tto\\tknow:\\nYou\\tcan\\tcreate\\ttwo\\ttypes\\tof\\twebsites,\\ta\\tuser/organization\\tsite\\tor\\ta\\tproject\\tsite.\\tWe\\twill\\tbe\\tworking\\twith\\tproject\\nwebsites.\\nFor\\ta\\tproject\\tsite,\\tGitHub\\twill\\tonly\\tserve\\tthe\\tcontent\\ton\\ta\\tspecific\\tbranch.\\tDepending\\ton\\tthe\\tsettings\\tfor\\tyour\\nrepository,\\tGitHub\\tcan\\tserve\\tyour\\tsite\\tfrom\\ta\\t\\n\\t\\nmaster\\n\\t\\n\\tor\\t\\n\\t\\ngh-pages\\n\\t\\n\\tbranch,\\tor\\ta\\t\\n\\t\\n/docs\\n\\t\\n\\tfolder\\ton\\tthe\\t\\n\\t\\nmaster\\n\\t\\nbranch.\\nThe\\trendered\\tsites\\tfor\\tour\\tprojects\\twill\\tappear\\tat\\t\\n\\t\\ngithubschool.github.io/repo-name\\n\\t\\n.\\nGetting\\tStarted\\n13', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='76e2a13c-0fea-45eb-a12d-528552bfa70c', embedding=None, metadata={'page_label': '14', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Getting\\tStarted\\n14', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='02f1b671-dec4-4d50-ab42-e0ce64e0e522', embedding=None, metadata={'page_label': '15', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Understanding\\tthe\\tGitHub\\tflow\\nIn\\tthis\\tsection,\\twe\\tdiscuss\\tthe\\tcollaborative\\tworkflow\\tenabled\\tby\\tGitHub.\\nThe\\tEssential\\tGitHub\\tWorkflow\\nThe\\tGitHub\\tflow\\tis\\ta\\tlightweight\\tworkflow\\tthat\\tallows\\tyou\\tto\\texperiment\\twith\\tnew\\tideas\\tsafely,\\twithout\\tfear\\tof\\ncompromising\\ta\\tproject.\\nBranching\\tis\\ta\\tkey\\tconcept\\tyou\\twill\\tneed\\tto\\tunderstand.\\tEverything\\tin\\tGitHub\\tlives\\ton\\ta\\tbranch.\\tBy\\tdefault,\\tthe\\n\"blessed\"\\tor\\t\"canonical\"\\tversion\\tof\\tyour\\tproject\\tlives\\ton\\ta\\tbranch\\tcalled\\t\\n\\t\\nmaster\\n\\t\\n.\\tThis\\tbranch\\tcan\\tactually\\tbe\\tnamed\\nanything,\\tas\\twe\\twill\\tsee\\tin\\ta\\tfew\\tminutes.\\nWhen\\tyou\\tare\\tready\\tto\\texperiment\\twith\\ta\\tnew\\tfeature\\tor\\tfix\\tan\\tissue,\\tyou\\tcreate\\ta\\tnew\\tbranch\\tof\\tthe\\tproject.\\tThe\\nbranch\\twill\\tlook\\texactly\\tlike\\t\\n\\t\\nmaster\\n\\t\\n\\tat\\tfirst,\\tbut\\tany\\tchanges\\tyou\\tmake\\twill\\tonly\\tbe\\treflected\\tin\\tyour\\tbranch.\\tSuch\\ta\\nnew\\tbranch\\tis\\toften\\tcalled\\ta\\t\"feature\"\\tbranch.\\nAs\\tyou\\tmake\\tchanges\\tto\\tthe\\tfiles\\twithin\\tthe\\tproject,\\tyou\\twill\\tcommit\\tyour\\tchanges\\tto\\tthe\\tfeature\\tbranch.\\nWhen\\tyou\\tare\\tready\\tto\\tstart\\ta\\tdiscussion\\tabout\\tyour\\tchanges,\\tyou\\twill\\topen\\ta\\tpull\\trequest.\\tA\\tpull\\trequest\\tdoesn\\'t\\nneed\\tto\\tbe\\ta\\tperfect\\twork\\tof\\tart\\t-\\tit\\tis\\tmeant\\tto\\tbe\\ta\\tstarting\\tpoint\\tthat\\twill\\tbe\\tfurther\\trefined\\tand\\tpolished\\tthrough\\tthe\\nefforts\\tof\\tthe\\tproject\\tteam.\\nWhen\\tthe\\tchanges\\tcontained\\tin\\tthe\\tpull\\trequest\\tare\\tapproved,\\tthe\\tfeature\\tbranch\\tis\\tmerged\\tonto\\tthe\\tmaster\\tbranch.\\nIn\\tthe\\tnext\\tsection,\\tyou\\twill\\tlearn\\thow\\tto\\tput\\tthis\\tGitHub\\tworkflow\\tinto\\tpractice.\\nExploring\\nHere\\tare\\tsome\\tinteresting\\tthings\\tyou\\tcan\\tcheck\\tout\\tlater:\\nguides.github.com/introduction/flow/\\n\\tAn\\tinteractive\\treview\\tof\\tthe\\tGitHub\\tWorkflow.\\nGitHub\\tFlow\\n15', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f7cc7828-0a37-454c-adfd-7074ad42b494', embedding=None, metadata={'page_label': '16', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Branching\\twith\\tGit\\nThe\\tfirst\\tstep\\tin\\tthe\\tGitHub\\tWorkflow\\tis\\tto\\tcreate\\ta\\tbranch.\\tThis\\twill\\tallow\\tus\\tto\\texperiment\\twith\\tnew\\tfeatures\\twithout\\naccidentally\\tintroducing\\tuntested\\tchanges\\ton\\tour\\tproduction\\tbranch.\\nBranching\\tDefined\\nWhen\\tyou\\tcreate\\ta\\tbranch,\\tyou\\tare\\tessentially\\tcreating\\tan\\tidentical\\tcopy\\tof\\tthe\\tproject\\tat\\tthat\\tpoint\\tin\\ttime.\\tThis\\tisn't\\nthe\\tsame\\tas\\tcreating\\ta\\tphysical\\tcopy\\ton\\tdisk.\\tIn\\tthe\\tbackground,\\ta\\tbranch\\tis\\tjust\\ta\\tpointer.\\nLet's\\tlearn\\thow\\tyou\\tcan\\tcreate\\ta\\tnew\\tbranch.\\ninclude\\nExploring\\nHere\\tare\\tsome\\tinteresting\\tthings\\tyou\\tcan\\tcheck\\tout\\tlater:\\nhttps://youtu.be/H5GJfcp3p4Q\\n\\tA\\tGitHub\\tTraining\\tVideo\\ton\\tbranching.\\nBranching\\twith\\tGit\\n16\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='387d7a1b-e4ed-4a75-b336-7db8b3402c39', embedding=None, metadata={'page_label': '17', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Local\\tGit\\tConfiguration\\nIn\\tthis\\tsection,\\twe\\twill\\tprepare\\tyour\\tlocal\\tenvironment\\tto\\twork\\twith\\tGit.\\nChecking\\tYour\\tGit\\tVersion\\nFirst,\\tlet's\\tconfirm\\tyour\\t\\nGit\\tInstallation\\n:\\n$\\tgit\\t--version\\n$\\tgit\\tversion\\t2.11.0\\nIf\\tyou\\tdo\\tnot\\tsee\\ta\\tgit\\tversion\\tlisted\\tor\\tthis\\tcommand\\treturns\\tan\\terror,\\tyou\\tmay\\tneed\\tto\\tinstall\\tGit.\\nTo\\tget\\tthe\\tlatest\\tversion\\tof\\tGit,\\tvisit\\t\\nwww.git-scm.com\\n.\\nGit\\tConfiguration\\tLevels\\nGit\\tallows\\tyou\\tto\\tset\\tconfiguration\\toptions\\tat\\tthree\\tdifferent\\tlevels.\\n--system\\nThese\\tare\\tsystem-wide\\tconfigurations.\\tThey\\tapply\\tto\\tall\\tusers\\ton\\tthis\\tcomputer.\\n--global\\nLocal\\tGit\\tConfigs\\n17\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='1cd08a78-78ab-425b-8139-dc81c81201b7', embedding=None, metadata={'page_label': '18', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='These\\tare\\tthe\\tuser\\tlevel\\tconfigurations.\\tThey\\tonly\\tapply\\tto\\tyour\\tuser\\taccount.\\n--local\\nThese\\tare\\tthe\\trepository\\tlevel\\tconfigurations.\\tThey\\tonly\\tapply\\tto\\tthe\\tspecific\\trepository\\twhere\\tthey\\tare\\tset.\\nThe\\tdefault\\tvalue\\tfor\\tgit\\tconfig\\tis\\t\\n\\t\\n--local\\n\\t\\n.\\nViewing\\tYour\\tConfigurations\\nIf\\tyou\\twould\\tlike\\tto\\tsee\\twhich\\tconfig\\tsettings\\thave\\tbeen\\tadded\\tautomatically,\\tyou\\tcan\\ttype\\t\\n\\t\\ngit\\tconfig\\t--list\\n\\t\\n.\\tThis\\nwill\\tautomatically\\tread\\tfrom\\teach\\tof\\tthe\\tthree\\tconfig\\tfiles\\tand\\tlist\\tthe\\tsetting\\tthey\\tcontain.\\n$\\tgit\\tconfig\\t--list\\nYou\\tcan\\talso\\tnarrow\\tthe\\tlist\\tto\\ta\\tspecific\\tconfiguration\\tlevel\\tby\\tincluding\\tit\\tbefore\\tthe\\tlist\\toption.\\n$\\tgit\\tconfig\\t--global\\t--list\\nConfiguring\\tYour\\tUser\\tName\\tand\\tEmail\\nGit\\tuses\\tthe\\tconfig\\tsettings\\tfor\\tyour\\tuser\\tname\\tand\\temail\\taddress\\tto\\tgenerate\\ta\\tunique\\tfingerprint\\tfor\\teach\\tof\\tthe\\ncommits\\tyou\\tcreate.\\tYou\\tcan\\'t\\tcreate\\tcommits\\twithout\\tthese\\tsettings:\\n$\\tgit\\tconfig\\t--global\\tuser.name\\t\\n\"First\\tLast\"\\n$\\tgit\\tconfig\\t--global\\tuser.email\\t\\n\"you@email.com\"\\nGit\\tConfig\\tand\\tYour\\tPrivacy\\nThe\\tinstructions\\tfor\\tthis\\texercise\\tuse\\tthe\\t\\n\\t\\n--global\\n\\t\\n\\tflag\\twhen\\tidentifying\\tyour\\t\\n\\t\\nuser.name\\n\\t\\n\\tand\\t\\n\\t\\nuser.email\\n\\t\\nconfiguration\\tsettings.\\tIf\\tyou\\tare\\tcurrently\\tusing\\ta\\tcomputer\\twithout\\ta\\tprivate,\\tpersonal\\taccount,\\tdon\\'t\\tapply\\tthe\\t\\n\\t\\n--\\nglobal\\n\\t\\n\\tflag.\\tThis\\tway,\\tthe\\tsettings\\twill\\tonly\\tbe\\tstored\\tin\\tour\\tassignment\\trepository.\\tIf\\tyou\\twork\\tin\\tanother\\trepository\\non\\tthis\\tsame\\tcomputer,\\tyou\\twill\\tneed\\tto\\tset\\tthese\\tconfiguration\\toptions\\tagain.\\nFor\\texample:\\ngit\\tconfig\\tuser.email\\t\\n\"you@email.com\"\\nYour\\tname\\tand\\temail\\taddress\\twill\\tautomatically\\tbe\\tstored\\tin\\tthe\\tcommits\\tyou\\tmake\\twith\\tGit.\\tIf\\tyou\\twould\\tlike\\tyour\\nemail\\tto\\tremain\\tprivate,\\tGitHub\\tallows\\tyou\\tto\\tgenerate\\ta\\tno-reply\\temail\\taddress\\tfor\\tyour\\taccount.\\tClick\\tthe\\t\\nKeep\\tmy\\nemail\\taddress\\tprivate\\n\\tin\\tthe\\t\\nSettings\\t>\\tEmails\\tsection\\n.\\tAfter\\tenabling\\tthis\\tfeature,\\tyou\\tjust\\tneed\\tto\\tenter\\tthe\\nautomatically\\tgenerated\\t\\n\\t\\nID+username@users.noreply.github.com\\n\\t\\n\\twhen\\tconfiguring\\tyour\\temail.\\nFor\\texample:\\ngit\\tconfig\\t--global\\tuser.email\\t18249274+githubteacher@users.noreply.github.com\\nConfiguring\\tautocrlf\\n$\\t//\\nfor\\n\\tWindows\\tusers\\n$\\tgit\\tconfig\\t--global\\tcore.autocrlf\\t\\ntrue\\n$\\t//\\nfor\\n\\tMac\\tor\\tLinux\\tusers\\n$\\tgit\\tconfig\\t--global\\tcore.autocrlf\\tinput\\nLocal\\tGit\\tConfigs\\n18', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='04b535b5-47e9-47d3-8558-f51924c9f308', embedding=None, metadata={'page_label': '19', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Different\\tsystems\\thandle\\tline\\tendings\\tand\\tline\\tbreaks\\tdifferently.\\tIf\\tyou\\topen\\ta\\tfile\\tcreated\\ton\\tanother\\tsystem\\tand\\tdo\\nnot\\thave\\tthis\\tconfig\\toption\\tset,\\tgit\\twill\\tthink\\tyou\\tmade\\tchanges\\tto\\tthe\\tfile\\tbased\\ton\\tthe\\tway\\tyour\\tsystem\\thandles\\tthis\\ntype\\tof\\tfile.\\nMemory\\tTip:\\t\\n\\t\\nautocrlf\\n\\t\\n\\tstands\\tfor\\tauto\\tcarriage\\treturn\\tline\\tfeed.\\nLocal\\tGit\\tConfigs\\n19', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d08ed67f-841b-4e9b-9db6-826e31806546', embedding=None, metadata={'page_label': '20', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Working\\tLocally\\twith\\tGit\\nUsing\\tthe\\tcommand\\tline,\\tyou\\tcan\\teasily\\tintegrate\\tGit\\tinto\\tyour\\tcurrent\\tworkflow.\\nCreating\\ta\\tLocal\\tCopy\\tof\\tthe\\trepo\\nBefore\\twe\\tcan\\twork\\tlocally,\\twe\\twill\\tneed\\tto\\tcreate\\ta\\tclone\\tof\\tthe\\trepository.\\nWhen\\tyou\\tclone\\ta\\trepository\\tyou\\tare\\tcreating\\ta\\tcopy\\tof\\teverything\\tin\\tthat\\trepository,\\tincluding\\tits\\thistory.\\tThis\\tis\\tone\\nof\\tthe\\tbenefits\\tof\\ta\\tDVCS\\tlike\\tgit\\t-\\trather\\tthan\\tbeing\\trequired\\tto\\tquery\\ta\\tslow\\tcentralized\\tserver\\tto\\treview\\tthe\\tcommit\\nhistory,\\tqueries\\tare\\trun\\tlocally\\tand\\tare\\tlightning\\tfast.\\nLet's\\tgo\\tahead\\tand\\tclone\\tthe\\tclass\\trepository\\tto\\tyour\\tlocal\\tdesktop.\\n1\\n.\\t\\nNavigate\\tto\\tthe\\t\\nCode\\n\\ttab\\tof\\tthe\\tclass\\trepository\\ton\\tGitHub.\\n2\\n.\\t\\nClick\\t\\nClone\\tor\\tdownload\\n.\\n3\\n.\\t\\nCopy\\tthe\\t\\nclone\\tURL\\n\\tto\\tyour\\tclipboard.\\n4\\n.\\t\\nOpen\\tyour\\tcommand\\tline\\tapplication.\\n5\\n.\\t\\nRetrieve\\ta\\tfull\\tcopy\\tof\\tthe\\trepository\\tfrom\\tGitHub:\\t\\n\\t\\ngit\\tclone\\t<CLONE-URL>\\n\\t\\n6\\n.\\t\\nOnce\\tthe\\tclone\\tis\\tcomplete,\\tcd\\tinto\\tthe\\tnew\\tdirectory\\tcreated\\tby\\tthe\\tclone\\toperation:\\t\\n\\t\\ncd\\t<REPOSITORY-NAME>\\n\\t\\nOur\\tFavorite\\tGit\\tcommand:\\t\\n\\t\\ngit\\tstatus\\n\\t\\n$\\tgit\\tstatus\\nOn\\tbranch\\tmaster\\nYour\\tbranch\\tis\\tup-to-date\\twith\\t\\n'origin/master'\\n.\\nnothing\\tto\\tcommit,\\tworking\\ttree\\tclean\\n\\t\\ngit\\tstatus\\n\\t\\n\\tis\\ta\\tcommand\\tyou\\twill\\tuse\\toften\\tto\\tverify\\tthe\\tcurrent\\tstate\\tof\\tyour\\trepository\\tand\\tthe\\tfiles\\tit\\tcontains.\\nRight\\tnow,\\twe\\tcan\\tsee\\tthat\\twe\\tare\\ton\\tbranch\\tmaster,\\teverything\\tis\\tup\\tto\\tdate\\twith\\torigin/master\\tand\\tour\\tworking\\ttree\\nis\\tclean.\\nUsing\\tBranches\\tlocally\\n$\\tgit\\tbranch\\nWorking\\tLocally\\n20\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='1ba7fe96-60f0-4fad-aa6e-4e8dedd10b94', embedding=None, metadata={'page_label': '21', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='If\\tyou\\ttype\\t\\n\\t\\ngit\\tbranch\\n\\t\\n\\tyou\\twill\\tsee\\ta\\tlist\\tof\\tlocal\\tbranches.\\n$\\tgit\\tbranch\\t--all\\n$\\tgit\\tbranch\\t\\n-a\\nIf\\tyou\\twant\\tto\\tsee\\tall\\tof\\tthe\\tbranches,\\tincluding\\tthe\\tread-only\\tcopies\\tof\\tyour\\tremote\\tbranches,\\tyou\\tcan\\tadd\\tthe\\t\\n\\t\\n--all\\n\\t\\noption\\tor\\tjust\\t\\n\\t\\n-a\\n\\t\\n.\\nThe\\t\\n\\t\\n--all\\n\\t\\n\\tand\\t\\n\\t\\n-a\\n\\t\\n\\tare\\tactually\\tsynonyms\\tfor\\tthe\\tbranch\\tcommand.\\tGit\\toften\\tprovides\\ta\\tverbose\\tand\\ta\\tshort\\noption.\\nSwitching\\tBranches\\n$\\tgit\\tcheckout\\t<BRANCH-NAME>\\nTo\\tcheckout\\tthe\\tbranch\\tyou\\tcreated\\tonline,\\ttype\\tgit\\tcheckout\\tand\\tthe\\tname\\tof\\tyour\\tbranch.\\tGit\\twill\\tprovide\\ta\\tmessage\\nthat\\tsays\\tyou\\thave\\tbeen\\tswitched\\tto\\tthe\\tbranch\\tand\\tit\\thas\\tbeen\\tset\\tup\\tto\\ttrack\\tthe\\tsame\\tremote\\tbranch\\tfrom\\torigin.\\nYou\\tdo\\tnot\\tneed\\tto\\ttype\\t\\n\\t\\nremotes/origin\\n\\t\\n\\tin\\tfront\\tof\\tthe\\tbranch\\t-\\tonly\\tthe\\tbranch\\tname.\\tTyping\\t\\n\\t\\nremotes/origin\\n\\t\\nin\\tfront\\tof\\tthe\\tbranch\\tname\\twill\\tput\\tyou\\tin\\ta\\tdetached\\tHEAD\\tstate.\\tWe\\twill\\tlearn\\tmore\\tabout\\tthat\\tlater,\\tbut\\tfor\\nnow\\tjust\\tremember\\tthis\\tis\\tnot\\ta\\tstate\\twe\\twant\\tto\\tbe\\tin.\\ninclude\\nThe\\tTwo\\tStage\\tCommit\\nAfter\\tyou\\thave\\tcreated\\tyour\\tfile,\\tit\\tis\\ttime\\tto\\tcreate\\tyour\\tfirst\\tsnapshot\\tof\\tthe\\trepository.\\tWhen\\tworking\\tfrom\\tthe\\ncommand\\tline,\\tyou\\twill\\tneed\\tto\\tbe\\tfamiliar\\twith\\tthe\\tidea\\tof\\tthe\\ttwo\\tstage\\tcommit.\\nWhen\\tyou\\twork\\tlocally,\\tyour\\tfiles\\texist\\tin\\tone\\tof\\tfour\\tstates.\\tThey\\tare\\teither\\tuntracked,\\tmodified,\\tstaged,\\tor\\ncommitted.\\nAn\\tuntracked\\tfile\\tis\\ta\\tnew\\tfile\\tthat\\thas\\tnever\\tbeen\\tcommitted.\\nGit\\ttracks\\tthese\\tfiles,\\tand\\tkeeps\\ttrack\\tof\\tyour\\thistory\\tby\\torganizing\\tyour\\tfiles\\tand\\tchanges\\tin\\tthree\\tworking\\ttrees.\\nThey\\tare\\tWorking,\\tStaging\\t(also\\tcalled\\tIndex),\\tand\\tHistory.\\tWhen\\twe\\tare\\tactively\\tmaking\\tchanges\\tto\\tfiles,\\tthis\\tis\\nhappening\\tin\\tthe\\tworking\\ttree.\\nWorking\\tLocally\\n21', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='16eb8602-c7bd-4902-935f-6cc2b31657a6', embedding=None, metadata={'page_label': '22', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='To\\tadd\\tthese\\tfiles\\tto\\tversion\\tcontrol,\\tyou\\twill\\tcreate\\ta\\tcollection\\tof\\tfiles\\tthat\\trepresent\\ta\\tdiscrete\\tunit\\tof\\twork.\\tWe\\tbuild\\nthis\\tunit\\tin\\tthe\\tstaging\\tarea.\\nWhen\\twe\\tare\\tsatisfied\\twith\\tthe\\tunit\\tof\\twork\\twe\\thave\\tassembled,\\twe\\twill\\ttake\\ta\\tsnapshot\\tof\\teverything\\tin\\tthe\\tstaging\\narea.\\tThis\\tis\\tcalled\\ta\\tcommit.\\nWorking\\tLocally\\n22', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='bf8c8c22-6d52-4331-b95b-41af0226a0de', embedding=None, metadata={'page_label': '23', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"In\\torder\\tto\\tmake\\ta\\tfile\\tpart\\tof\\tthe\\tversion\\tcontrolled\\tdirectory\\twe\\twill\\tfirst\\tdo\\ta\\tgit\\tadd\\tand\\tthen\\twe\\twill\\tdo\\ta\\tgit\\tcommit.\\nLet's\\tdo\\tit\\tnow.\\n1\\n.\\t\\nFirst,\\tlet's\\tcheck\\tthe\\tstatus\\tof\\tour\\tworking\\ttree:\\t\\n\\t\\ngit\\tstatus\\n\\t\\n2\\n.\\t\\nMove\\tthe\\tfile\\tfrom\\tthe\\tworking\\ttree\\tto\\tthe\\tstaging\\tarea:\\t\\n\\t\\ngit\\tadd\\tmy-file.md\\n\\t\\n3\\n.\\t\\nLet's\\tsee\\twhat\\thappened:\\t\\n\\t\\ngit\\tstatus\\n\\t\\n4\\n.\\t\\nNow\\tlet's\\ttake\\tour\\tfirst\\tsnapshot:\\t\\n\\t\\ngit\\tcommit\\n\\t\\n5\\n.\\t\\nGit\\twill\\topen\\tyour\\tdefault\\ttext\\teditor\\tto\\trequest\\ta\\tcommit\\tmessage.\\tSimply\\ttype\\tyour\\tmessage\\ton\\tthe\\ttop\\tline\\tof\\nthe\\tfile.\\tAny\\tline\\twithout\\ta\\t#\\twill\\tbe\\tincluded\\tin\\tthe\\tcommit\\tmessage.\\n6\\n.\\t\\nSave\\tand\\tclose\\tthe\\tcommit\\tmessage\\n7\\n.\\t\\nLet's\\ttake\\tanother\\tlook\\tat\\tour\\trepository\\tstatus:\\t\\n\\t\\ngit\\tstatus\\n\\t\\nGood\\tcommit\\tmessages\\tshould:\\nBe\\tshort.\\t~50\\tcharacters\\tis\\tideal.\\nDescribe\\tthe\\tchange\\tintroduced\\tby\\tthe\\tcommit.\\nTell\\tthe\\tstory\\tof\\thow\\tyour\\tproject\\thas\\tevolved.\\nWorking\\tLocally\\n23\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e78828fb-e802-4b3e-99ce-6334ec1383a9', embedding=None, metadata={'page_label': '24', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Collaborating\\ton\\tYour\\tCode\\nNow\\tthat\\tyou\\thave\\tmade\\tsome\\tchanges\\tin\\tthe\\tproject\\tlocally,\\tlet's\\tlearn\\thow\\tto\\tpush\\tyour\\tchanges\\tback\\tto\\tthe\\tshared\\nclass\\trepository\\tfor\\tcollaboration.\\nPushing\\tYour\\tChanges\\tto\\tGitHub\\nIn\\tthis\\tcase,\\tour\\tremote\\tis\\tGitHub.com,\\tbut\\tthis\\tcould\\talso\\tbe\\tyour\\tcompany's\\tinternal\\tinstance\\tof\\tGitHub\\tEnterprise.\\nTo\\tpush\\tyour\\tchanges\\tto\\tGitHub,\\tyou\\twill\\tuse\\tthe\\tcommand:\\n$\\tgit\\tpush\\nWhen\\tyou\\tpush,\\tyou\\twill\\tbe\\tasked\\tto\\tenter\\tyour\\tGitHub\\tusername\\tand\\tpassword.\\tIf\\tyou\\twould\\tlike\\tGit\\tto\\nremember\\tyour\\tcredentials\\ton\\tthis\\tcomputer,\\tyou\\tcan\\tcache\\tyour\\tcredentials\\tusing:\\nWindows:\\t\\n\\t\\ngit\\tconfig\\t--global\\tcredential.helper\\twincred\\n\\t\\nMac:\\t\\n\\t\\ngit\\tconfig\\t--global\\tcredential.helper\\tosxkeychain\\n\\t\\ninclude\\nExploring\\ta\\tPull\\tRequest\\nNow\\tthat\\twe\\thave\\tcreated\\ta\\tPull\\tRequest,\\tlet's\\texplore\\ta\\tfew\\tof\\tthe\\tfeatures\\tthat\\tmake\\tPull\\tRequests\\tthe\\tcenter\\tof\\ncollaboration:\\nConversation\\tview\\nCollaborating\\ton\\tCode\\n24\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ca078821-a13a-4c63-bfdf-5005a0248f7d', embedding=None, metadata={'page_label': '25', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Similar\\tto\\tthe\\tdiscussion\\tthread\\ton\\tan\\tIssue,\\ta\\tPull\\tRequest\\tcontains\\ta\\tdiscussion\\tabout\\tthe\\tchanges\\tbeing\\tmade\\tto\\nthe\\trepository.\\tThis\\tdiscussion\\tis\\tfound\\tin\\tthe\\tConversation\\ttab\\tand\\talso\\tincludes\\ta\\trecord\\tof\\tall\\tof\\tthe\\tcommits\\tmade\\non\\tthe\\tbranch\\tas\\twell\\tas\\tassignments,\\tlabels\\tand\\treviews\\tthat\\thave\\tbeen\\tapplied\\tto\\tthe\\tpull\\trequest.\\nCommits\\tview\\nThe\\tcommits\\tview\\tcontains\\tmore\\tdetailed\\tinformation\\tabout\\twho\\thas\\tmade\\tchanges\\tto\\tthe\\tfiles.\\tClicking\\teach\\tcommit\\nID\\twill\\tallow\\tyou\\tto\\tsee\\tthe\\tchanges\\tapplied\\tin\\tthat\\tspecific\\tcommit.\\nFiles\\tchanged\\tview\\nThe\\tFiles\\tchanged\\tview\\tallows\\tyou\\tto\\tsee\\tcumulative\\teffect\\tof\\tall\\tthe\\tchanges\\tmade\\ton\\tthe\\tbranch.\\tWe\\tcall\\tthis\\tthe\\n\\t\\ndiff\\n\\t\\n.\\tOur\\tdiff\\tisn't\\tvery\\tinteresting\\tyet,\\tbut\\tas\\twe\\tmake\\tchanges\\tyour\\tdiff\\twill\\tbecome\\tvery\\tcolorful.\\nCode\\tReview\\tin\\tPull\\tRequests\\nTo\\tprovide\\tfeedback\\ton\\tproposed\\tchanges,\\tGitHub\\toffers\\tthree\\tlevels\\tof\\tcommenting:\\nGeneral\\tConversation\\nYou\\tcan\\tprovide\\tgeneral\\tcomments\\ton\\tthe\\tPull\\tRequest\\twithin\\tthe\\t\\nConversation\\n\\ttab.\\nLine\\tComments\\nIn\\tthe\\tfiles\\tchanged\\tview,\\tyou\\tcan\\thover\\tover\\ta\\tline\\tto\\tsee\\ta\\tblue\\t\\n\\t\\n+\\n\\t\\n\\ticon.\\tClicking\\tthis\\ticon\\twill\\tallow\\tyou\\tto\\tenter\\ta\\ncomment\\ton\\ta\\tspecific\\tline.\\tThese\\tline\\tlevel\\tcomments\\tare\\ta\\tgreat\\tway\\tto\\tgive\\tadditional\\tcontext\\ton\\trecommended\\nchanges.\\tThey\\twill\\talso\\tbe\\tdisplayed\\tin\\tthe\\tconversation\\tview.\\nReview\\nWhen\\tyou\\tare\\tmaking\\tline\\tcomments,\\tyou\\tcan\\talso\\tchoose\\tto\\t\\nStart\\ta\\tReview\\n.\\tWhen\\tyou\\tcreate\\ta\\treview,\\tyou\\tcan\\ngroup\\tmany\\tline\\tcomments\\ttogether\\twith\\ta\\tgeneral\\tmessage:\\tComments,\\tApprove,\\tor\\tRequest\\tChanges.\\tReviews\\nhave\\tspecial\\tpower\\tin\\tGitHub\\twhen\\tused\\tin\\tconjunction\\twith\\tprotected\\tbranches.\\nActivity:\\tCode\\tReview\\nOne\\tof\\tthe\\tbest\\tways\\tto\\tensure\\tcode\\tquality\\tis\\tto\\tmake\\tpeer\\treviews\\ta\\tpart\\tof\\tevery\\tPull\\tRequest.\\tLet's\\treview\\tyour\\npartner's\\tcode\\tnow:\\n1\\n.\\t\\nClick\\tthe\\t\\nPull\\tRequest\\n\\ttab.\\n2\\n.\\t\\nUse\\tthe\\t\\nAuthor\\n\\tdrop\\tdown\\tto\\tlocate\\tyour\\tpartner's\\tpull\\trequest.\\n3\\n.\\t\\nClick\\tthe\\t\\nFiles\\tChanged\\n\\ttab.\\n4\\n.\\t\\nHover\\tover\\ta\\tsingle\\tline\\tin\\tthe\\tfile\\tto\\tsee\\tthe\\tblue\\t+.\\tClick\\tthe\\t+\\tto\\tadd\\ta\\tline\\tcomment.\\n5\\n.\\t\\nComment\\ton\\tthe\\tline\\tand\\tclick\\t\\nStart\\ta\\treview\\n.\\n6\\n.\\t\\nAdd\\tadditional\\tline\\tcomments\\tto\\tthe\\tpull\\trequest.\\n7\\n.\\t\\nClick\\t\\nReview\\tchanges\\n\\tin\\tthe\\ttop\\tright\\tcorner.\\n8\\n.\\t\\nChoose\\twhether\\tto\\t\\nApprove\\n\\tor\\t\\nRequest\\tchanges\\n9\\n.\\t\\nEnter\\ta\\tgeneral\\tcomment\\tfor\\tthe\\treview.\\n10\\n.\\t\\nClick\\t\\nSubmit\\treview\\n11\\n.\\t\\nClick\\tthe\\t\\nConversation\\n\\tview\\tto\\tcheck\\tout\\tyour\\tcompleted\\treview.\\nCollaborating\\ton\\tCode\\n25\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='30985a34-6081-45a2-a407-0ac1fff1afcf', embedding=None, metadata={'page_label': '26', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Collaborating\\ton\\tCode\\n26', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d6bbf3af-3e8b-4600-93f8-7c6bad4a6df8', embedding=None, metadata={'page_label': '27', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Editing\\tFiles\\ton\\tGitHub\\nSince\\tyou\\tcreated\\tthe\\tpull\\trequest,\\tyou\\twill\\tbe\\tnotified\\twhen\\tsomeone\\tadds\\ta\\tcomment\\tor\\ta\\treview.\\tSometimes,\\tthe\\nreviewer\\twill\\task\\tyou\\tto\\tmake\\ta\\tchange\\tto\\tthe\\tfile\\tyou\\tjust\\tcreated.\\tLet's\\tsee\\thow\\tGitHub\\tmakes\\tthis\\teasy.\\nEditing\\ta\\tFile\\ton\\tGitHub\\nTo\\tedit\\ta\\tpull\\trequest\\tfile,\\tyou\\twill\\tneed\\tto\\taccess\\tthe\\t\\nFiles\\tChanged\\n\\tview.\\n1\\n.\\t\\nClick\\tthe\\t\\npencil\\ticon\\n\\tin\\tthe\\ttop\\tright\\tcorner\\tof\\tthe\\tdiff\\tto\\tedit\\tthe\\tfile\\tusing\\tthe\\tGitHub\\tfile\\teditor.\\n2\\n.\\t\\nMake\\tchanges\\tto\\tthe\\tfile\\tbased\\ton\\tthe\\tcomments\\tfrom\\tyour\\treviewer\\tor\\tyour\\tpersonal\\tperspective.\\nCommitting\\tChanges\\ton\\tGitHub\\nOnce\\tyou\\thave\\tmade\\tsome\\tchanges\\tto\\tyour\\tfile,\\tyou\\twill\\tneed\\tto\\tcreate\\ta\\tnew\\tcommit.\\n1\\n.\\t\\nScroll\\tto\\tthe\\tbottom\\tof\\tthe\\tpage\\tto\\tfind\\tthe\\t\\nCommit\\tchanges\\n\\tdialog\\tbox.\\n2\\n.\\t\\nType\\ta\\t\\nCommit\\tmessage\\n.\\n3\\n.\\t\\nChoose\\tthe\\toption\\tto\\t\\nCommit\\tdirectly\\tto\\tyour\\tbranch\\n.\\n4\\n.\\t\\nClick\\t\\nCommit\\tchanges\\n.\\nActivity:\\tEditing\\tFiles\\tin\\tPull\\tRequests\\nGo\\tback\\tto\\tyour\\tPull\\tRequest\\tand\\tmake\\tthe\\tedits\\trequested\\tby\\tyour\\tcollaborators.\\nEditing\\ton\\tGitHub\\n27\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f9aeaec7-a36f-4d68-85cf-99e19b584a21', embedding=None, metadata={'page_label': '28', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Merging\\tPull\\tRequests\\nNow\\tthat\\tyou\\thave\\tmade\\tthe\\trequested\\tchanges,\\tyour\\tpull\\trequest\\tshould\\tbe\\tready\\tto\\tmerge.\\nMerge\\tExplained\\nWhen\\tyou\\tmerge\\tyour\\tbranch,\\tyou\\tare\\ttaking\\tthe\\tcontent\\tand\\thistory\\tfrom\\tyour\\tfeature\\tbranch\\tand\\tadding\\tit\\tto\\tthe\\ncontent\\tand\\thistory\\tof\\tthe\\t\\n\\t\\nmaster\\n\\t\\n\\tbranch.\\nMany\\tproject\\tteams\\thave\\testablished\\trules\\tabout\\twho\\tshould\\tmerge\\ta\\tpull\\trequest.\\nSome\\tsay\\tit\\tshould\\tbe\\tthe\\tperson\\twho\\tcreated\\tthe\\tpull\\trequest\\tsince\\tthey\\twill\\tbe\\tthe\\tones\\tto\\tdeal\\twith\\tany\\tissues\\nresulting\\tfrom\\tthe\\tmerge.\\nOthers\\tsay\\tit\\tshould\\tbe\\ta\\tsingle\\tperson\\twithin\\tthe\\tproject\\tteam\\tto\\tensure\\tconsistency.\\nStill\\tothers\\tsay\\tit\\tcan\\tbe\\tanyone\\tother\\tthan\\tthe\\tperson\\twho\\tcreated\\tthe\\tpull\\trequest\\tto\\tensure\\tat\\tleast\\tone\\treview\\nhas\\ttaken\\tplace.\\nThis\\tis\\ta\\tdiscussion\\tyou\\tshould\\thave\\twith\\tthe\\tother\\tmembers\\tof\\tyour\\tteam.\\nMerging\\tYour\\tPull\\tRequest\\nLet's\\ttake\\ta\\tlook\\tat\\thow\\tyou\\tcan\\tmerge\\tthe\\tpull\\trequest.\\n1\\n.\\t\\nNavigate\\tto\\tyour\\tPull\\tRequest\\t(HINT:\\tUse\\tthe\\tAuthor\\tor\\tAssignee\\tdrop\\tdowns\\tto\\tfind\\tyour\\tPull\\tRequest\\tquickly)\\n2\\n.\\t\\nClick\\t\\nConversation\\n3\\n.\\t\\nScroll\\tto\\tthe\\tbottom\\tof\\tthe\\tPull\\tRequest\\tand\\tclick\\tthe\\t\\nMerge\\tpull\\trequest\\n\\tbutton\\n4\\n.\\t\\nClick\\t\\nConfirm\\tmerge\\n5\\n.\\t\\nClick\\t\\nDelete\\tbranch\\n6\\n.\\t\\nClick\\t\\nIssues\\n\\tand\\tconfirm\\tyour\\toriginal\\tissue\\thas\\tbeen\\tclosed\\nGitHub\\toffers\\tthree\\tdifferent\\tmerge\\tstrategies\\tfor\\tPull\\tRequests:\\nCreate\\ta\\tmerge\\tcommit:\\n\\tThis\\tis\\tthe\\ttraditional\\toption\\tthat\\twill\\tperform\\ta\\tstandard\\trecursive\\tmerge.\\tA\\tnew\\ncommit\\twill\\tbe\\tadded\\tthat\\tshows\\tthe\\tpoint\\twhen\\tthe\\ttwo\\tbranches\\twere\\tmerged\\ttogether.\\nSquash\\tand\\tmerge:\\n\\tThis\\toption\\twill\\ttake\\tall\\tof\\tthe\\tcommits\\ton\\tyour\\tbranch\\tand\\tcompress\\tthem\\tinto\\ta\\nsingle\\tcommit.\\tThe\\tcommit\\tmessages\\twill\\tbe\\tpreserved\\tin\\tthe\\textended\\tcommit\\tmessage\\tfor\\tthe\\tcommit,\\nbut\\tthe\\tindividual\\tcommits\\twill\\tbe\\tlost.\\nRebase\\tand\\tmerge:\\n\\tThis\\toption\\twill\\ttake\\tall\\tof\\tthe\\tcommits\\tand\\treplay\\tthem\\tas\\tif\\tthey\\tjust\\thappened.\\tThis\\nallows\\tGitHub\\tto\\tperform\\ta\\tfast\\tforward\\tmerge\\t(and\\tavoids\\tthe\\taddition\\tof\\tthe\\tmerge\\tcommit).\\nUpdating\\tYour\\tLocal\\tRepository\\nMerging\\tPull\\tRequests\\n28\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d7def3f4-08fc-4e1e-a4b4-578582342b8c', embedding=None, metadata={'page_label': '29', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"When\\tyou\\tmerged\\tyour\\tPull\\tRequest,\\tyou\\tdeleted\\tthe\\tbranch\\ton\\tGitHub,\\tbut\\tthis\\twill\\tnot\\tautomatically\\tupdate\\tyour\\nlocal\\tcopy\\tof\\tthe\\trepository.\\tLet's\\tgo\\tback\\tto\\tour\\tcommand\\tline\\tapplication\\tand\\tget\\teverything\\tin\\tsync.\\nFirst,\\twe\\tneed\\tto\\tget\\tthe\\tchanges\\twe\\tmade\\ton\\tGitHub\\tinto\\tour\\tlocal\\tcopy\\tof\\tthe\\trepository:\\n1\\n.\\t\\nStart\\tby\\tswitching\\tback\\tto\\tyour\\tdefault\\tbranch:\\t\\n\\t\\ngit\\tcheckout\\tmaster\\n\\t\\n2\\n.\\t\\nRetrieve\\tall\\tof\\tthe\\tchanges\\tfrom\\tGitHub:\\t\\n\\t\\ngit\\tpull\\n\\t\\n\\t\\ngit\\tpull\\n\\t\\n\\tis\\ta\\tcombination\\tcommand\\tthat\\tretrieves\\tall\\tof\\tthe\\tchanges\\tfrom\\tGitHub\\tand\\tthen\\tupdates\\tthe\\tbranch\\tyou\\nare\\tcurrently\\ton\\tto\\tinclude\\tthe\\tchanges\\tfrom\\tthe\\tremote.\\tThe\\ttwo\\tseparate\\tcommands\\tbeing\\trun\\tare\\t\\n\\t\\ngit\\tfetch\\n\\t\\n\\tand\\n\\t\\ngit\\tmerge\\n\\t\\nCleaning\\tUp\\tthe\\tUnneeded\\tBranches\\nIf\\tyou\\ttype\\t\\n\\t\\ngit\\tbranch\\t--all\\n\\t\\n\\tyou\\twill\\tprobably\\tsee\\tthat,\\teven\\tthough\\tyou\\tdeleted\\tyour\\tbranch\\ton\\tthe\\tremote,\\tit\\tis\\tstill\\nlisted\\tin\\tyour\\tlocal\\tcopy\\tof\\tthe\\trepository,\\tboth\\tas\\ta\\tlocal\\tbranch\\tand\\tas\\ta\\tread-only\\tremote\\ttracking\\tbranch.\\tLet's\\tget\\nrid\\tof\\tthose\\textra\\tbranches.\\n1\\n.\\t\\nTake\\ta\\tlook\\tat\\tyour\\tlocal\\tbranches:\\t\\n\\t\\ngit\\tbranch\\t--all\\n\\t\\n2\\n.\\t\\nLet's\\tsee\\twhich\\tbranches\\tare\\tsafe\\tto\\tdelete:\\t\\n\\t\\ngit\\tbranch\\t--merged\\n\\t\\n3\\n.\\t\\nDelete\\tthe\\tlocal\\tbranch:\\t\\n\\t\\ngit\\tbranch\\t-d\\t<branch-name>\\n\\t\\n4\\n.\\t\\nTake\\tanother\\tlook\\tat\\tthe\\tlist:\\t\\n\\t\\ngit\\tbranch\\t--all\\n\\t\\n5\\n.\\t\\nYour\\tlocal\\tbranch\\tis\\tgone\\tbut\\tthe\\tremote\\ttracking\\tbranch\\tis\\tstill\\tthere.\\tDelete\\tthe\\tremote\\ttracking\\tbranch:\\t\\n\\t\\ngit\\npull\\t--prune\\n\\t\\nAdding\\tthe\\t\\n\\t\\n--merged\\n\\t\\n\\toption\\tto\\tthe\\t\\n\\t\\ngit\\tbranch\\n\\t\\n\\tcommand\\tallows\\tyou\\tto\\tsee\\twhich\\tbranches\\tdo\\tnot\\tcontain\\nunique\\twork\\twhen\\tcompared\\tto\\tthe\\tchecked\\tout\\tbranch.\\tIn\\tthis\\tcase,\\tsince\\twe\\tare\\tchecked\\tout\\tto\\tmaster,\\twe\\nwill\\tuse\\tthis\\tcommand\\tto\\tensure\\tall\\tof\\tthe\\tchanges\\ton\\tour\\tfeature\\tbranch\\thave\\tbeen\\tmerged\\tto\\tproduction\\nbefore\\twe\\tdelete\\tthe\\tbranch.\\nIf\\tyou\\twould\\tlike\\tpruning\\tof\\tthe\\tremote\\ttracking\\tbranches\\tto\\tbe\\tset\\tas\\tyour\\tdefault\\tbehavior\\twhen\\tyou\\tpull,\\tyou\\tcan\\nuse\\tthe\\tfollowing\\tconfiguration\\toption:\\t\\n\\t\\ngit\\tconfig\\t--global\\tfetch.prune\\ttrue\\n\\t\\n.\\nMerging\\tPull\\tRequests\\n29\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ced41f58-6ebf-434a-b857-e8e99deb2103', embedding=None, metadata={'page_label': '30', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Viewing\\tLocal\\tProject\\tHistory\\nIn\\tthis\\tsection,\\tyou\\twill\\tdiscover\\tcommands\\tfor\\tviewing\\tthe\\thistory\\tof\\tyour\\tproject.\\nUsing\\tGit\\tLog\\nWhen\\tyou\\tclone\\ta\\trepository,\\tyou\\treceive\\tthe\\thistory\\tof\\tall\\tof\\tthe\\tcommits\\tmade\\tin\\tthat\\trepository.\\tThe\\tlog\\tcommand\\nallows\\tus\\tto\\tview\\tthat\\thistory\\ton\\tour\\tlocal\\tmachine.\\nLet's\\ttake\\ta\\tlook\\tat\\tsome\\tof\\tthe\\toption\\tswitches\\tyou\\tcan\\tuse\\tto\\tcustomize\\tyour\\tview\\tof\\tthe\\tproject\\thistory.\\tYou\\tcan\\nfind\\tthese\\toptions,\\tand\\tmany\\tmore,\\ton\\t\\ngit-scm.com\\n.\\t\\n(Note:\\t\\n\\t\\n--graph\\n\\t\\n\\tis\\tdefault\\ton\\tmost\\tGit\\tBash\\tfor\\tWindows\\nterminals.)\\n$\\tgit\\t\\nlog\\n$\\tgit\\t\\nlog\\n\\t--oneline\\n$\\tgit\\t\\nlog\\n\\t--oneline\\t--graph\\n$\\tgit\\t\\nlog\\n\\t--oneline\\t--graph\\t--decorate\\n$\\tgit\\t\\nlog\\n\\t--oneline\\t--graph\\t--decorate\\t--all\\n$\\tgit\\t\\nlog\\n\\t--stat\\n$\\tgit\\t\\nlog\\n\\t--patch\\nUse\\tthe\\tup\\tand\\tdown\\tarrows\\tor\\tpress\\tenter\\tto\\tview\\tadditional\\tlog\\tentries.\\tType\\t\\n\\t\\nq\\n\\t\\n\\tto\\tquit\\tviewing\\tthe\\tlog\\tand\\nreturn\\tto\\tthe\\tcommand\\tprompt.\\nLocal\\tHistory\\n30\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ae5c2a3f-d6e9-4a62-b4e9-b05d2bf16f69', embedding=None, metadata={'page_label': '31', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Streamlining\\tYour\\tWorkflow\\twith\\tAliases\\nSo\\tfar\\twe\\thave\\tlearned\\tquite\\ta\\tfew\\tcommands.\\tSome,\\tlike\\tthe\\tlog\\tcommands,\\tcan\\tbe\\tlong\\tand\\ttedious\\tto\\ttype.\\tIn\\tthis\\nsection,\\tyou\\twill\\tlearn\\thow\\tto\\tcreate\\tcustom\\tshortcuts\\tfor\\tGit\\tcommands.\\nCreating\\tCustom\\tAliases\\nAn\\talias\\tallows\\tyou\\tto\\ttype\\ta\\tshortened\\tcommand\\tto\\trepresent\\ta\\tlong\\tstring\\ton\\tthe\\tcommand\\tline.\\nFor\\texample,\\tlet\\'s\\tcreate\\tan\\talias\\tfor\\tthe\\tlog\\tcommand\\twe\\tlearned\\tearlier.\\nOriginal\\tCommand\\n$\\tgit\\t\\nlog\\n\\t--oneline\\t--graph\\t--decorate\\t--all\\nCreating\\tthe\\tAlias\\n$\\tgit\\tconfig\\t--global\\talias.lol\\t\\n\"log\\t--oneline\\t--graph\\t--decorate\\t--all\"\\nUsing\\tthe\\tAlias\\n$\\tgit\\tlol\\nExplore\\tOther\\tHelpful\\tAliases\\nCheck\\tout\\tthese\\tresources\\tfor\\ta\\tlist\\tof\\tcommon\\taliases:\\ngit-scm.com/book/en/v2/Git-Basics-Git-Aliases\\n\\tA\\thelpful\\toverview\\tof\\tsome\\tof\\tthe\\tmost\\tcommon\\tgit\\taliases.\\nWe\\talso\\tencourage\\tyou\\tto\\tread\\tthrough\\tthese\\tthree\\tblog\\tposts\\tby\\tGitHub\\tdeveloper\\tPhil\\tHack.\\tHis\\ttips\\tare\\treferenced\\nthroughout\\tthe\\tmanual.\\nGitHub\\tFlow\\tAliases\\nGit\\tMigrate\\nGit\\tAlias\\tOpen\\tURL\\nPro\\tTip\\t#\\t1:\\t\\nTo\\tedit\\taliases\\tby\\thand,\\tyou\\tcan\\topen\\tthe\\tgitconfig\\tfile\\twith\\tyour\\tdefault\\teditor.\\ngit\\tconfig\\t--global\\talias.ec\\t\"config\\t--global\\t-e\"\\nPro\\tTip\\t#\\t2:\\tTo\\tcheckout\\tto\\tanother\\tbranch,\\tyou\\tcan\\tmake\\ta\\tquick\\tshortcut.\\ngit\\tconfig\\t--global\\talias.ch\\t\"checkout\"\\nPro\\tTip\\t#\\t3:\\tTo\\tcheckout\\tto\\ta\\tbrand\\tnew\\tbranch,\\tyou\\tcan\\teasily\\textend\\tyour\\texisting\\tshortcut.\\ngit\\tconfig\\t--global\\talias.cob\\t\"checkout\\t-b\"\\nPro\\tTip\\t#\\t4:\\tYou\\tcan\\tcreate\\taliases\\tthat\\tonly\\tcall\\tone\\tcommand.\\ngit\\tconfig\\t--global\\talias.s\\t\"status\\t-s\"\\nStreamline\\tWorkflow\\twith\\tAliases\\n31', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='736ab333-370c-4304-b499-d45b464f8aa9', embedding=None, metadata={'page_label': '32', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Pro\\tTip\\t#\\t5:\\tClean\\tup\\tbranches\\tquickly\\tand\\teasily.\\n$\\tgit\\tconfig\\talias.dlb\\t\\'!git\\tcheckout\\t<DEFAULT-BRANCH>\\t&&\\tgit\\tpull\\t--prune\\t&&\\tgit\\tbranch\\t--merged\\t|\\tgrep\\t-v\\t\"\\\\*\\n\"\\t|\\txargs\\t-n\\t1\\tgit\\tbranch\\t-d\\'\\nStreamline\\tWorkflow\\twith\\tAliases\\n32', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='366ebc28-20a5-4c18-b396-696e0b3f2f6c', embedding=None, metadata={'page_label': '33', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='What\\tis\\ta\\tmerge\\tconflict?\\nWhen\\tyou\\twork\\twith\\ta\\tteam\\t(and\\teven\\tsometimes\\twhen\\tyou\\tare\\tworking\\talone)\\tyou\\twill\\toccasionally\\tcreate\\tmerge\\nconflicts.\\tAt\\tfirst,\\tmerge\\tconflicts\\tcan\\tbe\\tintimidating,\\tbut\\tresolving\\tthem\\tis\\tactually\\tquite\\teasy.\\tIn\\tthis\\tsection\\tyou\\twill\\nlearn\\thow!\\nThese\\texercises\\twill\\tfocus\\ton\\tthe\\ttechnical\\t\"how\".\\tIn\\treal\\tmerge\\tconflicts,\\tit\\'s\\timportant\\tto\\tknow\\twho\\tto\\task\\tin\\tcase\\nyou\\taren\\'t\\tsure\\thow\\tto\\tresolve\\tthe\\tconflict\\ton\\tyour\\town.\\tUsually\\tit\\'s\\ta\\tgood\\tidea\\tto\\task\\tthe\\tperson\\twho\\tmade\\tthe\\nconflicting\\tchanges,\\tor\\tsomeone\\twho\\tis\\ta\\tCODEOWNER\\ton\\tthe\\tfile.\\nLocal\\tMerge\\tConflicts\\nMerge\\tconflicts\\tare\\ta\\tnatural\\tand\\tminor\\tside\\teffect\\tof\\tdistributed\\tversion\\tcontrol.\\tThey\\tonly\\thappen\\tunder\\tvery\\tspecific\\ncircumstances.\\nChanges\\tto\\tthe\\tsame\\t\"hunk\"\\tof\\tthe\\tsame\\tfile\\nTwo\\tdifferent\\tbranches\\nChanges\\ton\\tboth\\tbranches\\thappened\\tsince\\tthe\\tbranches\\thave\\tdiverged\\nDefining\\ta\\tmerge\\tconflict\\n33', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='c24480d4-c00f-4e6d-9141-7fe2d6855625', embedding=None, metadata={'page_label': '34', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Resolving\\ta\\tMerge\\tConflict\\nLet's\\ttry\\tto\\tcreate\\ta\\tmerge\\tconflict,\\tand\\tfix\\tit\\ttogether.\\tYou\\tand\\ta\\tpartner\\twill\\teach\\tcreate\\tseparate\\tbranches,\\tcreate\\ta\\nfile\\twith\\tthe\\tsame\\tname,\\tand\\tthen\\ttry\\tto\\tmerge.\\tThe\\tfirst\\twill\\tmerge\\tcleanly,\\tthe\\tsecond\\twill\\thave\\ta\\tmerge\\tconflict.\\nWork\\ttogether\\tto\\tresolve\\tthe\\tmerge\\tconflict.\\n1\\n.\\t\\nIn\\tour\\tclass\\trepository,\\tcreate\\tthe\\tbranch\\tthat\\tyou\\twill\\tbe\\tworking\\ton\\tand\\tname\\tit\\tsomething\\tmemorable\\tlike\\n\\t\\nUSERNAME-conflict\\n\\t\\n.\\n2\\n.\\t\\nChoose\\ta\\tfile\\tthat\\tboth\\tyou\\tand\\tyour\\tpartner\\twill\\tedit.\\t(One\\tof\\tyour\\tfiles\\tfrom\\tearlier\\twould\\twork\\twell.)\\tOn\\tyour\\nbranch,\\tedit\\tthat\\tfile.\\tThe\\tfile\\tname\\tmust\\tbe\\tthe\\tsame\\tfile\\tname\\tthat\\tyour\\tpartner\\tuses.\\tMake\\tsure\\tthe\\tcontent\\ninside\\tof\\tthe\\tfile\\tis\\tdifferent,\\tand\\tthat\\tneither\\tfile\\tis\\tempty.\\n3\\n.\\t\\nCreate\\ta\\tpull\\trequest\\tin\\tthe\\tclass\\trepository\\twith\\t\\n\\t\\nbase:\\tmaster\\n\\t\\n\\tand\\t\\n\\t\\ncompare:\\tUSERNAME-conflict\\n\\t\\n.\\n4\\n.\\t\\nYou\\twill\\tsee\\tthat\\tthe\\t\\nfirst\\n\\tpull\\trequest\\tcan\\tmerge\\twell.\\n5\\n.\\t\\nWhen\\tyou\\tsee\\tthe\\tmerge\\tconflict\\tin\\tthe\\t\\nsecond\\n\\tpull\\trequest,\\twork\\ttogether\\tto\\tresolve\\tthe\\tmerge\\tconflict.\\ni\\n.\\t\\nWorking\\tlocally,\\tmerge\\t\\n\\t\\nmaster\\n\\t\\n\\tinto\\tthe\\tfeature\\tbranch.\\nii\\n.\\t\\nWhen\\tyou\\tsee\\tthere's\\ta\\tconflict,\\tthat's\\tOK!\\tThe\\tfiles\\tthat\\thave\\tconflicts\\tare\\tlisted\\tunder\\t\\n\\t\\nUnmerged\\tPaths\\n\\t\\n.\\nType\\t\\n\\t\\ngit\\tstatus\\n\\t\\n\\tto\\tverify\\twhich\\tfile\\thas\\tthe\\tconflict.\\niii\\n.\\t\\nOpen\\tthat\\tfile\\tin\\tyour\\ttext\\teditor,\\tand\\tlook\\tfor\\tthe\\tmerge\\tconflict\\tmarkers.\\t(\\n\\t\\n<<<<<<<\\n\\t\\n,\\t\\n\\t\\n=======\\n\\t\\n,\\t\\n\\t\\n>>>>>>>\\n\\t\\n)\\niv\\n.\\t\\nBoth\\tbranches'\\tversions\\tof\\tcode\\tare\\tpresent\\t-\\tpick\\twhich\\tone\\tyou\\twant\\tto\\tkeep,\\tand\\tsave\\tthe\\tchanges.\\nv\\n.\\t\\nAdd\\tand\\tcommit\\tthe\\tsaved\\tchanges\\tto\\tresolve\\tthe\\tmerge\\tconflict.\\nvi\\n.\\t\\nPush\\tthe\\tfeature\\tbranch\\tup\\tto\\tthe\\tremote,\\tand\\tsee\\tthe\\tresolution\\tin\\tthe\\tpull\\trequest.\\n6\\n.\\t\\nMerge\\tthe\\tpull\\trequest.\\nWhat\\tis\\ta\\tmerge\\tmessage?\\tIn\\tthis\\texample,\\twe\\tare\\tdoing\\ta\\trecursive\\tmerge.\\tA\\trecursive\\tmerge\\tcreates\\ta\\tnew\\ncommit\\tthat\\tpermanently\\trecords\\tthe\\tpoint\\tin\\ttime\\twhen\\tthese\\ttwo\\tbranches\\twere\\tmerged\\ttogether.\\tWe\\twill\\ttalk\\nmore\\tabout\\tGit's\\tmerge\\tstrategies\\ta\\tlittle\\tlater.\\nResolving\\tmerge\\tConflicts\\n34\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='6aae9853-69d6-4f17-922b-38948ccc4018', embedding=None, metadata={'page_label': '35', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Project:\\tGitHub\\tGames\\nIn\\tthis\\tsection,\\twe\\twill\\twork\\ton\\ta\\tproject\\trepository\\tcalled\\t\\n\\t\\ngithub-games\\n\\t\\n.\\nA\\t\\n\\t\\ngithub-games\\n\\t\\n\\trepository\\thas\\tbeen\\tcreated\\tfor\\tyou\\tin\\tthe\\tgithubschool\\torganization.\\tYou\\tcan\\taccess\\tthe\\trepository\\nat\\t\\n\\t\\nhttps://github.com/githubschool/github-games-USERNAME\\n\\t\\n.\\nIf\\tyou\\'re\\tusing\\tthe\\tFork\\tand\\tPull\\tWorkflow,\\t\\ndon\\'t\\tforget\\tto\\tlook\\tin\\tthe\\tappendix\\tfor\\ta\\tmore\\tthorough\\texplanation\\n.\\nWorkflow\\tReview:\\tUpdating\\tthe\\tREADME.md\\nNow\\tyou\\twill\\tpractice\\tthe\\tGitHub\\tFlow\\tfrom\\tbeginning\\tto\\tend\\tby\\tupdating\\tthe\\tlink\\tin\\tthe\\tREADME\\tto\\tpoint\\tto\\tyour\\tfork\\nof\\tthe\\trepository.\\nRemember,\\tyour\\tcopy\\tof\\tthe\\twebsite\\twill\\tbe\\trendered\\tat\\t\\n\\t\\nhttps://githubschool.github.io/github-games-\\nUSERNAME\\n\\t\\n.\\nThis\\tlink\\talso\\tappears\\tin\\tthe\\trepository\\tdescription.\\tIt\\tis\\ta\\tgood\\tidea\\tto\\tedit\\tthe\\twebsite\\tURL\\tin\\tthe\\tdescription\\nso\\tyou\\tcan\\teasily\\taccess\\tyour\\tgame.\\nIf\\tyou\\tclick\\tthe\\tlink,\\tyou\\twill\\tsee\\tthe\\ttext\\tin\\tthe\\t\\n\\t\\nREADME.md\\n\\t\\n.\\tWe\\thave\\tintentionally\\tbroken\\tthis\\trepository\\tso\\twe\\ncan\\tfix\\tit\\ttogether.\\nSince\\tthis\\tis\\ta\\treview,\\twe\\thave\\twritten\\tthese\\tsteps\\tat\\ta\\thigh\\tlevel.\\tAs\\twe\\tcomplete\\tthe\\treview,\\twe\\twill\\tshow\\tyou\\ta\\tfew\\nshortcuts\\tfor\\tthe\\tcommands\\tyou\\tlearned\\tin\\tthe\\tprevious\\tactivity:\\n1\\n.\\t\\nClone\\tyour\\tcopy\\tof\\tthe\\trepository:\\t\\n\\t\\ngit\\tclone\\thttps://github.com/githubschool/github-games-USERNAME.git\\n\\t\\n2\\n.\\t\\nCreate\\ta\\tnew\\tbranch\\tcalled\\t\\n\\t\\nreadme-update\\n\\t\\n:\\t\\n\\t\\ngit\\tcheckout\\t-b\\treadme-update\\n\\t\\n3\\n.\\t\\nEdit\\tthe\\tURL\\tin\\tthe\\tREADME.md.\\n4\\n.\\t\\nCommit\\tthe\\tchanges\\tto\\tyour\\tbranch.\\n5\\n.\\t\\nPush\\tyour\\tbranch\\tto\\tGitHub:\\t\\n\\t\\ngit\\tpush\\t-u\\torigin\\treadme-update\\n\\t\\n6\\n.\\t\\nCreate\\ta\\tPull\\tRequest\\t\\nin\\tyour\\trepository\\n\\t(base:\\t\\n\\t\\nmaster\\n\\t\\n,\\tcompare:\\t\\n\\t\\nreadme-update\\n\\t\\n)\\n7\\n.\\t\\nMerge\\tyour\\tPull\\tRequest.\\n8\\n.\\t\\nDelete\\tthe\\tbranch\\ton\\tGitHub.\\n9\\n.\\t\\nUpdate\\tyour\\tlocal\\tcopy\\tof\\tthe\\trepository:\\t\\n\\t\\ngit\\tpull\\t--prune\\n\\t\\n\\t\\ngit\\tcheckout\\t-b\\treadme-update\\n\\t\\n\\tis\\ta\\tshortcut\\tcommand\\tthat\\tallows\\tyou\\tto\\tcombine\\tthe\\tcreation\\tof\\tthe\\tbranch\\t(\\n\\t\\ngit\\nbranch\\treadme-update\\n\\t\\n)\\tand\\tchecking\\tout\\tto\\tthat\\tbranch\\t(\\n\\t\\ngit\\tcheckout\\treadme-update\\n\\t\\n).\\tThe\\t\\n\\t\\n-b\\n\\t\\n\\ttells\\tGit\\tto\\tcreate\\ta\\nnew\\tbranch.\\n\\t\\ngit\\tpush\\t-u\\torigin\\treadme-update\\n\\t\\n\\tis\\tthe\\tslightly\\tlonger\\tversion\\tof\\tthe\\tpush\\tcommand\\tthat\\tshould\\tbe\\tused\\twhen\\nyou\\tpush\\ta\\tnew\\tbranch\\tfor\\tthe\\tfirst\\ttime.\\nThe\\t\\n\\t\\n-u\\n\\t\\n\\tis\\tthe\\tshort\\tversion\\tof\\tthe\\toption\\t\\n\\t\\n--set-upstream\\n\\t\\n.\\tThis\\toption\\ttells\\tGit\\tto\\tcreate\\ta\\trelationship\\tbetween\\nour\\tlocal\\tbranch\\tand\\ta\\tremote\\ttracking\\tbranch\\tof\\tthe\\tsame\\tname.\\\\\\nYou\\tonly\\tneed\\tto\\tuse\\tthis\\tlong\\tcommand\\tthe\\tfirst\\ttime\\tyou\\tpush\\ta\\tnew\\tbranch.\\tAfter\\tthat,\\tyou\\tcan\\tsimply\\tuse\\n\\t\\ngit\\tpush\\n\\t\\n.\\n\\t\\ngit\\tconfig\\t--global\\talias.bclean\\t\"!f()\\t{\\tbranches=$(git\\tbranch\\t--merged\\t${1-master}\\t|\\tgrep\\t-v\\t\"\\t${1-master}$\");\\t[\\t-\\nz\\t\\\\\"$branches\\\\\"\\t]\\t||\\tgit\\tbranch\\t-d\\t$branches;\\t};\\tf\"\\n\\t\\n\\tcould\\tbe\\thelpful\\there.\\t\\nTake\\ta\\tpeek\\tin\\tthe\\tappendix\\tto\\tlearn\\nhow!\\nWorkflow\\tReview\\n35', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='515c85fb-c892-4d6a-bf20-55b07543bcfb', embedding=None, metadata={'page_label': '36', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Workflow\\tReview\\n36', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='0a2421ac-b2be-4796-bed0-41d0d2ace874', embedding=None, metadata={'page_label': '37', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Protected\\tBranches\\t&\\tCODEOWNERS\\nIn\\tsome\\tworkflows,\\tyou\\twill\\twant\\tto\\tprotect\\tcritical\\tbranches\\tto\\tensure\\tthe\\tcode\\tbeing\\tmerged\\tto\\tthose\\tbranches\\thas\\npassed\\tthe\\trequired\\tchecks\\tand\\treceived\\tappropriate\\tpeer\\treview.\\tThere\\tare\\tseveral\\tmethods\\tfor\\tthis,\\tincluding\\nProtected\\tBranches\\n\\tand\\t\\nCode\\tOwners\\n.\\nProtected\\tBranches\\nRepository\\tmaintainers\\tcan\\tprevent\\tmerges\\tto\\tspecific\\tbranches\\tthat\\thave\\tnot\\tmet\\tpre-defined\\tcriteria.\\tThis\\tcriteria\\ncan\\tinclude\\tpeer\\treviews,\\ttests\\trun\\tby\\tintegrations\\tsuch\\tas\\ta\\tContinuous\\tIntegration\\tservices\\tor\\tcode\\tquality,\\tor\\tuntil\\ta\\nspecific\\tcode\\towner\\thas\\treviewed\\tand\\tapproved\\tchanges.\\nLet's\\tenable\\tprotected\\tbranches:\\n1\\n.\\t\\nSelect\\tthe\\t\\nSettings\\n\\ttab.\\n2\\n.\\t\\nSelect\\t\\nBranches\\n\\tfrom\\tthe\\tmenu\\ton\\tthe\\tleft\\tside\\tof\\tthe\\tscreen.\\n3\\n.\\t\\nClick\\tthe\\t\\nAdd\\trule\\n\\tbutton\\tnext\\tto\\t\\nBranch\\tprotection\\trules\\n.\\n4\\n.\\t\\nIn\\tthe\\t\\nApply\\trule\\tto\\n\\ttextbox\\ttype\\tthe\\tname\\tof\\tthe\\tbranch\\tyou\\twould\\tlike\\tto\\tprotect,\\tfor\\texample,\\t\\n\\t\\nmaster\\n\\t\\n.\\n5\\n.\\t\\nClick\\tthe\\t\\nCreate\\n\\tbutton.\\nWithout\\tchecking\\tany\\tother\\toptions,\\tbasic\\tbranch\\tprotection\\tprevents\\tforce-pushes\\tand\\tprevents\\tit\\tfrom\\tbeing\\ndeleted.\\tTo\\tlearn\\tmore\\tabout\\tthe\\toptions\\tavailable,\\tcheck\\tout\\t\\nthe\\tdocumentation\\tfor\\tthis\\tfeature\\n.\\nPro\\ttip:\\tYou\\tcan\\tuse\\twildcards\\t(\\n\\t\\n*\\n\\t\\n,\\t\\n\\t\\n?\\n\\t\\n)\\tand\\tregular\\texpressions\\tto\\tmake\\ta\\tbranch\\tprotection\\trule\\tapply\\tto\\nmultiple\\tbranches.\\t\\nCheck\\tout\\tthe\\t\\nbranch\\tprotection\\tdocumentation\\n\\tfor\\tmore\\tinformation\\ton\\thow\\twildcards\\tand\\nregular\\texpression\\tmatching\\twork.\\nCODEOWNERS\\nRepository\\tmaintainers\\tcan\\tdefine\\texactly\\twhich\\tpeople\\tand\\tteams\\tneed\\tto\\treview\\tsets\\tof\\tchanges\\tby\\tcreating\\ta\\nCODEOWNERS\\n\\tfile.\\tFor\\texample,\\tyou\\tcould\\tuse\\tCODEOWNERS\\tto\\tensure:\\nyour\\tteam's\\tJavascript\\texpert\\treviews\\tall\\tfiles\\twith\\ta\\t\\n\\t\\n.js\\n\\t\\n\\textension\\nyour\\ttechnical\\tdocumentation\\tteam\\treviews\\tall\\tchanges\\tin\\tthe\\t\\n\\t\\ndocs/\\n\\t\\n\\tfolder\\nyour\\tsecurity\\tteam\\treviews\\tany\\tnew\\tdependencies\\tlisted\\tin\\tthe\\t\\n\\t\\npackage.json\\n\\t\\n\\tfile\\nLet's\\tcreate\\ta\\tCODEOWNERS\\tfile:\\n1\\n.\\t\\nGo\\tout\\tto\\tthe\\t\\nCode\\n\\ttab\\tof\\tyour\\trepository.\\n2\\n.\\t\\nClick\\tthe\\t\\nCreate\\tnew\\tfile\\n\\tbutton.\\n3\\n.\\t\\nIn\\tthe\\t\\nName\\tyour\\tfile...\\n\\ttextbox\\tenter\\t\\n\\t\\nCODEOWNERS\\n\\t\\n\\t(no\\textension\\tnecessary).\\tYou\\tcan\\tadd\\tthis\\tto\\ta\\t\\n\\t\\n.github/\\n\\t\\ndirectory\\tif\\tdesired\\tby\\tentering\\t\\n\\t\\n.github/CODEOWNERS\\n\\t\\n.\\n4\\n.\\t\\nOn\\tthe\\tfirst\\tline,\\ttype\\t\\n\\t\\n*\\t\\n@YOUR_USERNAME\\n\\t\\nThis\\tmeans\\tthat\\tyou\\twill\\tbe\\tthe\\tdefault\\towner\\tfor\\teverything\\tin\\tthe\\trepo,\\tunless\\ta\\tlater\\tmatch\\ttakes\\npreference.\\n5\\n.\\t\\nOn\\tthe\\tnext\\tline,\\ttype\\t\\n\\t\\n*.js\\t\\n@GITHUBTEACHER\\n\\t\\nOrder\\tis\\timportant.\\tThe\\tlast\\tmatching\\tpattern\\tfor\\ta\\tgiven\\tchange\\ttakes\\tprecedence.\\n6\\n.\\t\\nScroll\\tdown,\\tand\\ttype\\ta\\tcommit\\tmessage\\tinto\\tthe\\t\\nCommit\\tnew\\tfile\\n\\tdialog\\tbox.\\n7\\n.\\t\\nClick\\tthe\\t\\nCommit\\tnew\\tfile\\n\\tbutton\\tto\\tsave\\tyour\\tchanges.\\n8\\n.\\t\\nNow\\tthat\\tyou\\thave\\tcreated\\ta\\tCODEOWNERS\\tfile,\\tgo\\tback\\tto\\tyour\\tbranch\\tprotection\\tsettings\\tand\\tclick\\tthe\\t\\nEdit\\nbutton\\tnext\\tto\\t\\n\\t\\nmaster\\n\\t\\n.\\n9\\n.\\t\\nUnder\\t\\nRule\\tsettings\\n,\\tselect\\tthe\\toption\\tto\\t\\nRequire\\tpull\\trequest\\treviews\\tbefore\\tmerging\\n\\tand\\t\\nRequire\\treview\\nfrom\\tCode\\tOwners\\n.\\tRemember\\tto\\tclick\\t\\nSave\\tchanges\\n.\\nProtected\\tBranches\\t&\\tCODEOWNERS\\n37\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='4e264fd7-39c4-4b0b-ad07-9c6c6afc882e', embedding=None, metadata={'page_label': '38', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='For\\tmore\\tinformation\\ton\\thow\\tto\\tformat\\tthe\\tCODEOWNERS\\tfile,\\tcheck\\tout\\t\\nthe\\tdocumentation\\nProtected\\tBranches\\t&\\tCODEOWNERS\\n38', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='2aceb8e3-b80a-46dd-ae6f-8283f03423a2', embedding=None, metadata={'page_label': '39', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Searching\\tfor\\tEvents\\tin\\tYour\\tCode\\nIn\\tthis\\tsection,\\twe\\twill\\tlearn\\thow\\twe\\tcan\\tuse\\t\\n\\t\\ngit\\tbisect\\n\\t\\n\\tto\\tfind\\tthe\\tcommit\\tthat\\tintroduced\\ta\\tbug\\tinto\\tour\\trepository.\\nWhat\\tis\\t\\n\\t\\ngit\\tbisect\\n\\t\\n?\\nUsing\\ta\\tbinary\\tsearch,\\t\\n\\t\\ngit\\tbisect\\n\\t\\n\\tcan\\thelp\\tus\\tdetect\\tspecific\\tevents\\tin\\tour\\tcode.\\tFor\\texample,\\tyou\\tcould\\tuse\\tbisect\\nto\\tlocate\\tthe\\tcommit\\twhere:\\na\\tbug\\twas\\tintroduced.\\na\\tnew\\tfeature\\twas\\tadded.\\na\\tbenchmark’s\\tperformance\\timproved.\\nHow\\tit\\tworks\\n\\t\\ngit\\tbisect\\n\\t\\n\\tworks\\tby\\tcutting\\tthe\\thistory\\tbetween\\ttwo\\tpoints\\tin\\thalf\\tand\\tthen\\tchecking\\tyou\\tout\\tto\\tthat\\tcommit.\\tYou\\nthen\\tcheck\\twhether\\tthe\\tbug/feature\\texists\\tat\\tthat\\tpoint\\tand\\ttell\\tGit\\tthe\\tresult.\\tFrom\\tthere,\\tGit\\twill\\tdo\\tanother\\tdivision,\\netc\\tuntil\\tyou\\thave\\tlocated\\tthe\\tdesired\\tcommit.\\nWhen\\tyou\\tare\\tdoing\\ta\\tbisect,\\tyou\\tare\\tessentially\\tin\\ta\\tdetached\\thead\\tstate.\\tIt\\tis\\timportant\\tto\\tremember\\tto\\tend\\nthe\\tbisect\\twith\\t\\n\\t\\ngit\\tbisect\\treset\\n\\t\\n\\tbefore\\tattempting\\tto\\tperform\\tother\\toperations\\twith\\tGit.\\nFinding\\tthe\\tBug\\tin\\tOur\\tProject\\nThe\\tLong\\tWay\\n1\\n.\\t\\nInitiate\\tthe\\tbinary\\tsearch:\\t\\n\\t\\ngit\\tbisect\\tstart\\n\\t\\n.\\n2\\n.\\t\\nSpecify\\tthe\\tcommit\\twhere\\tyou\\tnoticed\\tthe\\tcode\\twas\\tbroken:\\t\\n\\t\\ngit\\tbisect\\tbad\\t<SHA>\\n\\t\\n.\\n3\\n.\\t\\nSpecify\\tthe\\tcommit\\twhere\\tyou\\tknew\\tthings\\twere\\tworking:\\t\\n\\t\\ngit\\tbisect\\tgood\\t<SHA>\\n\\t\\n.\\n4\\n.\\t\\nBisect\\twill\\tcheck\\tyou\\tout\\tto\\tthe\\tmidpoint\\tbetween\\tgood\\tand\\tbad.\\n5\\n.\\t\\nRun\\ta\\ttest\\tto\\tsee\\tif\\tthe\\tgame\\twould\\twork\\tat\\tthis\\tpoint.\\tOur\\ttest\\tis\\tto\\tuse\\t\\n\\t\\nls\\n\\t\\n\\tto\\tsee\\tif\\tan\\t\\n\\t\\nindex.html\\n\\t\\n\\tfile\\texists.\\nGit\\tBisect\\n39', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='2cd14530-6c14-43b6-b0b8-1839834163eb', embedding=None, metadata={'page_label': '40', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"6\\n.\\t\\nIf\\tthe\\tgame\\tis\\tstill\\tbroken\\t(there\\t\\nis\\tno\\n\\t\\n\\t\\nindex.html\\n\\t\\n\\tfile),\\ttype:\\t\\n\\t\\ngit\\tbisect\\tbad\\n\\t\\n.\\n7\\n.\\t\\nIf\\tthe\\tgame\\tworks\\t(and\\tthere\\t\\nis\\n\\tan\\t\\n\\t\\nindex.html\\n\\t\\n\\tfile),\\ttype:\\t\\n\\t\\ngit\\tbisect\\tgood\\n\\t\\n.\\n8\\n.\\t\\nGit\\twill\\tbisect\\tagain\\tand\\twait\\tfor\\tyou\\tto\\ttest.\\tThis\\twill\\thappen\\tuntil\\tGit\\thas\\tenough\\tinformation\\tto\\tpinpoint\\tthe\\tfirst\\nbad\\tcommit.\\n9\\n.\\t\\nWhen\\tGit\\thas\\tdetected\\tthe\\terror,\\tit\\twill\\tprovide\\ta\\tmessage\\tthat\\t\\n\\t\\nSHA\\tis\\tthe\\tfirst\\tbad\\tcommit.\\n\\t\\n10\\n.\\t\\nExit\\tthe\\tbisect\\tprocess:\\t\\n\\t\\ngit\\tbisect\\treset\\n\\t\\n.\\nThe\\tShort\\tWay\\nBisect\\tcan\\talso\\trun\\tthe\\ttests\\ton\\tyour\\tcode\\tautomatically.\\tLet's\\ttry\\tit\\tagain\\tusing\\ta\\tshortcut\\tcommand\\tand\\ta\\ttest:\\n1\\n.\\t\\n\\t\\ngit\\tbisect\\tstart\\t<bad-SHA>\\t<good-SHA>\\n\\t\\n2\\n.\\t\\n\\t\\ngit\\tbisect\\trun\\tls\\tindex.html\\n\\t\\n3\\n.\\t\\n\\t\\ngit\\tbisect\\treset\\n\\t\\nGit\\tBisect\\n40\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='59f63208-e6ce-4e03-99ad-7b33b93e7a88', embedding=None, metadata={'page_label': '41', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Reverting\\tCommits\\nIn\\tthis\\tsection,\\twe\\twill\\tlearn\\tabout\\tcommands\\tthat\\tre-write\\thistory\\tand\\tunderstand\\twhen\\tyou\\tshould\\tor\\tshouldn't\\tuse\\nthem.\\nHow\\tCommits\\tAre\\tMade\\nEvery\\tcommit\\tin\\tGit\\tis\\ta\\tunique\\tsnapshot\\tof\\tthe\\tproject\\tat\\tthat\\tpoint\\tin\\ttime.\\tIt\\tcontains\\tthe\\tfollowing\\tinformation:\\nPointers\\tto\\tthe\\tcurrent\\tobjects\\tin\\tthe\\trepository\\nCommit\\tauthor\\tand\\temail\\t(from\\tyour\\tconfig\\tsettings)\\nCommit\\tdate\\tand\\ttime\\nCommit\\tmessage\\nEach\\tcommit\\talso\\tcontains\\tthe\\tcommit\\tID\\tof\\tits\\tparent\\tcommit.\\nImage\\tsource:\\tProGit\\tv2\\tby\\tScott\\tChacon\\nSafe\\tOperations\\nGit's\\tdata\\tstructure\\tgives\\tit\\tintegrity\\tbut\\tits\\tdistributed\\tnature\\talso\\trequires\\tus\\tto\\tbe\\taware\\tof\\thow\\tcertain\\toperations\\nwill\\timpact\\tthe\\tcommits\\tthat\\thave\\talready\\tbeen\\tshared.\\nReverting\\tCommits\\n41\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='144700d2-91e0-48f4-86c1-b4e4c168279c', embedding=None, metadata={'page_label': '42', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='If\\tan\\toperation\\twill\\tchange\\ta\\tcommit\\tID\\tthat\\thas\\tbeen\\tpushed\\tto\\tthe\\tremote\\t(also\\tknown\\tas\\ta\\tpublic\\tcommit),\\twe\\tmust\\nbe\\tcareful\\tin\\tchoosing\\tthe\\toperations\\tto\\tperform.\\nGuidelines\\tfor\\tCommon\\tCommands\\nCommand\\nCautions\\n\\t\\nrevert\\n\\t\\nGenerally\\tsafe\\tsince\\tit\\tcreates\\ta\\tnew\\tcommit.\\n\\t\\ncommit\\t--amend\\n\\t\\nOnly\\tuse\\ton\\tlocal\\tcommits.\\n\\t\\nreset\\n\\t\\nOnly\\tuse\\ton\\tlocal\\tcommits.\\n\\t\\ncherry-pick\\n\\t\\nOnly\\tuse\\ton\\tlocal\\tcommits.\\n\\t\\nrebase\\n\\t\\nOnly\\tuse\\ton\\tlocal\\tcommits.\\nReverting\\tCommits\\nTo\\tget\\tyour\\tgame\\tworking,\\tyou\\twill\\tneed\\tto\\treverse\\tthe\\tcommit\\tthat\\tincorrectly\\trenames\\t\\n\\t\\nindex.html\\n\\t\\n.\\nWarning\\n:\\tBefore\\tyou\\treverse\\tthe\\tcommit,\\tit\\tis\\ta\\tgood\\tidea\\tto\\tmake\\tsure\\tyou\\twill\\tnot\\tbe\\tinadvertently\\treversing\\nother\\tchanges\\tthat\\twere\\tlumped\\tinto\\tthe\\tsame\\tcommit.\\tTo\\tsee\\twhat\\twas\\tchanged\\tin\\tthe\\tcommit,\\tuse\\t\\n\\t\\ngit\\tshow\\nSHA\\n\\t\\n.\\n1\\n.\\t\\nInitialize\\tthe\\trevert:\\t\\n\\t\\ngit\\trevert\\t<SHA>\\n\\t\\n2\\n.\\t\\nType\\ta\\tcommit\\tmessage.\\n3\\n.\\t\\nPush\\tyour\\tchanges\\tto\\tGitHub.\\nReverting\\tCommits\\n42', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='7a50426d-5f21-4190-9a46-d6b02deb89a8', embedding=None, metadata={'page_label': '43', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Helpful\\tGit\\tCommands\\nIn\\tthis\\tsection,\\twe\\twill\\texplore\\tsome\\thelpful\\tGit\\tcommands.\\nMoving\\tand\\tRenaming\\tFiles\\twith\\tGit\\n1\\n.\\t\\nCreate\\ta\\tnew\\tbranch\\tnamed\\t\\n\\t\\nslow-down\\n\\t\\n.\\n2\\n.\\t\\nOn\\t\\nline\\t9\\n\\tof\\tthe\\tindex.html\\tfile,\\tchange\\tthe\\tbackground\\turl\\tto\\t\\n(images/texture.jpg)\\n.\\n3\\n.\\t\\nOn\\t\\nline\\t78\\n,\\tchange\\tthe\\ttiming\\tfor\\tthe\\tgame\\tto\\tspeed\\tit\\tup\\tor\\tslow\\tit\\tdown.\\n4\\n.\\t\\nSave\\tyour\\tchanges.\\n5\\n.\\t\\nSee\\twhat\\tgit\\tis\\ttracking:\\t\\n\\t\\ngit\\tstatus\\n\\t\\n6\\n.\\t\\nCreate\\ta\\tnew,\\tempty\\tdirectory:\\t\\n\\t\\nmkdir\\timages\\n\\t\\n7\\n.\\t\\nMove\\tthe\\ttexture\\tfile\\tinto\\tthe\\tdirectory\\twith\\tgit:\\t\\n\\t\\ngit\\tmv\\ttexture.jpg\\timages/texture.jpg\\n\\t\\nStaging\\tHunks\\tof\\tChanges\\nCrafting\\tatomic\\tcommits\\tis\\tan\\timportant\\tpart\\tof\\tcreating\\ta\\treadable\\tand\\tinformative\\thistory\\tof\\tthe\\tproject.\\n1\\n.\\t\\nSee\\twhat\\tgit\\tis\\ttracking:\\t\\n\\t\\ngit\\tstatus\\n\\t\\n.\\n2\\n.\\t\\nMove\\tsome\\tparts\\tof\\tsome\\tfiles\\tto\\tthe\\tstaging\\tarea\\twith\\tthe\\t\\n\\t\\n--patch\\n\\t\\n\\tflag:\\t\\n\\t\\ngit\\tadd\\t-p\\n\\t\\n.\\n3\\n.\\t\\nStage\\tthe\\thunk\\trelated\\tto\\tthe\\timage\\tmove:\\t\\n\\t\\ny\\n\\t\\n4\\n.\\t\\nLeave\\tthe\\thunk\\trelated\\tto\\tthe\\tspeed\\tchange\\tin\\tthe\\tworking\\tarea:\\t\\n\\t\\nn\\n\\t\\nWondering\\twhat\\tall\\tof\\tthose\\tother\\toptions\\tare\\tfor\\tthe\\thunks?\\tUse\\tthe\\t\\n\\t\\n?\\n\\t\\n\\tto\\tsee\\ta\\tlist\\tof\\toptions\\tabove\\tthe\\thunk.\\n\\t\\ngit\\tconfig\\t--global\\talias.cm\\t\"!git\\tadd\\t-A\\t&&\\tgit\\tcommit\\t-m\"\\n\\t\\n\\tcould\\tbe\\thelpful\\there.\\tCheck\\tout\\tthe\\tappendix\\tto\\tsee\\nhow!\\nHelpful\\tGit\\tCommands\\n43', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='cdafb67b-94b7-4950-ba0d-e5f46737a1f5', embedding=None, metadata={'page_label': '44', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Viewing\\tLocal\\tChanges\\nNow\\tthat\\tyou\\thave\\tsome\\tfiles\\tin\\tthe\\tstaging\\tarea\\tand\\tthe\\tworking\\tdirectory,\\tlet\\'s\\texplore\\thow\\tyou\\tcan\\tcompare\\ndifferent\\tpoints\\tin\\tyour\\trepository.\\nComparing\\tChanges\\twithin\\tthe\\tRepository\\n\\t\\ngit\\tdiff\\n\\t\\n\\tallows\\tyou\\tto\\tsee\\tthe\\tdifference\\tbetween\\tany\\ttwo\\trefs\\tin\\tthe\\trepository.\\tThe\\tdiagram\\tbelow\\tshows\\thow\\tyou\\ncan\\tcompare\\tthe\\tcontent\\tof\\tyour\\tworking\\tarea,\\tstaging,\\tand\\tHEAD\\t(or\\tthe\\tmost\\trecent\\tcommit):\\nLet\\'s\\ttry\\tthese\\tcommands\\ton\\tthe\\trepository:\\n$\\tgit\\tdiff\\n$\\tgit\\tdiff\\t--staged\\n$\\tgit\\tdiff\\tHEAD\\n$\\tgit\\tdiff\\t--color-words\\n\\t\\ngit\\tdiff\\n\\t\\n\\twill\\talso\\tallow\\tyou\\tto\\tcompare\\tbetween\\tbranches,\\tcommits,\\tand\\ttags\\tby\\tsimply\\ttyping:\\n$\\tgit\\tdiff\\t<REF-1>\\t<REF-2>\\n$\\tgit\\tdiff\\tmaster\\tslow-down\\n$\\tgit\\tdiff\\torigin/master\\tmaster\\n$\\tgit\\tdiff\\t2710\\tb745\\nNotice\\tthat,\\tjust\\tlike\\tmerges,\\tdiffs\\tare\\tdirectional.\\tIt\\tis\\teasiest\\tto\\tthink\\tof\\tit\\tas\\t\"diff\\tback\\tto\\t\\n\\t\\n<REF-1>\\n\\t\\n\\tstarting\\tat\\n\\t\\n<REF-2>\\n\\t\\n\"\\tor\\t\"see\\twhat\\tis\\t\\nnot\\n\\tin\\t\\n\\t\\n<REF-1>\\n\\t\\n\\tbut\\t\\nis\\n\\tin\\t\\n\\t\\n<REF-2>\\n\\t\\n\".\\t\\nThe\\tfinal\\texample\\tshows\\thow\\tto\\tcompare\\ttwo\\ncommits\\tbased\\ton\\ttheir\\tcommit\\thashes.\\t\\nThis\\texact\\tcommand\\twill\\tnot\\twork\\tfor\\teveryone\\tsince\\tthe\\tcommits\\tin\\nyour\\town\\trepository\\twill\\thave\\tdifferent\\thashes.\\nThere\\'s\\ta\\thelpful\\talias\\tfor\\topening\\tthe\\tremote\\tdirectly\\tfrom\\tyour\\tcommand\\tline.\\tCheck\\tout\\tthe\\tappendix\\tif\\tyou\\'d\\tlike\\tto\\nknow\\tmore!\\nViewing\\tLocal\\tChanges\\n44', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e1ab9320-131e-4212-8655-b73c4528805c', embedding=None, metadata={'page_label': '45', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Viewing\\tLocal\\tChanges\\n45', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='fe3a4ca6-ada0-4175-b3e7-98987f4542bd', embedding=None, metadata={'page_label': '46', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Tags\\tand\\tReleases\\nYou\\tmay\\twant\\tto\\tput\\ttags\\tor\\treleases\\ton\\tcertain\\tcommits\\tin\\tyour\\tcode\\'s\\thistory\\tto\\tmark\\tspecific\\tstates\\tor\\tplaces\\tin\\ntime.\\tTo\\tdo\\tthis,\\tyou\\tcould\\tuse\\tGit\\'s\\t\\ntag\\n\\tfeature,\\tor\\tyou\\tcould\\tuse\\tGitHub\\'s\\t\\nrelease\\n\\tfeature.\\nTags\\nA\\ttag\\tis\\ta\\tpointer\\tthat\\tpoints\\tto\\ta\\tspecific\\tcommit.\\tUnlike\\tcommits,\\ttags\\tare\\t\\nnot\\n\\timmutable.\\tThey\\tcan\\tbe\\tmoved\\tand\\nchanged.\\tLet\\'s\\tpractice\\ta\\tbit\\twith\\ttags.\\nTags\\tcan\\tbe\\tcreated\\tlocally\\twith\\tGit,\\tor\\ton\\tGitHub.\\tWhen\\tcreating\\ta\\ttag\\tfrom\\tthe\\tcommand\\tline,\\tit\\'s\\trecommended\\tto\\ncreate\\tan\\t\"annotated\"\\ttag.\\tThe\\tfollowing\\texample\\tcreates\\tan\\tannotated\\ttag\\twith\\tthe\\t\\n\\t\\n-a\\n\\t\\n\\tflag,\\tnames\\tthe\\ttag\\t\\n\\t\\nv1.0\\n\\t\\n,\\nand\\tconnects\\tit\\tto\\twhichever\\tcommit\\tSHA\\tis\\tincluded.\\n\\t\\ngit\\ttag\\t-a\\tv1.0\\t<SHA>\\n\\t\\nTo\\tsee\\tall\\ttags,\\ttype\\t\\n\\t\\ngit\\ttag\\t--list\\n\\t\\n.\\nAnother\\tcaveat\\twith\\ttags\\tis\\tthat\\tthey\\tare\\tnot\\tautomatically\\tpushed\\tup\\twith\\tcommits.\\tTo\\tpush\\ttags,\\ttype\\t\\n\\t\\ngit\\tpush\\t--\\ntags\\n\\t\\n.\\nYou\\tcan\\talso\\tset\\tthis\\tas\\ta\\tdefault\\twith\\tconfigs\\tusing\\t\\n\\t\\ngit\\tconfig\\tpush.followTags\\ttrue\\n\\t\\n\\twhich\\twill\\tautomatically\\tpush\\ntags\\twhen\\ttheir\\tassociated\\tcommits\\tare\\tpushed.\\t\\nRead\\tmore\\tabout\\tthis\\tconfig\\tsetting\\n.\\nReleases\\nReleases\\tare\\ta\\tGitHub\\tfeature\\tthat\\tallow\\tyou\\tto\\tadd\\tan\\texecutable\\tto\\tthe\\ttag\\tfor\\teasier\\taccess\\tby\\tvisitors\\twho\\tjust\\nwant\\tto\\tdownload\\tand\\tinstall\\tyour\\tsoftware.\\tReleases\\tare\\ttags,\\tbecause\\tthey\\tpoint\\tto\\ta\\tspecific\\tcommit\\tand\\tcan\\tbe\\nnamed\\tlike\\tany\\tother\\ttag.\\tHowever,\\treleases\\tcan\\talso\\tinclude\\tattached\\tbinaries.\\nAdd\\ta\\tRelease\\tto\\tGitHub-Games\\n1\\n.\\t\\nOn\\tGitHub,\\tnavigate\\tto\\tthe\\t\\nCode\\n\\ttab\\tof\\tthe\\trepository.\\n2\\n.\\t\\nUnder\\tyour\\trepository\\tname,\\tclick\\tReleases.\\n3\\n.\\t\\nClick\\tDraft\\ta\\tnew\\trelease.\\n4\\n.\\t\\nType\\ta\\tname\\tfor\\tthe\\ttag.\\tWe\\trecommend\\tyou\\tuse\\tsemantic\\tversioning.\\n5\\n.\\t\\nSelect\\ta\\tbranch\\tthat\\tcontains\\tthe\\tproject\\tyou\\twant\\tto\\trelease.\\tUsually,\\tyou\\'ll\\twant\\tto\\trelease\\tagainst\\tyour\\tmaster\\nbranch,\\tunless\\tyou\\'re\\treleasing\\tbeta\\tsoftware.\\tYou\\tcan\\talso\\tselect\\ta\\trecent\\tcommit\\tby\\tchoosing\\tthe\\trecent\\ncommits\\ttab.\\n6\\n.\\t\\nType\\ta\\ttitle\\tand\\tdescription\\tthat\\tdescribes\\tyour\\trelease.\\n7\\n.\\t\\nIf\\tyou\\'re\\tready\\tto\\tpublicize\\tyour\\trelease,\\tclick\\tPublish\\trelease.\\tOtherwise,\\tclick\\tSave\\tdraft\\tto\\twork\\ton\\tit\\tlater.\\nNotice\\tthat\\tyou\\tcould\\tdrag\\tand\\tdrop\\tor\\tselect\\tfiles\\tmanually\\tin\\tthe\\tbinaries\\tbox,\\tor\\tselect\\t\"This\\tis\\ta\\tpre-release\"\\nto\\tnotify\\tusers\\tthat\\tit\\'s\\tnot\\tready\\tfor\\tproduction.\\nTags\\t&\\tReleases\\n46', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ee800d64-3ce9-45be-ab4f-3e1ad1c87d96', embedding=None, metadata={'page_label': '47', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Discussion\\tGuide:\\tTeam\\tWorkflows\\tand\\tBranching\\nStrategies\\nNow\\tis\\ta\\tgood\\ttime\\tto\\tdiscuss\\tworkflows\\t-\\twhat\\tworks\\tfor\\tyou\\tand\\tyour\\tteam,\\twhat\\tmight\\twork,\\tand\\twhat\\tyou\\'ve\\tbeen\\ndoing\\tin\\tthe\\tpast.\\tHere\\tare\\tsome\\ttopics\\tyou\\twill\\twant\\tto\\tdiscuss\\twith\\tyour\\tteam\\tas\\tyou\\testablish\\tyour\\tideal\\tprocess.\\nHave\\ta\\tconversation\\teither\\tsynchronously\\tor\\tin\\tissues\\tin\\tthe\\tclass\\trepository\\tabout\\tdifferent\\tworkflows.\\n1\\n.\\t\\nWhich\\tbranching\\tstrategy\\twill\\twe\\tuse?\\n2\\n.\\t\\nWhich\\tbranch\\twill\\tserve\\tas\\tour\\t\"master\"\\tor\\tdeployed\\tcode?\\n3\\n.\\t\\nHow\\twill\\tyou\\tprotect\\tyour\\tcode?\\n4\\n.\\t\\nWill\\twe\\tuse\\tnaming\\tconventions\\tfor\\tour\\tbranches?\\n5\\n.\\t\\nHow\\twill\\twe\\tuse\\tlabels\\tand\\tassignees?\\n6\\n.\\t\\nWill\\twe\\tuse\\tmilestones?\\n7\\n.\\t\\nWill\\twe\\thave\\trequired\\telements\\tof\\tIssues\\tor\\tPull\\tRequests\\t(e.g.\\tshipping\\tchecklists)?\\n8\\n.\\t\\nWho\\tis\\texpected\\tto\\treview\\tyour\\twork?\\tDo\\tyou\\tplan\\tto\\tinvolve\\tother\\tteams?\\n9\\n.\\t\\nHow\\twill\\twe\\tindicate\\tsign-off\\ton\\tPull\\tRequests?\\n10\\n.\\t\\nWho\\twill\\tmerge\\tpull\\trequests?\\n11\\n.\\t\\nHow\\twill\\tyou\\tteach\\tyour\\tworkflow\\tto\\tyour\\tteam?\\tIf\\tit\\talready\\texists,\\thow\\tis\\tit\\ttaught\\tto\\tnew\\thires?\\n12\\n.\\t\\nWhat\\tintegrations\\twill\\tbe\\tused\\tin\\tdifferent\\tstages\\tof\\tdevelopment?\\tWill\\tall\\tteams\\tbe\\tusing\\tthe\\tsame\\ttools?\\n13\\n.\\t\\nIf\\tusers\\thave\\tquestions\\tabout\\tGit,\\tGitHub,\\tor\\ttheir\\tworkflows,\\twho\\tdo\\tthey\\task?\\tHow\\tdo\\tthey\\tknow\\twho\\tto\\task?\\nWorkflow\\tDiscussion\\n47', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='2ba831b1-444f-4894-9894-95816ab1890e', embedding=None, metadata={'page_label': '48', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Initializing\\ta\\tNew\\tLocal\\tRepository\\nLet\\'s\\tcreate\\ta\\tlocal\\trepository\\tthat\\twe\\tcan\\tuse\\tto\\tpractice\\tthe\\tnext\\tset\\tof\\tcommands.\\n1\\n.\\t\\nNavigate\\tto\\tthe\\tdirectory\\twhere\\tyou\\twill\\tplace\\tyour\\tpractice\\trepo\\t(\\n\\t\\ncd\\t..\\n\\t\\n\\tto\\tget\\tback\\tto\\tthe\\tparent\\tfolder).\\n2\\n.\\t\\nCreate\\ta\\tnew\\tdirectory\\tand\\tinitialize\\tit\\tas\\ta\\tgit\\trepository:\\t\\n\\t\\ngit\\tinit\\tpractice-repo\\n\\t\\n3\\n.\\t\\nCD\\tinto\\tyour\\tnew\\trepository:\\t\\n\\t\\ncd\\tpractice-repo\\n\\t\\n4\\n.\\t\\nCreate\\tan\\tempty\\tnew\\tfile\\tnamed\\t\\n\\t\\nREADME.md\\n\\t\\n:\\nBash:\\t\\n\\t\\ntouch\\tREADME.md\\n\\t\\nPowerShell:\\t\\n\\t\\nOut-File\\tREADME.md\\n\\t\\n5\\n.\\t\\nAdd\\tand\\tcommit\\tthe\\tREADME.md\\tfile.\\nSince\\twe\\twill\\tbe\\tusing\\tthis\\tas\\tour\\tpractice\\trepository,\\twe\\tneed\\tto\\tgenerate\\tsome\\tfiles\\tand\\tcommits.\\tHere\\tare\\tsome\\nscripts\\tto\\tmake\\tthis\\teasier:\\nBash:\\nfor\\td\\tin\\t{1..6};\\tdo\\ttouch\\t\"file${d}.md\";\\tgit\\tadd\\t\"file${d}.md\";\\tgit\\tcommit\\t-m\\t\"adding\\tfile\\t${d}\";\\tdone\\nPowerShell:\\nfor\\t($d=1;\\t$d\\t-le\\t6;\\t$d++)\\t{\\tOut-File\\tfile$d.md;\\tgit\\tadd\\tfile$d.md;\\tgit\\tcommit\\t-m\\t\"adding\\tfile$d.md\";\\t}\\nYou\\tmight\\tsee\\ta\\tcommand\\tduring\\tthis\\tsection,\\t\\n\\t\\ntree\\t.git\\n\\t\\n.\\tIf\\tyou\\'re\\ton\\ta\\tmachine\\twhere\\t\\n\\t\\ntree\\t.git\\n\\t\\n\\tdoesn\\'t\\nwork\\t(probably\\ta\\tWindows\\tmachine),\\ttry\\t\\n\\t\\ncmd\\t//c\\ttree\\n\\t\\n\\tinstead.\\nCreate\\ta\\tLocal\\tRepo\\n48', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='9d7b9780-2c14-4a9e-b62a-b3fabc1175ed', embedding=None, metadata={'page_label': '49', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Fixing\\tCommit\\tMistakes\\nIn\\tthis\\tactivity,\\twe\\twill\\tbegin\\tto\\texplore\\tsome\\tof\\tthe\\tways\\tGit\\tand\\tGitHub\\tcan\\thelp\\tus\\tshape\\tour\\tproject\\thistory.\\nRevising\\tYour\\tLast\\tCommit\\n\\t\\ngit\\tcommit\\t--amend\\n\\t\\n\\tallows\\tus\\tto\\tmake\\tchanges\\tto\\tthe\\tcommit\\tthat\\tHEAD\\tis\\tcurrently\\tpointing\\tto.\\tTwo\\tof\\tthe\\tmost\\ncommon\\tuses\\tare:\\nRe-writing\\tcommit\\tmessages\\nAdding\\tfiles\\tto\\tthe\\tcommit\\nLet's\\tsee\\tthis\\tin\\taction:\\n1\\n.\\t\\nCreate\\ta\\tnew\\tfile:\\nBash:\\t\\n\\t\\ntouch\\tfile7.md\\n\\t\\nPowerShell:\\t\\n\\t\\nOut-File\\tfile7.md\\n\\t\\n2\\n.\\t\\nWhen\\tyou\\tare\\tadding\\tfiles\\tto\\tthe\\tprevious\\tcommit,\\tthey\\tshould\\tbe\\tin\\tthe\\tstaging\\tarea.\\tMove\\tyour\\tfile\\tto\\tthe\\nstaging\\tarea:\\t\\n\\t\\ngit\\tadd\\tfile7.md\\n\\t\\n3\\n.\\t\\n\\t\\ngit\\tcommit\\t--amend\\n\\t\\n4\\n.\\t\\nThe\\ttext\\teditor\\twill\\topen,\\tallowing\\tyou\\tto\\tedit\\tyour\\tcommit\\tmessage.\\nYou\\tcan\\tactually\\tamend\\tany\\tdata\\tstored\\tby\\tthe\\tlast\\tcommit\\tsuch\\tas\\tcommit\\tauthor,\\temail,\\tetc.\\nFixing\\tCommit\\tMistakes\\n49\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='1e2311f4-7439-4482-b860-d8e2259c4355', embedding=None, metadata={'page_label': '50', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Rewriting\\tHistory\\twith\\tGit\\tReset\\nWhen\\tyou\\twant\\tto\\tmake\\tchanges\\tto\\tcommits\\tfurther\\tback\\tin\\thistory,\\tyou\\twill\\tneed\\tto\\tuse\\ta\\tmore\\tpowerful\\tcommand:\\n\\t\\ngit\\treset\\n\\t\\n.\\nUnderstanding\\tReset\\nSometimes\\twe\\tare\\tworking\\ton\\ta\\tbranch\\tand\\twe\\tdecide\\tthings\\taren\\'t\\tgoing\\tquite\\tlike\\twe\\thad\\tplanned.\\tWe\\twant\\tto\\nreset\\tsome,\\tor\\teven\\tall,\\tof\\tour\\tfiles\\tto\\tlook\\tlike\\twhat\\tthey\\twere\\tat\\ta\\tdifferent\\tpoint\\tin\\thistory.\\nRemember,\\tthere\\tare\\tthree\\tdifferent\\tsnapshots\\tof\\tour\\tproject\\tat\\tany\\tgiven\\ttime.\\tThe\\tfirst\\tis\\tthe\\tmost\\trecent\\tcommit\\n(also\\tknown\\tas\\tHEAD).\\tThe\\tsecond\\tis\\tthe\\tstaging\\tarea\\t(also\\tcalled\\tthe\\tindex).\\tThe\\tthird\\tis\\tthe\\tworking\\tdirectory\\ncontaining\\tany\\tnew,\\tdeleted,\\tor\\tmodified\\tfiles.\\nThe\\t\\n\\t\\ngit\\treset\\n\\t\\n\\tcommand\\thas\\tthree\\tmodes,\\tand\\tthey\\tallow\\tus\\tto\\tchange\\tsome\\tor\\tall\\tof\\tthese\\tthree\\tsnapshots.\\nIt\\talso\\thelps\\tto\\tknow\\twhat\\tbranches\\ttechnically\\tare:\\teach\\tis\\ta\\tpointer,\\tor\\treference,\\tto\\tthe\\tlatest\\tcommit\\tin\\ta\\tline\\tof\\nwork.\\tAs\\twe\\tadd\\tnew\\tcommits,\\tthe\\tcurrently\\tchecked-out\\tbranch\\t\"moves\\tforward,\"\\tso\\tthat\\tit\\talways\\tpoints\\tto\\tthe\\tmost\\nrecent\\tcommit.\\nReset\\tModes\\nRewriting\\tHistory\\twith\\tGit\\tReset\\n50', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='179e68ac-4e21-4843-b4e9-7c16db4822b1', embedding=None, metadata={'page_label': '51', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The\\tthree\\tmodes\\tfor\\tgit\\treset\\tare:\\t\\n\\t\\n--soft\\n\\t\\n,\\t\\n\\t\\n--mixed\\n\\t\\n,\\tand\\t\\n\\t\\n--hard\\n\\t\\n.\\tFor\\tthese\\texamples,\\tassume\\tthat\\twe\\thave\\ta\\n\"clean\"\\tworking\\tdirectory,\\ti.e.\\tthere\\tare\\tno\\tuncommited\\tchanges.\\n\\t\\n--soft\\n\\t\\n\\t\\ngit\\treset\\t--soft\\t<SHA>\\n\\t\\n\\tmoves\\tthe\\tcurrent\\tbranch\\tto\\tpoint\\tat\\tthe\\t\\n\\t\\n<SHA>\\n\\t\\n.\\tHowever,\\tthe\\tworking\\tdirectory\\tand\\tstaging\\narea\\tremain\\tuntouched.\\tSince\\tthe\\tsnapshot\\tthat\\tcurrent\\tbranch\\tpoints\\tto\\tnow\\tdiffers\\tfrom\\tthe\\tindex\\'s\\tsnapshot,\\tthis\\ncommand\\teffectively\\tstages\\tall\\tdifferences\\tbetween\\tthose\\tsnapshots.\\tThis\\tis\\ta\\tgood\\tcommand\\tto\\tuse\\twhen\\tyou\\thave\\nmade\\ta\\tlarge\\tnumber\\tof\\tsmall\\tcommits\\tand\\tyou\\twould\\tlike\\tto\\tregroup\\tthem\\tinto\\ta\\tsingle\\tcommit.\\n\\t\\n--mixed\\n\\t\\n\\t\\ngit\\treset\\t--mixed\\t<SHA>\\n\\t\\n\\tmakes\\tthe\\tcurrent\\tbranch\\t\\nand\\n\\tthe\\tstaging\\tarea\\tlook\\tlike\\tthe\\t\\n\\t\\n<SHA>\\n\\t\\n\\tsnapshot.\\t\\nThis\\tis\\tthe\\ndefault\\tmode:\\n\\tif\\tyou\\tdon\\'t\\tinclude\\ta\\tmode\\tflag,\\tGit\\twill\\tassume\\tyou\\twant\\tto\\tdo\\ta\\t\\n\\t\\n--mixed\\n\\t\\n\\treset.\\t\\n\\t\\n--mixed\\n\\t\\n\\tis\\tuseful\\tif\\nyou\\twant\\tto\\tkeep\\tall\\tof\\tyour\\tchanges\\tin\\tthe\\tworking\\tdirectory,\\tbut\\tchange\\twhether\\tand\\thow\\tyou\\tcommit\\tthose\\nchanges.\\n\\t\\n--hard\\n\\t\\n\\t\\ngit\\treset\\t--hard\\t<SHA>\\n\\t\\n\\tis\\tthe\\tmost\\tdrastic\\toption.\\tWith\\tthis,\\tGit\\twill\\tmake\\tall\\t3\\tsnapshots,\\tthe\\tcurrent\\tbranch,\\tthe\\nstaging\\tarea,\\t\\nand\\n\\tyour\\tworking\\tdirectory,\\tlook\\tlike\\tthey\\tdid\\tat\\t\\n\\t\\n<other-commit>\\n\\t\\n.\\tThis\\tcan\\tbe\\tdangerous!\\tWe\\'ve\\nassumed\\tso\\tfar\\tthat\\tour\\tworking\\tdirectory\\tis\\tclean.\\tIf\\tit\\tis\\tnot,\\tand\\tyou\\thave\\tuncommitted\\tchanges,\\t\\n\\t\\ngit\\treset\\t--hard\\n\\t\\nwill\\t\\ndelete\\tall\\tof\\tthose\\tchanges\\n.\\tEven\\twith\\ta\\tclean\\tworking\\tdirectory,\\tuse\\t\\n\\t\\n--hard\\n\\t\\n\\tonly\\tif\\tyou\\'re\\tsure\\tyou\\twant\\tto\\ncompletely\\tundo\\tearlier\\tchanges.\\nReset\\tSoft\\nRewriting\\tHistory\\twith\\tGit\\tReset\\n51', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='7d487743-9dc5-478b-903c-43ab6e43f698', embedding=None, metadata={'page_label': '52', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Using\\tthe\\tpractice\\trepository\\twe\\tcreated\\tearlier,\\tlet\\'s\\ttry\\ta\\t\\n\\t\\nreset\\t--soft\\n\\t\\n.\\n1\\n.\\t\\nView\\tthe\\thistory\\tof\\tour\\tproject:\\t\\n\\t\\ngit\\tlog\\t--oneline\\t--decorate\\n\\t\\n2\\n.\\t\\nIdentify\\tthe\\tcurrent\\tlocation\\tof\\t\\n\\t\\nHEAD\\n\\t\\n.\\n3\\n.\\t\\nGo\\tback\\ttwo\\tcommits\\tin\\thistory:\\t\\n\\t\\ngit\\treset\\t--soft\\tHEAD~2\\n\\t\\n4\\n.\\t\\nSee\\tthe\\ttip\\tof\\tour\\tbranch\\t(and\\t\\n\\t\\nHEAD\\n\\t\\n)\\tis\\tnow\\tsitting\\ttwo\\tcommits\\tearlier\\tthan\\tit\\twas\\tbefore:\\t\\n\\t\\ngit\\tlog\\t--oneline\\t--\\ndecorate\\n\\t\\n5\\n.\\t\\nThe\\tchanges\\twe\\tmade\\tin\\tthe\\tlast\\ttwo\\tcommits\\tshould\\tbe\\tin\\tthe\\tstaging\\tarea:\\t\\n\\t\\ngit\\tstatus\\n\\t\\n6\\n.\\t\\nAll\\tthe\\tfiles\\tstill\\texist\\tlocally:\\t\\n\\t\\nls\\n\\t\\n7\\n.\\t\\nLet\\'s\\tremove\\tthe\\textra\\tfile\\twe\\tcreated\\tearlier:\\t\\n\\t\\ngit\\trm\\t--cached\\tfile7.md\\n\\t\\n8\\n.\\t\\nNow,\\twe\\'ll\\tre-commit\\tthese\\tchanges\\twithout\\tthe\\textra\\tfile:\\t\\n\\t\\ngit\\tcommit\\t-m\\t\"re-add\\tfile\\t5\\tand\\t6\"\\n\\t\\nIn\\tthis\\texample,\\tthe\\ttilde\\ttells\\tgit\\twe\\twant\\tto\\treset\\tto\\ttwo\\tcommits\\tbefore\\tthe\\tcurrent\\tlocation\\tof\\t\\n\\t\\nHEAD\\n\\t\\n.\\tYou\\tcan\\nalso\\tuse\\tthe\\tfirst\\tfew\\tcharacters\\tof\\tthe\\tcommit\\tID\\tto\\tpinpoint\\tthe\\tlocation\\twhere\\tyou\\twould\\tlike\\tto\\treset.\\nReset\\tMixed\\nNext\\twe\\twill\\ttry\\tthe\\tdefault\\tmode\\tof\\treset,\\t\\n\\t\\nreset\\t--mixed\\n\\t\\n:\\n1\\n.\\t\\nOnce\\tagain,\\twe\\twill\\tstart\\tby\\tviewing\\tthe\\thistory\\tof\\tour\\tproject:\\t\\n\\t\\ngit\\tlog\\t--oneline\\n\\t\\n2\\n.\\t\\nGo\\tback\\tone\\tcommit\\tin\\thistory:\\t\\n\\t\\ngit\\treset\\tHEAD~\\n\\t\\n3\\n.\\t\\nSee\\twhere\\tthe\\ttip\\tof\\tthe\\tbranch\\tis\\tpointing:\\t\\n\\t\\ngit\\tlog\\t--oneline\\t--decorate\\n\\t\\n4\\n.\\t\\nThe\\tchanges\\twe\\tmade\\tin\\tthe\\tlast\\tcommit\\thave\\tbeen\\tmoved\\tback\\tto\\tthe\\tworking\\tdirectory:\\t\\n\\t\\ngit\\tstatus\\n\\t\\n5\\n.\\t\\nAll\\tthe\\tfiles\\tstill\\texist\\tlocally:\\t\\n\\t\\nls\\n\\t\\n6\\n.\\t\\nMove\\tthe\\tfiles\\tto\\tthe\\tstaging\\tarea\\tbefore\\twe\\tcan\\tcommit\\tthem:\\t\\n\\t\\ngit\\tadd\\tfile5.md\\tfile6.md\\n\\t\\n7\\n.\\t\\nRe-commit\\tthe\\tfiles:\\t\\n\\t\\ngit\\tcommit\\t-m\\t\"re-add\\tfile\\t5\\tand\\t6\"\\n\\t\\nNotice\\tthat\\talthough\\twe\\thave\\tessentially\\tmade\\tthe\\texact\\tsame\\tcommit\\t(adding\\tfile\\t5\\tand\\t6\\ttogether\\twith\\tthe\\nsame\\tHEAD\\tand\\tcommit\\tmessage)\\twe\\tstill\\tget\\ta\\tnew\\tcommit\\tID.\\tThis\\tcan\\thelp\\tus\\tsee\\twhy\\tthe\\treset\\tcommand\\nshould\\tnever\\tbe\\tused\\ton\\tcommits\\tthat\\thave\\tbeen\\tpushed\\tto\\tthe\\tremote.\\nReset\\tHard\\nLast\\tbut\\tnot\\tleast,\\tlet\\'s\\ttry\\ta\\thard\\treset.\\n1\\n.\\t\\nStart\\tby\\tviewing\\tthe\\thistory\\tof\\tour\\tproject\\twith:\\t\\n\\t\\ngit\\tlog\\t--oneline\\n\\t\\n2\\n.\\t\\nReset\\tto\\tthe\\tpoint\\tin\\ttime\\twhere\\tthe\\tonly\\tfile\\tthat\\texisted\\twas\\tthe\\tREADME.md:\\t\\n\\t\\ngit\\treset\\t--hard\\t<SHA>\\n\\t\\n3\\n.\\t\\nSee\\tthat\\tall\\tof\\tthe\\tcommits\\tare\\tgone:\\t\\n\\t\\ngit\\tlog\\t--oneline\\n\\t\\n4\\n.\\t\\nNotice\\tyour\\tworking\\tdirectory\\tis\\tclean:\\t\\n\\t\\ngit\\tstatus\\n\\t\\n5\\n.\\t\\nSee\\tthat\\tthe\\tonly\\tfiles\\tin\\tyour\\trepository\\tare\\tthe\\tREADME.md\\tand\\tfile7.md:\\t\\n\\t\\nls\\n\\t\\nWarning:\\n\\tRemember,\\t\\n\\t\\ngit\\treset\\t--hard\\n\\t\\n\\toverwrites\\tyour\\tworking\\tdirectory,\\tstaging\\tarea,\\tand\\thistory.\\tThis\\nmeans\\tthat\\tuncommitted\\tchanges\\tyou\\thave\\tmade\\tto\\tyour\\tfiles\\twill\\tbe\\tcompletely\\tlost.\\tDon\\'t\\tuse\\tit\\tunless\\tyou\\nreally\\twant\\tto\\tdiscard\\tyour\\tchanges.\\tAny\\tfiles\\tthat\\tare\\tuntracked\\twill\\tremain\\tand\\tbe\\tunchanged.\\nDoes\\tGone\\tReally\\tMean\\tGone?\\nThe\\tanswer:\\tIt\\tdepends!\\n$\\tgit\\treflog\\nThe\\treflog\\tis\\ta\\trecord\\tof\\tevery\\tplace\\tHEAD\\thas\\tbeen.\\tIn\\ta\\tfew\\tminutes\\twe\\twill\\tsee\\thow\\tthe\\treflog\\tcan\\tbe\\thelpful\\tin\\nallowing\\tus\\tto\\trestore\\tpreviously\\tcommitted\\tchanges.\\tBut\\tfirst,\\twe\\tneed\\tto\\tbe\\taware\\tof\\tsome\\tof\\tthe\\treflog\\'s\\tlimitations:\\nRewriting\\tHistory\\twith\\tGit\\tReset\\n52', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ca16bd55-adfb-4d3f-8b53-4950df74d35e', embedding=None, metadata={'page_label': '53', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The\\treflog\\tis\\tonly\\tlocal.\\n\\tIt\\tis\\tnot\\tpushed\\tto\\tthe\\tremote\\tand\\tonly\\tincludes\\tyour\\tlocal\\thistory.\\tIn\\tother\\twords,\\tyou\\ncan\\'t\\tsee\\tthe\\treflog\\tfor\\tsomeone\\telse\\'s\\tcommits\\tand\\tthey\\tcan\\'t\\tsee\\tyours.\\nThe\\treflog\\tis\\ta\\tlimited\\ttime\\toffer.\\n\\tBy\\tdefault,\\treachable\\tcommits\\tare\\tdisplayed\\tin\\tthe\\treflog\\tfor\\t90\\tdays,\\tbut\\nunreachable\\tcommits\\t(meaning\\tcommits\\tthat\\tare\\tnot\\tattached\\tto\\ta\\tbranch)\\tare\\tonly\\tdisplayed\\tfor\\t30\\tdays.\\nSometimes,\\tyou\\'ll\\twant\\tto\\tsave\\tyour\\twork\\tin\\ta\\tcommit\\twithout\\thaving\\tto\\tthink\\tof\\ta\\tcommit\\tmessage,\\tor\\tbefore\\nyou\\'re\\tready\\tto\\torganize\\tyour\\tchanges.\\tIf\\tthat\\'s\\tthe\\tcase,\\tyou\\tcan\\tcreate\\taliases\\tto\\tcreate\\t\"save\\tpoints\".\\tSee\\nthe\\tappendix\\twith\\taliases\\tto\\tlearn\\thow!\\nRewriting\\tHistory\\twith\\tGit\\tReset\\n53', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='33c588c1-e5d8-45e3-91c4-680be8016b9e', embedding=None, metadata={'page_label': '54', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Getting\\tit\\tBack:\\t\\n\\t\\ngit\\tcherry-pick\\n\\t\\nWe\\tjust\\tlearned\\thow\\treflog\\tcan\\thelp\\tus\\tfind\\tlocal\\tchanges\\tthat\\thave\\tbeen\\tdiscarded.\\tSo\\twhat\\tif:\\nYou\\tJust\\tWant\\tThat\\tOne\\tCommit\\nCherry\\tpicking\\tallows\\tyou\\tto\\tpick\\tup\\ta\\tcommit\\tfrom\\tyour\\treflog\\tor\\tanother\\tbranch\\tof\\tyour\\tproject\\tand\\tmove\\tit\\tto\\tyour\\ncurrent\\tbranch.\\tRight\\tnow,\\tyour\\tfile\\tdirectory\\tand\\tlog\\tshould\\tlook\\tlike\\tthis:\\n$\\tls\\nREADME.md\\n$\\tgit\\t\\nlog\\n\\t--oneline\\n84nqdkq\\tinitializing\\trepo\\twith\\tREADME\\nLet's\\tcherry\\tpick\\tthe\\tcommit\\twhere\\twe\\tadded\\tfile\\t4:\\n1\\n.\\t\\nFind\\tthe\\tcommit\\tID\\twhere\\tyou\\tadded\\tfile4.md:\\t\\n\\t\\ngit\\treflog\\n\\t\\n2\\n.\\t\\nCherry-pick\\tthat\\tcommit:\\t\\n\\t\\ngit\\tcherry-pick\\t<SHA>\\n\\t\\nNow\\twhen\\tyou\\tview\\tyour\\tdirectory\\tand\\tlog,\\tyou\\tshould\\tsee:\\n$\\tls\\nfile4.md\\nREADME.md\\n$\\tgit\\t\\nlog\\n\\t--oneline\\neanu482\\tadding\\tfile\\t4\\n84nqdkq\\tinitializing\\trepo\\twith\\tREADME\\nIs\\tthe\\tcommit\\tID\\tthe\\tsame\\tas\\tthe\\tone\\tyou\\tused\\tin\\tthe\\tcherry\\tpick\\tcommand?\\tWhy\\tor\\twhy\\tnot?\\nRemember,\\twhen\\tusing\\tany\\tcommands\\tthat\\tchange\\thistory,\\tit's\\timportant\\tto\\tmake\\tthese\\tchanges\\tbefore\\npushing\\tto\\tGitHub.\\tWhen\\tyou\\tchange\\ta\\tcommit\\tID\\tthat\\thas\\tbeen\\tpushed\\tto\\tthe\\tremote,\\tyou\\trisk\\tcreating\\nproblems\\tfor\\tyour\\tcollaborators.\\t{:\\t.warning}\\nOops,\\tI\\tDidn't\\tMean\\tto\\tReset\\nSometimes,\\tyou\\t\\n\\t\\ngit\\treset\\t--hard\\n\\t\\n\\ta\\tlittle\\tfurther\\tthan\\tintended\\tand\\twant\\tto\\trestore\\tthat\\twork.\\tThe\\tgood\\tnews\\tis,\\tthat\\n\\t\\ngit\\treset\\t--hard\\n\\t\\n\\tdoesn't\\tjust\\twork\\tby\\tgoing\\tback\\tin\\ttime,\\tit\\tcan\\talso\\tgo\\tforward:\\n1\\n.\\t\\nView\\tthe\\thistory\\tof\\teverywhere\\tHEAD\\thas\\tpointed:\\t\\n\\t\\ngit\\treflog\\n\\t\\n2\\n.\\t\\nReset\\tto\\tthe\\tpoint\\tin\\ttime\\twhere\\tthe\\toriginal\\t\\n\\t\\nfile6.md\\n\\t\\n\\twas\\tcreated:\\t\\n\\t\\ngit\\treset\\t--hard\\t<SHA>\\n\\t\\n3\\n.\\t\\nSee\\tyour\\trestored\\thistory:\\t\\n\\t\\ngit\\tlog\\t--oneline\\n\\t\\nTake\\ta\\tlook\\tat\\tthe\\tcommit\\tIDs\\tin\\t\\n\\t\\ngit\\tlog\\t--oneline\\n\\t\\n\\tcompared\\tto\\t\\n\\t\\ngit\\treflog\\n\\t\\n.\\tWhat\\tdo\\tyou\\tnotice?\\nWhy\\tdidn't\\tthis\\tcommand\\tcause\\ta\\tmerge\\tconflict\\tsince\\twe\\thad\\talready\\tcherry-picked\\tfile\\t4.\\tThe\\treason\\tis\\tthat\\n\\t\\ngit\\treset\\t--hard\\n\\t\\n\\tis\\tnot\\ttrying\\tto\\tmerge\\tthe\\ttwo\\thistories\\ttogether,\\tit\\tis\\tsimply\\tmoving\\tthe\\tbranch\\tto\\tpoint\\tto\\ta\\nnew\\tcommit.\\tIn\\tthis\\tcase,\\tthis\\twas\\twhat\\twe\\twanted.\\tIn\\tother\\tcases,\\tthis\\tcould\\tcause\\tus\\tto\\tlose\\tany\\twork\\twe\\nmay\\thave\\tdone\\tafter\\tthe\\toriginal\\treset.\\nSee\\thow\\tto\\tavoid\\ttragedy\\twith\\ta\\tconvenient\\talias\\tin\\tthe\\tappendix.\\nCherry\\tPicking\\n54\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='e26eaaee-f640-4c2c-b41b-86e5f74a3fac', embedding=None, metadata={'page_label': '55', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Cherry\\tPicking\\n55', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ba4d3336-ec3f-432e-9773-71757c7c991c', embedding=None, metadata={'page_label': '56', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Merge\\tStrategies:\\tRebase\\nIn\\tthis\\tsection,\\twe\\twill\\tdiscuss\\tanother\\tpopular\\tmerge\\tstrategy,\\trebasing.\\nUnderstanding\\tGit\\tMerge\\tStrategies\\nGit\\tuses\\tthree\\tprimary\\tmerge\\tstrategies:\\nFast\\tForward\\nA\\tfast\\tforward\\tmerge\\tassumes\\tthat\\tno\\tchanges\\thave\\tbeen\\tmade\\ton\\tthe\\tbase\\tbranch\\tsince\\tthe\\tfeature\\tbranch\\twas\\ncreated.\\tThis\\tmeans\\tthat\\tthe\\tbranch\\tpointer\\tfor\\tbase\\tcan\\tsimply\\tbe\\t\"fast\\tforwarded\"\\tto\\tpoint\\tto\\tthe\\tsame\\tcommit\\tas\\nthe\\tfeature\\tbranch.\\nRecursive\\nA\\trecursive\\tmerge\\tmeans\\tthat\\tchanges\\thave\\tbeen\\tmade\\ton\\tboth\\tthe\\tbase\\tbranch\\tand\\tthe\\tfeature\\tbranch\\tand\\tgit\\nneeds\\tto\\trecursively\\tcombine\\tthem.\\tWith\\ta\\trecursive\\tmerge,\\ta\\tnew\\t\"merge\\tcommit\"\\tis\\tmade\\tto\\tmark\\tthe\\tpoint\\tin\\ttime\\nwhen\\tthe\\ttwo\\tbranches\\tcame\\ttogether.\\tThis\\tmerge\\tcommit\\tis\\tspecial\\tbecause\\tit\\thas\\tmore\\tthan\\tone\\tparent.\\nOctopus\\nA\\tmerge\\tof\\t3\\tor\\tmore\\tbranches\\tis\\tan\\toctopus\\tmerge.\\tThis\\twill\\talso\\tcreate\\ta\\tmerge\\tcommit\\twith\\tmultiple\\tparents.\\nAbout\\tGit\\tRebase\\n\\t\\ngit\\trebase\\n\\t\\n\\tenables\\tyou\\tto\\tmodify\\tyour\\tcommit\\thistory\\tin\\ta\\tvariety\\tof\\tways.\\tFor\\texample,\\tyou\\tcan\\tuse\\tit\\tto\\treorder\\ncommits,\\tedit\\tthem,\\tsquash\\tmultiple\\tcommits\\tinto\\tone,\\tand\\tmuch\\tmore.\\nTo\\tenable\\tall\\tof\\tthis,\\t\\n\\t\\nrebase\\n\\t\\n\\tcomes\\tin\\tseveral\\tforms.\\tFor\\ttoday\\'s\\tclass,\\twe\\'ll\\tbe\\tusing\\tinteractive\\trebase:\\t\\n\\t\\ngit\\trebase\\n--interactive\\n\\t\\n,\\tor\\t\\n\\t\\ngit\\trebase\\t-i\\n\\t\\n\\tfor\\tshort.\\nTypically,\\tyou\\twould\\tuse\\t\\n\\t\\ngit\\trebase\\t-i\\n\\t\\n\\tto:\\nReplay\\tone\\tbranch\\ton\\ttop\\tof\\tanother\\tbranch\\nEdit\\tprevious\\tcommit\\tmessages\\nCombine\\tmultiple\\tcommits\\tinto\\tone\\nDelete\\tor\\trevert\\tcommits\\tthat\\tare\\tno\\tlonger\\tnecessary\\nCreating\\ta\\tLinear\\tHistory\\nOne\\tof\\tthe\\tmost\\tcommon\\tuses\\tof\\trebase\\tis\\tto\\teliminate\\trecursive\\tmerges\\tand\\tcreate\\ta\\tmore\\tlinear\\thistory.\\tIn\\tthis\\nactivity,\\twe\\twill\\tlearn\\thow\\tit\\tis\\tdone.\\nMerge\\tStrategies\\n56', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='af9766ef-7767-4b85-a3b2-27fb5308977f', embedding=None, metadata={'page_label': '57', 'file_name': 'github_manual.pdf', 'file_path': '/Users/adityajamwal/My Drive/AI DataScience Related Opportunities/UNC AI Bootcamp/UNC AI Bootcamp Material/23-Project-3/data/github_manual.pdf', 'file_type': 'application/pdf', 'file_size': 2237837, 'creation_date': '2024-05-13', 'last_modified_date': '2024-05-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"Set\\tUp\\n1\\n.\\t\\nFind\\tthe\\tSHA\\tof\\tthe\\tinitial\\tcommit:\\t\\n\\t\\ngit\\tlog\\t--oneline\\n\\t\\n2\\n.\\t\\nReset\\tto\\tthe\\tSHA\\tof\\tthe\\tinitial\\tcommit:\\t\\n\\t\\ngit\\treset\\t--hard\\tSHA\\n\\t\\n3\\n.\\t\\nCreate\\ta\\tnew\\tbranch\\tand\\tcheck\\tout\\tto\\tit:\\t\\n\\t\\ngit\\tcheckout\\t-b\\trebase-me\\n\\t\\n4\\n.\\t\\nCherry-pick\\tfiles\\t4-6\\tonto\\tthe\\t\\n\\t\\nrebase-me\\n\\t\\n\\tbranch\\tusing\\tthe\\treflog.\\n5\\n.\\t\\nCheckout\\tto\\tmaster:\\t\\n\\t\\ngit\\tcheckout\\tmaster\\n\\t\\n6\\n.\\t\\nCherry-pick\\tfiles\\t1-3\\tonto\\tthe\\t\\n\\t\\nmaster\\n\\t\\n\\tbranch\\tusing\\tthe\\treflog.\\n7\\n.\\t\\nLook\\tat\\tyour\\thistory:\\t\\n\\t\\ngit\\tlog\\t--oneline\\t--graph\\t--decorate\\t--all\\n\\t\\n8\\n.\\t\\nIf\\tyou\\tmerged\\tnow,\\tit\\twould\\tbe\\ta\\trecursive\\tmerge.\\nBegin\\tthe\\tRebase\\n1\\n.\\t\\nCheckout\\tto\\tthe\\t\\n\\t\\nrebase-me\\n\\t\\n\\tbranch:\\t\\n\\t\\ngit\\tcheckout\\trebase-me\\n\\t\\n2\\n.\\t\\nStart\\tthe\\tmerge:\\t\\n\\t\\ngit\\trebase\\t-i\\tmaster\\n\\t\\n3\\n.\\t\\nYour\\ttext\\teditor\\twill\\topen,\\tallowing\\tyou\\tto\\tsee\\tthe\\tcommits\\tto\\tbe\\trebased.\\n4\\n.\\t\\nSave\\tand\\tclose\\tthe\\t\\n\\t\\nrebase-todo\\n\\t\\n.\\n5\\n.\\t\\nWatch\\tyour\\trebase\\thappen\\ton\\tthe\\tcommand\\tline.\\n6\\n.\\t\\nTake\\tanother\\tlook\\tat\\tyour\\thistory:\\t\\n\\t\\ngit\\tlog\\t--oneline\\t--graph\\t--decorate\\t--all\\n\\t\\n7\\n.\\t\\nIf\\tyou\\tmerged\\tnow,\\tit\\twould\\tbe\\ta\\tfast-forward\\tmerge.\\nFinish\\tthe\\tMerge\\n1\\n.\\t\\nCheckout\\tto\\tmaster,\\tthe\\tbranch\\tyou\\twill\\tmerge\\tinto:\\t\\n\\t\\ngit\\tcheckout\\tmaster\\n\\t\\n2\\n.\\t\\nMerge\\tyour\\tchanges\\tin\\tto\\tmaster:\\t\\n\\t\\ngit\\tmerge\\trebase-me\\n\\t\\nIf\\tyou'd\\tlike\\tsome\\thelp\\tkeeping\\teverything\\tclean\\twith\\tan\\talias,\\tdon't\\tforget\\tto\\tcheck\\tthe\\tappendix!\\nMerge\\tStrategies\\n57\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.core import Document, VectorStoreIndex\n",
        "\n",
        "chunks = []\n",
        "for chunk in doc.chunks():\n",
        "    chunks.append(Document(text=chunk.to_context_text(), extra_info={}))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/adityajamwal/anaconda3/envs/dev/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/Users/adityajamwal/anaconda3/envs/dev/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/adityajamwal/anaconda3/envs/dev/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "embeddings_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embeddings_model = HuggingFaceEmbeddings(model_name=embeddings_model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import chromadb\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore # pip install llama-index-vector-stores-postgres\n",
        "from llama_index.core import StorageContext\n",
        "# pip install llama-index-vector-stores-chroma\n",
        "\n",
        "# load some documents\n",
        "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
        "\n",
        "# initialize client, setting path to save data\n",
        "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "# create collection\n",
        "chroma_collection = db.get_or_create_collection(\"quickstart\")\n",
        "\n",
        "# assign chroma as the vector_store to the context\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# create your index\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    chunks, storage_context=storage_context, embed_model=embeddings_model\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/adityajamwal/anaconda3/envs/dev/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "This manual appears to be about using GitHub for collaborating on projects. The text mentions \"Understanding the GitHub flow\" and \"Getting Started With Collaboration,\" indicating that the content will cover the basics of using GitHub for version control and working with others on code. The file named \"README.md\" is also mentioned, which is typically a file that explains a project and provides helpful information for new users.\n"
          ]
        }
      ],
      "source": [
        "# create a query engine and query\n",
        "query_engine = index.as_query_engine(llm=llm)\n",
        "response = query_engine.query(\"What is this manual about?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGqsLP5zmirK",
        "outputId": "cb521786-ef48-4e95-8577-5a08e2c59b74"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import Document, VectorStoreIndex\n",
        "\n",
        "index = VectorStoreIndex([])\n",
        "for chunk in doc.chunks():\n",
        "    index.insert(Document(text=chunk.to_context_text(), extra_info={}))\n",
        "query_engine = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f797GR6nGKw"
      },
      "source": [
        "Let's run one query:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC9H9c38nOsG",
        "outputId": "bbbe1616-1765-41d9-fd71-997b9b380363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "1. First, create a new repository on GitHub. Give it a descriptive name and a brief description that explains the purpose of the project.\n",
            "2. Once the repository is created, add all the team members as collaborators. This will allow them to clone, commit, and push changes to the repository.\n",
            "3. Decide on a branching strategy, such as GitHub flow, and create branches for each feature or bug fix.\n",
            "4. Set up GitHub Pages for the project site. Depending on the settings for your repository, GitHub can serve your site from a master or gh-pages branch or a /docs folder on the master branch.\n",
            "5. Use pull requests to merge changes from branches to the master branch. This allows for code review and discussion before merging changes.\n",
            "6. Make sure to frequently merge the master branch to ensure that all team members have the latest changes.\n",
            "7. Lastly, make sure to commit and push changes regularly to keep the repository up to date and to allow for easy rollback if necessary.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"If we are working on a group project, how should we setup the github repository?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ylioaL0nUyr"
      },
      "source": [
        "Let's try another query that needs answer from a table:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZEHBSsnnc30",
        "outputId": "db684d29-8757-4180-a922-ab7a14d07567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Branching strategy refers to a method used in software development to create and manage multiple branches of a project's source codebase simultaneously. This approach allows developers to work on different features, bug fixes, or improvements independently, without affecting the main codebase or each other's work. By using a branching strategy, teams can collaborate more efficiently, reduce merge conflicts, and ensure that the codebase remains stable and ready for release. Common branching strategies include GitFlow, GitHub Flow, and Forking.\n",
            "\n",
            "Discussion Guide: Team Workflows and Branching Strategies\n",
            "1. Which branching strategy will we use?\n",
            "\n",
            "Branching with Git > GitFlow\n",
            "Let's discuss GitFlow and its benefits.\n",
            "---------------------\n",
            "Given the context information and the understanding of branching strategy, answer the query.\n",
            "Query: What is GitFlow and why is it used?\n",
            "Answer: GitFlow is a popular branching strategy for managing larger software projects with multiple developers. It is based on the Git version control system and consists of the following branches:\n",
            "\n",
            "1. master branch: The main branch where only stable, production-ready code is merged. It represents the current release.\n",
            "2. develop branch: A branch for integrating all the new features, enhancements, and bug fixes. It is the default branch for continuous integration and represents the next release.\n",
            "3. feature branches: Branches created for individual features or improvements. Developers can work on these branches independently without affecting the main codebase.\n",
            "4. release branches: Branches created for preparing a specific release. They are created from the develop branch when the features are ready for release.\n",
            "5. hotfix branches: Branches created to fix critical bugs in the master or develop branch. These branches are merged back into the main branches as soon as possible.\n",
            "\n",
            "GitFlow is used because it offers a clear separation of concerns for different stages of the software development process. It ensures that each feature is properly tested and integrated before being merged into the main branches. This reduces the risk of introducing bugs into the production codebase and helps maintain a stable release cycle.\n",
            "\n",
            "Discussion Guide: Team Workflows and Branching Strategies\n",
            "1. Which branching strategy will we use?\n",
            "\n",
            "Branching with Git > GitHub Flow\n",
            "Let's discuss GitHub Flow and its benefits.\n",
            "---------------------\n",
            "Given the context information and the understanding of branching strategy, answer the query.\n",
            "Query: What is GitHub Flow and why is it used?\n",
            "Answer: GitHub Flow is a simple and flexible branching model for smaller teams or projects that value frequent releases. It is inspired by GitFlow but has fewer branches and is easier to implement. GitHub Flow consists of the following branches:\n",
            "\n",
            "1. master branch: The main branch where only stable, production-ready code is merged. It represents the current release.\n",
            "2. feature branches or pull requests: Developers create new branches or pull requests for their features or improvements. They work on these branches independently and collaborate with their team members by reviewing and merging their changes into their own branch.\n",
            "3. releases: When a feature branch is ready to be merged into the master branch, it is merged into a new release branch. This release branch is then tagged with a version number and deployed to production. Once the release is stable, the release branch is merged back into the master branch.\n",
            "\n",
            "GitHub Flow is used because it encourages continuous integration and frequent releases. It also provides an easy way for teams to collaborate and review each other's work. This results in a faster development cycle, fewer merge conflicts, and a more stable codebase. It is particularly useful for teams that value agility, as it allows them to quickly respond to customer feedback and market changes.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"Explain what you mean by branching strategy\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT67xijEnh1X"
      },
      "source": [
        "**Get the Raw JSON**\n",
        "\n",
        "To get the complete json returned by llmsherpa service and process it differently, simply get the json attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YHwKINfnri7",
        "outputId": "b676008e-2b25-40b8-d4fd-0e5bf6ba47df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'block_class': 'cls_0',\n",
              "  'block_idx': 0,\n",
              "  'level': 0,\n",
              "  'page_idx': 0,\n",
              "  'sentences': ['BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_1',\n",
              "  'block_idx': 1,\n",
              "  'level': 0,\n",
              "  'page_idx': 0,\n",
              "  'sentences': ['Mike Lewis*, Yinhan Liu*, Naman Goyal*, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, Luke Zettlemoyer Facebook AI'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_5',\n",
              "  'block_idx': 2,\n",
              "  'level': 1,\n",
              "  'page_idx': 0,\n",
              "  'sentences': ['{mikelewis,yinhanliu,naman}@fb.com'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_1',\n",
              "  'block_idx': 3,\n",
              "  'level': 2,\n",
              "  'page_idx': 0,\n",
              "  'sentences': ['Abstract'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 4,\n",
              "  'level': 3,\n",
              "  'page_idx': 0,\n",
              "  'sentences': ['We present BART, a denoising autoencoder for pretraining sequence-to-sequence models.',\n",
              "   'BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text.',\n",
              "   'It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and many other more recent pretraining schemes.',\n",
              "   'We evaluate a number of noising approaches, ﬁnding the best performance by both randomly shufﬂing the order of the original sentences and using a novel in-ﬁlling scheme, where spans of text are replaced with a single mask token.',\n",
              "   'BART is particularly effective when ﬁne tuned for text generation but also works well for comprehension tasks.',\n",
              "   'It matches the performance of RoBERTa with comparable training resources on GLUE and SQuAD, achieves new stateof-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 6 ROUGE.',\n",
              "   'BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining.',\n",
              "   'We also report ablation experiments that replicate other pretraining schemes within the BART framework, to better measure which factors most inﬂuence end-task performance.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_1',\n",
              "  'block_idx': 5,\n",
              "  'level': 2,\n",
              "  'page_idx': 0,\n",
              "  'sentences': ['1 Introduction'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 6,\n",
              "  'level': 3,\n",
              "  'page_idx': 0,\n",
              "  'sentences': ['methods have achieved remarkable success in a wide range of NLP tasks (Mikolov et al., 2013; Peters et al., 2018; Devlin et al., 2019; Joshi et al., 2019; Yang et al., 2019; Liu et al., 2019).',\n",
              "   'The most successful approaches have been variants of masked language models, which are denoising autoencoders that are trained to reconstruct text where a random subset of the words has been masked out.',\n",
              "   'Recent work has shown gains by improving the distribution of masked tokens (Joshi et al., 2019), the order in which masked tokens are predicted (Yang et al., 2019), and the available context for replacing masked tokens (Dong et al., 2019).',\n",
              "   'However, these methods typically focus on particular types of end tasks (e.g. span prediction, generation, etc.), limiting their applicability.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 7,\n",
              "  'level': 3,\n",
              "  'page_idx': 0,\n",
              "  'sentences': ['In this paper, we present BART, which pre-trains a model combining Bidirectional and Auto-Regressive Transformers.',\n",
              "   'BART is a denoising autoencoder built with a sequence-to-sequence model that is applicable to a very wide range of end tasks.',\n",
              "   'Pretraining has two stages (1) text is corrupted with an arbitrary noising function, and (2) a sequence-to-sequence model is learned to reconstruct the original text.',\n",
              "   'BART uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and many other more recent pretraining schemes (see Figure 1).'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 8,\n",
              "  'level': 3,\n",
              "  'page_idx': 0,\n",
              "  'sentences': ['A key advantage of this setup is the noising ﬂexibility; arbitrary transformations can be applied to the original text, including changing its length.',\n",
              "   'We evaluate a number of noising approaches, ﬁnding the best performance by both randomly shufﬂing the order of the original sentences and using a novel in-ﬁlling scheme, where arbitrary length spans of text (including zero length) are replaced with a single mask token.',\n",
              "   'This approach generalizes the original word masking and next sentence prediction objectives in BERT by forcing the model to reason more about overall sentence length and make longer range transformations to the input.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 9,\n",
              "  'level': 3,\n",
              "  'page_idx': 0,\n",
              "  'sentences': ['BART is particularly effective when ﬁne tuned for text generation but also works well for comprehension tasks.',\n",
              "   'It matches the performance of RoBERTa (Liu et al., 2019) with comparable training resources on GLUE (Wang et al., 2018) and SQuAD (Rajpurkar et al., 2016), and achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks.',\n",
              "   'For example, it improves performance by 6 ROUGE over previous work on XSum (Narayan et al., 2018).'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 10,\n",
              "  'level': 3,\n",
              "  'page_idx': 0,\n",
              "  'sentences': ['BART also opens up new ways of thinking about ﬁne tuning.',\n",
              "   'We present a new scheme for machine translation where a BART model is stacked above a few additional transformer layers.',\n",
              "   'These layers are trained to essentially translate the foreign language to noised'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_10',\n",
              "  'block_idx': 11,\n",
              "  'level': 3,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['B D A B C D E'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_10',\n",
              "  'block_idx': 12,\n",
              "  'level': 4,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['Autoregressive Decoder'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_8',\n",
              "  'block_idx': 13,\n",
              "  'level': 3,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['Bidirectional Encoder'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_8',\n",
              "  'block_idx': 14,\n",
              "  'level': 4,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['A _ C _ E'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_10',\n",
              "  'block_idx': 15,\n",
              "  'level': 5,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['<s> A B C D'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_9',\n",
              "  'block_idx': 16,\n",
              "  'level': 6,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['(a) BERT: Random tokens are replaced with masks, and the document is encoded bidirectionally.',\n",
              "   'Missing tokens are predicted independently, so BERT cannot easily be (b) GPT: Tokens are predicted auto-regressively, meaning GPT can be used for generation.',\n",
              "   'However words can only condition on leftward context, so it cannot learn bidirec- tional interactions.'],\n",
              "  'tag': 'list_item'},\n",
              " {'block_class': 'cls_9',\n",
              "  'block_idx': 17,\n",
              "  'level': 6,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['used for generation.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_10',\n",
              "  'block_idx': 18,\n",
              "  'level': 6,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['A B C D E'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_10',\n",
              "  'block_idx': 19,\n",
              "  'left': 211.35,\n",
              "  'level': 7,\n",
              "  'name': 'A B C D E',\n",
              "  'page_idx': 1,\n",
              "  'table_rows': [{'block_idx': 19,\n",
              "    'cells': [{'cell_value': 'Bidirectional Encoder'},\n",
              "     {'cell_value': 'Autoregressive Decoder'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 20,\n",
              "    'cell_value': 'A _ B _ E <s> A B C D',\n",
              "    'col_span': 2,\n",
              "    'type': 'full_row'}],\n",
              "  'tag': 'table',\n",
              "  'top': 226.4},\n",
              " {'block_class': 'cls_9',\n",
              "  'block_idx': 21,\n",
              "  'level': 6,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['(c) BART: Inputs to the encoder need not be aligned with decoder outputs, allowing arbitary noise transformations.',\n",
              "   'Here, a document has been corrupted by replacing spans of text with mask symbols.',\n",
              "   'The corrupted document (left) is encoded with a bidirectional model, and then the likelihood of the original document (right) is calculated with an autoregressive decoder.',\n",
              "   'For ﬁne-tuning, an uncorrupted document is input to both the encoder and decoder, and we use representations from the ﬁnal hidden state of the decoder.'],\n",
              "  'tag': 'list_item'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 22,\n",
              "  'level': 6,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['Figure 1: A schematic comparison of BART with BERT (Devlin et al., 2019) and GPT (Radford et al., 2018).'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 23,\n",
              "  'level': 6,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['English, by propagation through BART, thereby using BART as a pre-trained target-side language model.',\n",
              "   'This approach improves performance over a strong back-translation MT baseline by 1.1 BLEU on the WMT Romanian-English benchmark.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 24,\n",
              "  'level': 6,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['To better understand these effects, we also report an ablation analysis that replicates other recently proposed training objectives.',\n",
              "   'This study allows us to carefully control for a number of factors, including data and optimization parameters, which have been shown to be as important for overall performance as the selection of training objectives (Liu et al., 2019).',\n",
              "   'We ﬁnd that BART exhibits the most consistently strong performance across the full range of tasks we consider.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_1',\n",
              "  'block_idx': 25,\n",
              "  'level': 2,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['2 Model'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 26,\n",
              "  'level': 3,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['is a denoising autoencoder that maps a corrupted document to the original document it was derived from.',\n",
              "   'It is implemented as a sequence-to-sequence model with a bidirectional encoder over corrupted text and a left-to-right autoregressive decoder.',\n",
              "   'For pre-training, we optimize the negative log likelihood of the original document.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_11',\n",
              "  'block_idx': 27,\n",
              "  'level': 3,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['2.1 Architecture'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 28,\n",
              "  'level': 4,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['BART uses the standard sequence-to-sequence Transformer architecture from (Vaswani et al., 2017), except, following GPT, that we modify ReLU activation functions to GeLUs (Hendrycks & Gimpel, 2016) and initialise parameters from N (0, 0.02).',\n",
              "   'For our base model, we use 6 layers in the encoder and de- coder, and for our large model we use 12 layers in each.',\n",
              "   'The architecture is closely related to that used in BERT, with the following differences: (1) each layer of the decoder additionally performs cross-attention over the ﬁnal hidden layer of the encoder (as in the transformer sequence-to-sequence model); and (2) BERT uses an additional feed-forward network before wordprediction, which BART does not.',\n",
              "   'In total, BART contains roughly 10% more parameters than the equivalently sized BERT model.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_11',\n",
              "  'block_idx': 29,\n",
              "  'level': 3,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['2.2 Pre-training BART'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 30,\n",
              "  'level': 4,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['BART is trained by corrupting documents and then optimizing a reconstruction loss—the cross-entropy between the decoder’s output and the original document.',\n",
              "   'Unlike existing denoising autoencoders, which are tailored to speciﬁc noising schemes, BART allows us to apply any type of document corruption.',\n",
              "   'In the extreme case, where all information about the source is lost, BART is equivalent to a language model.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 31,\n",
              "  'level': 4,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['We experiment with several previously proposed and novel transformations, but we believe there is a signiﬁcant potential for development of other new alternatives.',\n",
              "   'The transformations we used are summarized below, and examples are shown in Figure 2.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 32,\n",
              "  'level': 4,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['Token Masking Following BERT (Devlin et al., 2019), random tokens are sampled and replaced with [MASK] elements.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 33,\n",
              "  'level': 4,\n",
              "  'page_idx': 1,\n",
              "  'sentences': ['Token Deletion Random tokens are deleted from the input.',\n",
              "   'In contrast to token masking, the model must decide which positions are missing inputs.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_16',\n",
              "  'block_idx': 34,\n",
              "  'left': 152.36,\n",
              "  'level': 3,\n",
              "  'name': '2.2 Pre-training BART',\n",
              "  'page_idx': 2,\n",
              "  'table_rows': [{'block_idx': 34,\n",
              "    'cells': [{'cell_value': 'A _C . _ E .'},\n",
              "     {'cell_value': 'D E . A B C .'},\n",
              "     {'cell_value': 'C . D E . A B'}],\n",
              "    'type': 'table_header'},\n",
              "   {'block_idx': 35,\n",
              "    'cells': [{'cell_value': ''},\n",
              "     {'cell_value': 'Sentence Permutation'},\n",
              "     {'cell_value': 'Document RotationToken Masking'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 36,\n",
              "    'cells': [{'cell_value': ''},\n",
              "     {'cell_value': 'A B C . D E .A . C . E .'},\n",
              "     {'cell_value': 'A _ . D _ E .'}],\n",
              "    'type': 'table_data_row'}],\n",
              "  'tag': 'table',\n",
              "  'top': 65.33},\n",
              " {'block_class': 'cls_16',\n",
              "  'block_idx': 37,\n",
              "  'level': 3,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['Token Deletion Text Inﬁlling'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 38,\n",
              "  'level': 4,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['Figure 2: Transformations for noising the input that we experiment with.',\n",
              "   'These transformations can be composed.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 39,\n",
              "  'level': 4,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['Text Inﬁlling A number of text spans are sampled, with span lengths drawn from a Poisson distribution (λ = 3).',\n",
              "   'Each span is replaced with a single [MASK] token.',\n",
              "   '0-length spans correspond to the insertion of [MASK] tokens.',\n",
              "   'Text inﬁlling is inspired by SpanBERT (Joshi et al., 2019), but SpanBERT samples span lengths from a different (clamped geometric) distribution, and replaces each span with a sequence of [MASK] tokens of exactly the same length.',\n",
              "   'Text inﬁlling teaches the model to predict how many tokens are missing from a span.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 40,\n",
              "  'level': 4,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['Sentence Permutation A document is divided into sentences based on full stops, and these sentences are shufﬂed in a random order.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 41,\n",
              "  'level': 4,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['Document Rotation A token is chosen uniformly at random, and the document is rotated so that it begins with that token.',\n",
              "   'This task trains the model to identify the start of the document.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_1',\n",
              "  'block_idx': 42,\n",
              "  'level': 2,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['3 Fine-tuning BART'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 43,\n",
              "  'level': 3,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['The representations produced by BART can be used in several ways for downstream applications.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_11',\n",
              "  'block_idx': 44,\n",
              "  'level': 3,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['3.1 Sequence Classiﬁcation Tasks'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 45,\n",
              "  'level': 3,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['For sequence classiﬁcation tasks, the same input is fed into the encoder and decoder, and the ﬁnal hidden state of the ﬁnal decoder token is fed into new multi-class linear classiﬁer.',\n",
              "   'This approach is related to the CLS token in BERT; however we add the additional token to the end so that representation for the token in the decoder can attend to decoder states from the complete input (Figure 3a).'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_11',\n",
              "  'block_idx': 46,\n",
              "  'level': 3,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['3.2 Token Classiﬁcation Tasks'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 47,\n",
              "  'level': 5,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['For token classiﬁcation tasks, such as answer endpoint classiﬁcation for SQuAD, we feed the complete document into the encoder and decoder, and use the top hidden state of the decoder as a representation for each word.',\n",
              "   'This representation is used to classify the token.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_11',\n",
              "  'block_idx': 48,\n",
              "  'level': 3,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['3.3 Sequence Generation Tasks'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 49,\n",
              "  'level': 5,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['Because BART has an autoregressive decoder, it can be directly ﬁne tuned for sequence generation tasks such as abstractive question answering and summarization.',\n",
              "   'In both of these tasks, information is copied from the input but manipulated, which is closely related to the denoising pre-training objective.',\n",
              "   'Here, the encoder input is the input sequence, and the decoder generates outputs autoregressively.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_11',\n",
              "  'block_idx': 50,\n",
              "  'level': 3,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['3.4 Machine Translation'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 51,\n",
              "  'level': 5,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['We also explore using BART to improve machine translation decoders for translating into English.',\n",
              "   'Previous work Edunov et al.',\n",
              "   '(2019) has shown that models can be improved by incorporating pre-trained encoders, but gains from using pre-trained language models in decoders have been limited.',\n",
              "   'We show that it is possible to use the entire BART model (both encoder and decoder) as a single pretrained decoder for machine translation, by adding a new set of encoder parameters that are learned from bitext (see Figure 3b).'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 52,\n",
              "  'level': 5,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['More precisely, we replace BART’s encoder embedding layer with a new randomly initialized encoder.',\n",
              "   'The model is trained end-to-end, which trains the new encoder to map foreign words into an input that BART can de-noise to English.',\n",
              "   'The new encoder can use a separate vocabulary from the original BART model.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 53,\n",
              "  'level': 5,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['We train the source encoder in two steps, in both cases backpropagating the cross-entropy loss from the output of the BART model.',\n",
              "   'In the ﬁrst step, we freeze most of BART parameters and only update the randomly initialized source encoder, the BART positional embeddings, and the self-attention input projection matrix of BART’s encoder ﬁrst layer.',\n",
              "   'In the second step, we train all model parameters for a small number of iterations.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_1',\n",
              "  'block_idx': 54,\n",
              "  'level': 2,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['4 Comparing Pre-training Objectives'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 55,\n",
              "  'level': 3,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['BART supports a much wider range of noising schemes during pre-training than previous work.',\n",
              "   'We compare a range of options using base-size models (6 encoder and 6 decoder layers, with a hidden size of 768), evaluated on a representative subset of the tasks we will consider for the full large scale experiments in §5.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_11',\n",
              "  'block_idx': 56,\n",
              "  'level': 3,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['4.1 Comparison Objectives'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 57,\n",
              "  'level': 3,\n",
              "  'page_idx': 2,\n",
              "  'sentences': ['While many pre-training objectives have been proposed, fair comparisons between these have been difﬁcult to perform, at least in part due to differences in training data, training resources, architectural differences between models, and ﬁne-tuning procedures.',\n",
              "   'We'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_17',\n",
              "  'block_idx': 58,\n",
              "  'level': 4,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['A', 'B', 'C', 'D E'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_8',\n",
              "  'block_idx': 59,\n",
              "  'level': 3,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['label'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_17',\n",
              "  'block_idx': 60,\n",
              "  'left': 350.41,\n",
              "  'level': 4,\n",
              "  'name': 'label',\n",
              "  'page_idx': 3,\n",
              "  'table_rows': [{'block_idx': 60,\n",
              "    'cells': [{'cell_value': 'Pre-trained Encoder'},\n",
              "     {'cell_value': 'Pre-trained Decoder'}],\n",
              "    'type': 'table_header'},\n",
              "   {'block_idx': 61,\n",
              "    'cells': [{'cell_value': 'Pre-trained Encoder'},\n",
              "     {'cell_value': 'Pre-trained Decoder'}],\n",
              "    'type': 'table_data_row'}],\n",
              "  'tag': 'table',\n",
              "  'top': 82.59},\n",
              " {'block_class': 'cls_17',\n",
              "  'block_idx': 62,\n",
              "  'left': 420.55,\n",
              "  'level': 4,\n",
              "  'name': 'label',\n",
              "  'page_idx': 3,\n",
              "  'table_rows': [{'block_idx': 62,\n",
              "    'cells': [{'cell_value': '<s> A'},\n",
              "     {'cell_value': 'B'},\n",
              "     {'cell_value': 'C'},\n",
              "     {'cell_value': 'D'}],\n",
              "    'type': 'table_header'},\n",
              "   {'block_idx': 63,\n",
              "    'cell_value': 'Randomly Initialized Encoder',\n",
              "    'col_span': 4,\n",
              "    'type': 'full_row'}],\n",
              "  'tag': 'table',\n",
              "  'top': 109.04},\n",
              " {'block_class': 'cls_8',\n",
              "  'block_idx': 64,\n",
              "  'level': 3,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['A B C D E <s> A B C D E'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_18',\n",
              "  'block_idx': 65,\n",
              "  'level': 4,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['α', 'β', 'γ', 'δ ε'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_9',\n",
              "  'block_idx': 66,\n",
              "  'level': 5,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['(a) To use BART for classiﬁcation problems, the same input is fed into the encoder and decoder, and the repre- sentation from the ﬁnal output is used.',\n",
              "   '(b) For machine translation, we learn a small additional encoder that replaces the word embeddings in BART.',\n",
              "   'The new encoder can use a disjoint vocabulary.'],\n",
              "  'tag': 'list_item'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 67,\n",
              "  'level': 4,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['Figure 3: Fine tuning BART for classiﬁcation and translation.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 68,\n",
              "  'level': 4,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['re-implement strong pre-training approaches recently proposed for discriminative and generation tasks.',\n",
              "   'We aim, as much as possible, to control for differences unrelated to the pre-training objective.',\n",
              "   'However, we do make minor changes to the learning rate and usage of layer normalisation in order to improve performance (tuning these separately for each objective).',\n",
              "   'For reference, we compare our implementations with published numbers from BERT, which was also trained for 1M steps on a combination of books and Wikipedia data.',\n",
              "   'We compare the following approaches:'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 69,\n",
              "  'level': 4,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['Language Model Similarly to GPT (Radford et al., 2018), we train a left-to-right Transformer language model.',\n",
              "   'This model is equivalent to the BART decoder, without cross-attention.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 70,\n",
              "  'level': 4,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['Permuted Language Model Based on XLNet (Yang et al., 2019), we sample 1/6 of the tokens, and generate them in a random order autoregressively.',\n",
              "   'For consistency with other models, we do not implement the relative positional embeddings or attention across segments from XLNet.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 71,\n",
              "  'level': 4,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['Masked Language Model Following BERT (Devlin et al., 2019), we replace 15% of tokens with [MASK] symbols, and train the model to independently predict the original tokens.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 72,\n",
              "  'level': 4,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['Multitask Masked Language Model As in UniLM (Dong et al., 2019), we train a Masked Language Model with additional self-attention masks.',\n",
              "   'Self attention masks are chosen randomly in with the follow proportions: 1/6 left-to-right, 1/6 right-to-left, 1/3 unmasked, and 1/3 with the ﬁrst 50% of tokens unmasked and a left-to-right mask for the remainder.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 73,\n",
              "  'level': 4,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['Masked Seq-to-Seq Inspired by MASS (Song et al., 2019), we mask a span containing 50% of tokens, and train a sequence to sequence model to predict the masked tokens.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 74,\n",
              "  'level': 4,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['For the Permuted LM, Masked LM and Multitask Masked LM, we use two-stream attention (Yang et al., 2019) to efﬁciently compute likelihoods of the output part of the sequence (using a diagonal self-attention mask on the output to predict words left-to-right).'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 75,\n",
              "  'level': 4,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['We experiment with (1) treating the task as a standard sequence-to-sequence problem, where the source input to the encoder and the target is the decoder output, or (2) adding the source as preﬁx to the target in the decoder, with a loss only on the target part of the sequence.',\n",
              "   'We ﬁnd the former works better for BART models, and the latter for other models.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 76,\n",
              "  'level': 4,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['To most directly compare our models on their ability to model their ﬁne-tuning objective (the log likelihood of the human text), we report perplexity in Table 1.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_11',\n",
              "  'block_idx': 77,\n",
              "  'level': 3,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['4.2 Tasks'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 78,\n",
              "  'level': 5,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['SQuAD (Rajpurkar et al., 2016)a an extractive question answering task on Wikipedia paragraphs.',\n",
              "   'Answers are text spans extracted from a given document context.',\n",
              "   'Similar to BERT (Devlin et al., 2019), we use concatenated question and context as input to the encoder of BART, and additionally pass them to the decoder.',\n",
              "   'The model includes classiﬁers to predict the start and end indices of each token.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 79,\n",
              "  'level': 5,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['MNLI (Williams et al., 2017), a bitext classiﬁcation task to predict whether one sentence entails another.',\n",
              "   'The ﬁne-tuned model concatenates the two sentences with appended an EOS token, and passes them to both the BART encoder and decoder.',\n",
              "   'In contrast to BERT, the representation of the EOS token is used to classify the sentences relations.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 80,\n",
              "  'level': 5,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['ELI5 (Fan et al., 2019), a long-form abstractive question answering dataset.',\n",
              "   'Models generate answers conditioned on the concatenation of a question and supporting documents.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 81,\n",
              "  'level': 5,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['XSum (Narayan et al., 2018), a news summarization dataset with highly abstractive summaries.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 82,\n",
              "  'level': 5,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['ConvAI2 (Dinan et al., 2019), a dialogue response generation task, conditioned on context and a persona.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 83,\n",
              "  'level': 5,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['CNN/DM (Hermann et al., 2015), a news summarization dataset.',\n",
              "   'Summaries here are typically closely related to source sentences.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_11',\n",
              "  'block_idx': 84,\n",
              "  'level': 3,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['4.3 Results'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 85,\n",
              "  'level': 5,\n",
              "  'page_idx': 3,\n",
              "  'sentences': ['Results are shown in Table 1.', 'Several trends are clear:'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_11',\n",
              "  'block_idx': 86,\n",
              "  'left': 85.95,\n",
              "  'level': 4,\n",
              "  'name': '4.3 Results',\n",
              "  'page_idx': 4,\n",
              "  'table_rows': [{'block_idx': 86,\n",
              "    'cells': [{'cell_value': 'Model'},\n",
              "     {'cell_value': 'SQuAD 1.1'},\n",
              "     {'cell_value': 'MNLI'},\n",
              "     {'cell_value': 'ELI5'},\n",
              "     {'cell_value': 'XSum'},\n",
              "     {'cell_value': 'ConvAI2'},\n",
              "     {'cell_value': 'CNN/DM'}],\n",
              "    'type': 'table_header'},\n",
              "   {'block_idx': 87,\n",
              "    'cell_value': 'F1 Acc PPL PPL PPL PPL',\n",
              "    'col_span': 7,\n",
              "    'type': 'full_row'},\n",
              "   {'block_idx': 88,\n",
              "    'cells': [{'cell_value': 'BERT Base (Devlin et al., 2019)'},\n",
              "     {'cell_value': '88.5'},\n",
              "     {'cell_value': '84.3'},\n",
              "     {'cell_value': '-'},\n",
              "     {'cell_value': '-'},\n",
              "     {'cell_value': '-'},\n",
              "     {'cell_value': '-'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 89,\n",
              "    'cells': [{'cell_value': 'Masked Language Model'},\n",
              "     {'cell_value': '90.0'},\n",
              "     {'cell_value': '83.5'},\n",
              "     {'cell_value': '24.77'},\n",
              "     {'cell_value': '7.87'},\n",
              "     {'cell_value': '12.59'},\n",
              "     {'cell_value': '7.06'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 90,\n",
              "    'cells': [{'cell_value': 'Masked Seq2seq'},\n",
              "     {'cell_value': '87.0'},\n",
              "     {'cell_value': '82.1'},\n",
              "     {'cell_value': '23.40'},\n",
              "     {'cell_value': '6.80'},\n",
              "     {'cell_value': '11.43'},\n",
              "     {'cell_value': '6.19'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 91,\n",
              "    'cells': [{'cell_value': 'Language Model'},\n",
              "     {'cell_value': '76.7'},\n",
              "     {'cell_value': '80.1'},\n",
              "     {'cell_value': '21.40'},\n",
              "     {'cell_value': '7.00'},\n",
              "     {'cell_value': '11.51'},\n",
              "     {'cell_value': '6.56'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 92,\n",
              "    'cells': [{'cell_value': 'Permuted Language Model'},\n",
              "     {'cell_value': '89.1'},\n",
              "     {'cell_value': '83.7'},\n",
              "     {'cell_value': '24.03'},\n",
              "     {'cell_value': '7.69'},\n",
              "     {'cell_value': '12.23'},\n",
              "     {'cell_value': '6.96'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 93,\n",
              "    'cells': [{'cell_value': 'Multitask Masked Language Model'},\n",
              "     {'cell_value': '89.2'},\n",
              "     {'cell_value': '82.4'},\n",
              "     {'cell_value': '23.73'},\n",
              "     {'cell_value': '7.50'},\n",
              "     {'cell_value': '12.39'},\n",
              "     {'cell_value': '6.74'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 94,\n",
              "    'cells': [{'cell_value': 'BART Base w/ Token Masking'},\n",
              "     {'cell_value': '90.4'},\n",
              "     {'cell_value': '84.1'},\n",
              "     {'cell_value': '25.05'},\n",
              "     {'cell_value': '7.08'},\n",
              "     {'cell_value': '11.73'},\n",
              "     {'cell_value': '6.10'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 95,\n",
              "    'cells': [{'cell_value': 'w/ Token Deletion'},\n",
              "     {'cell_value': '90.4'},\n",
              "     {'cell_value': '84.1'},\n",
              "     {'cell_value': '24.61'},\n",
              "     {'cell_value': '6.90'},\n",
              "     {'cell_value': '11.46'},\n",
              "     {'cell_value': '5.87'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 96,\n",
              "    'cells': [{'cell_value': 'w/ Text Inﬁlling'},\n",
              "     {'cell_value': '90.8'},\n",
              "     {'cell_value': '84.0'},\n",
              "     {'cell_value': '24.26'},\n",
              "     {'cell_value': '6.61'},\n",
              "     {'cell_value': '11.05'},\n",
              "     {'cell_value': '5.83'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 97,\n",
              "    'cells': [{'cell_value': 'w/ Document Rotation'},\n",
              "     {'cell_value': '77.2'},\n",
              "     {'cell_value': '75.3'},\n",
              "     {'cell_value': '53.69'},\n",
              "     {'cell_value': '17.14'},\n",
              "     {'cell_value': '19.87'},\n",
              "     {'cell_value': '10.59'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 98,\n",
              "    'cells': [{'cell_value': 'w/ Sentence Shufﬂing'},\n",
              "     {'cell_value': '85.4'},\n",
              "     {'cell_value': '81.5'},\n",
              "     {'cell_value': '41.87'},\n",
              "     {'cell_value': '10.93'},\n",
              "     {'cell_value': '16.67'},\n",
              "     {'cell_value': '7.89'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 99,\n",
              "    'cells': [{'cell_value': 'w/ Text Inﬁlling + Sentence Shufﬂing'},\n",
              "     {'cell_value': '90.8'},\n",
              "     {'cell_value': '83.8'},\n",
              "     {'cell_value': '24.17'},\n",
              "     {'cell_value': '6.62'},\n",
              "     {'cell_value': '11.12'},\n",
              "     {'cell_value': '5.41'}],\n",
              "    'type': 'table_data_row'}],\n",
              "  'tag': 'table',\n",
              "  'top': 64.8},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 100,\n",
              "  'level': 4,\n",
              "  'page_idx': 4,\n",
              "  'sentences': ['Table 1: Comparison of pre-training objectives.',\n",
              "   'All models are of comparable size and are trained for 1M steps on a combination of books and Wikipedia data.',\n",
              "   'Entries in the bottom two blocks are trained on identical data using the same code-base, and ﬁne-tuned with the same procedures.',\n",
              "   'Entries in the second block are inspired by pre-training objectives proposed in previous work, but have been simpliﬁed to focus on evaluation objectives (see §4.1).',\n",
              "   'Performance varies considerably across tasks, but the BART models with text inﬁlling demonstrate the most consistently strong performance.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 101,\n",
              "  'level': 4,\n",
              "  'page_idx': 4,\n",
              "  'sentences': ['Performance of pre-training methods varies signiﬁcantly across tasks The effectiveness of pre-training methods is highly dependent on the task.',\n",
              "   'For example, a simple language model achieves the best ELI5 performance, but the worst SQUAD results.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 102,\n",
              "  'level': 4,\n",
              "  'page_idx': 4,\n",
              "  'sentences': ['Token masking is crucial Pre-training objectives based on rotating documents or permuting sentences perform poorly in isolation.',\n",
              "   'The successful methods either use token deletion or masking, or self-attention masks.',\n",
              "   'Deletion appears to outperform masking on generation tasks.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 103,\n",
              "  'level': 4,\n",
              "  'page_idx': 4,\n",
              "  'sentences': ['Left-to-right pre-training improves generation The Masked Language Model and the Permuted Language Model perform less well than others on generation, and are the only models we consider that do not include left-to-right auto-regressive language modelling during pre-training.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 104,\n",
              "  'level': 4,\n",
              "  'page_idx': 4,\n",
              "  'sentences': ['Bidirectional encoders are crucial for SQuAD As noted in previous work (Devlin et al., 2019), just left-to-right decoder performs poorly on SQuAD, because future context is crucial in classiﬁcation decisions.',\n",
              "   'However, BART achieves similar performance with only half the number of bidirectional layers.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 105,\n",
              "  'level': 4,\n",
              "  'page_idx': 4,\n",
              "  'sentences': ['The pre-training objective is not the only important factor Our Permuted Language Model performs less well than XLNet (Yang et al., 2019).',\n",
              "   'Some of this difference is likely due to not including other architectural improvements, such as relative-position embeddings or segment-level recurrence.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 106,\n",
              "  'level': 4,\n",
              "  'page_idx': 4,\n",
              "  'sentences': ['Pure language models perform best on ELI5 The ELI5 dataset is an outlier, with much higher perplexities than other tasks, and is the only generation task where other models outperform BART.',\n",
              "   'A pure language model performs best, suggesting that BART is less effective when the output is only loosely constrained by the input.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 107,\n",
              "  'level': 4,\n",
              "  'page_idx': 4,\n",
              "  'sentences': ['BART achieves the most consistently strong performance.',\n",
              "   'With the exception of ELI5, BART models using text-inﬁlling perform well on all tasks.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_1',\n",
              "  'block_idx': 108,\n",
              "  'level': 2,\n",
              "  'page_idx': 4,\n",
              "  'sentences': ['5 Large-scale Pre-training Experiments'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 109,\n",
              "  'level': 3,\n",
              "  'page_idx': 4,\n",
              "  'sentences': ['Recent work has shown that downstream performance can dramatically improve when pre-training is scaled to large batch sizes (Yang et al., 2019; Liu et al., 2019) and corpora.',\n",
              "   'To test how well BART performs in this regime, and to create a useful model for downstream tasks, we trained BART using the same scale as the RoBERTa model.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_11',\n",
              "  'block_idx': 110,\n",
              "  'level': 3,\n",
              "  'page_idx': 4,\n",
              "  'sentences': ['5.1 Experimental Setup'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 111,\n",
              "  'level': 3,\n",
              "  'page_idx': 4,\n",
              "  'sentences': ['We pre-train a large model with 12 layers in each of the encoder and decoder, and a hidden size of 1024.',\n",
              "   'Following RoBERTa (Liu et al., 2019), we use a batch size of 8000, and train the model for 500000 steps.',\n",
              "   'Documents are tokenized with the same byte-pair encoding as GPT-2 (Radford et al., 2019).',\n",
              "   'Based on the results in Section §4, we use a combination of text inﬁlling and sentence permutation.',\n",
              "   'We mask 30% of tokens in each document, and permute all sentences.',\n",
              "   'Although sentence permutation only shows signiﬁcant additive gains'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_11',\n",
              "  'block_idx': 112,\n",
              "  'left': 130.05,\n",
              "  'level': 3,\n",
              "  'name': '5.1 Experimental Setup',\n",
              "  'page_idx': 5,\n",
              "  'table_rows': [{'block_idx': 112,\n",
              "    'cells': [{'cell_value': ''},\n",
              "     {'cell_value': 'SQuAD 1.1 EM/F1'},\n",
              "     {'cell_value': 'SQuAD 2.0 EM/F1'},\n",
              "     {'cell_value': 'MNLI m/mm'},\n",
              "     {'cell_value': 'SST Acc'},\n",
              "     {'cell_value': 'QQP Acc'},\n",
              "     {'cell_value': 'QNLI Acc'},\n",
              "     {'cell_value': 'STS-B Acc'},\n",
              "     {'cell_value': 'RTE Acc'},\n",
              "     {'cell_value': 'MRPC Acc'},\n",
              "     {'cell_value': 'CoLA Mcc'}],\n",
              "    'type': 'table_header'},\n",
              "   {'block_idx': 113,\n",
              "    'cells': [{'cell_value': 'BERT'},\n",
              "     {'cell_value': '84.1/90.9'},\n",
              "     {'cell_value': '79.0/81.8'},\n",
              "     {'cell_value': '86.6/-'},\n",
              "     {'cell_value': '93.2'},\n",
              "     {'cell_value': '91.3'},\n",
              "     {'cell_value': '92.3'},\n",
              "     {'cell_value': '90.0'},\n",
              "     {'cell_value': '70.4'},\n",
              "     {'cell_value': '88.0'},\n",
              "     {'cell_value': '60.6'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 114,\n",
              "    'cells': [{'cell_value': 'UniLM'},\n",
              "     {'cell_value': '-/-'},\n",
              "     {'cell_value': '80.5/83.4'},\n",
              "     {'cell_value': '87.0/85.9'},\n",
              "     {'cell_value': '94.5'},\n",
              "     {'cell_value': '-'},\n",
              "     {'cell_value': '92.7'},\n",
              "     {'cell_value': '-'},\n",
              "     {'cell_value': '70.9'},\n",
              "     {'cell_value': '-'},\n",
              "     {'cell_value': '61.1'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 115,\n",
              "    'cells': [{'cell_value': 'XLNet'},\n",
              "     {'cell_value': '89.0/94.5'},\n",
              "     {'cell_value': '86.1/88.8'},\n",
              "     {'cell_value': '89.8/-'},\n",
              "     {'cell_value': '95.6'},\n",
              "     {'cell_value': '91.8'},\n",
              "     {'cell_value': '93.9'},\n",
              "     {'cell_value': '91.8'},\n",
              "     {'cell_value': '83.8'},\n",
              "     {'cell_value': '89.2'},\n",
              "     {'cell_value': '63.6'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 116,\n",
              "    'cells': [{'cell_value': 'RoBERTa'},\n",
              "     {'cell_value': '88.9/94.6'},\n",
              "     {'cell_value': '86.5/89.4'},\n",
              "     {'cell_value': '90.2/90.2'},\n",
              "     {'cell_value': '96.4'},\n",
              "     {'cell_value': '92.2'},\n",
              "     {'cell_value': '94.7'},\n",
              "     {'cell_value': '92.4'},\n",
              "     {'cell_value': '86.6'},\n",
              "     {'cell_value': '90.9'},\n",
              "     {'cell_value': '68.0'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 117,\n",
              "    'cells': [{'cell_value': 'BART'},\n",
              "     {'cell_value': '88.8/94.6'},\n",
              "     {'cell_value': '86.1/89.2'},\n",
              "     {'cell_value': '89.9/90.1'},\n",
              "     {'cell_value': '96.6'},\n",
              "     {'cell_value': '92.5'},\n",
              "     {'cell_value': '94.9'},\n",
              "     {'cell_value': '91.2'},\n",
              "     {'cell_value': '87.0'},\n",
              "     {'cell_value': '90.4'},\n",
              "     {'cell_value': '62.8'}],\n",
              "    'type': 'table_data_row'}],\n",
              "  'tag': 'table',\n",
              "  'top': 64.8},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 118,\n",
              "  'level': 3,\n",
              "  'page_idx': 5,\n",
              "  'sentences': ['Table 2: Results for large models on SQuAD and GLUE tasks.',\n",
              "   'BART performs comparably to RoBERTa and XLNet, suggesting that BART’s uni-directional decoder layers do not reduce performance on discriminative tasks.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_11',\n",
              "  'block_idx': 119,\n",
              "  'left': 305.7,\n",
              "  'level': 4,\n",
              "  'name': '5.1 Experimental Setup',\n",
              "  'page_idx': 5,\n",
              "  'table_rows': [{'block_idx': 119,\n",
              "    'cells': [{'cell_value': '', 'col_span': 1},\n",
              "     {'cell_value': 'CNN/DailyMail', 'col_span': 3},\n",
              "     {'cell_value': 'XSum', 'col_span': 2}],\n",
              "    'type': 'table_header'},\n",
              "   {'block_idx': 120,\n",
              "    'cells': [{'cell_value': ''},\n",
              "     {'cell_value': 'R1'},\n",
              "     {'cell_value': 'R2'},\n",
              "     {'cell_value': 'RL'},\n",
              "     {'cell_value': 'R1'},\n",
              "     {'cell_value': 'R2'},\n",
              "     {'cell_value': 'RL'}],\n",
              "    'type': 'table_header'},\n",
              "   {'block_idx': 121,\n",
              "    'cells': [{'cell_value': 'Lead-3'},\n",
              "     {'cell_value': '40.42'},\n",
              "     {'cell_value': '17.62'},\n",
              "     {'cell_value': '36.67'},\n",
              "     {'cell_value': '16.30'},\n",
              "     {'cell_value': '1.60'},\n",
              "     {'cell_value': '11.95'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 122,\n",
              "    'cells': [{'cell_value': 'PTGEN (See et al., 2017)'},\n",
              "     {'cell_value': '36.44'},\n",
              "     {'cell_value': '15.66'},\n",
              "     {'cell_value': '33.42'},\n",
              "     {'cell_value': '29.70'},\n",
              "     {'cell_value': '9.21'},\n",
              "     {'cell_value': '23.24'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 123,\n",
              "    'cells': [{'cell_value': 'PTGEN+COV (See et al., 2017)'},\n",
              "     {'cell_value': '39.53'},\n",
              "     {'cell_value': '17.28'},\n",
              "     {'cell_value': '36.38'},\n",
              "     {'cell_value': '28.10'},\n",
              "     {'cell_value': '8.02'},\n",
              "     {'cell_value': '21.72'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 124,\n",
              "    'cells': [{'cell_value': 'UniLM'},\n",
              "     {'cell_value': '43.33'},\n",
              "     {'cell_value': '20.21'},\n",
              "     {'cell_value': '40.51'},\n",
              "     {'cell_value': '-'},\n",
              "     {'cell_value': '-'},\n",
              "     {'cell_value': '-'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 125,\n",
              "    'cells': [{'cell_value': 'BERTSUMABS (Liu & Lapata, 2019)'},\n",
              "     {'cell_value': '41.72'},\n",
              "     {'cell_value': '19.39'},\n",
              "     {'cell_value': '38.76'},\n",
              "     {'cell_value': '38.76'},\n",
              "     {'cell_value': '16.33'},\n",
              "     {'cell_value': '31.15'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 126,\n",
              "    'cells': [{'cell_value': 'BERTSUMEXTABS (Liu & Lapata, 2019)'},\n",
              "     {'cell_value': '42.13'},\n",
              "     {'cell_value': '19.60'},\n",
              "     {'cell_value': '39.18'},\n",
              "     {'cell_value': '38.81'},\n",
              "     {'cell_value': '16.50'},\n",
              "     {'cell_value': '31.27'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 127,\n",
              "    'cells': [{'cell_value': 'BART'},\n",
              "     {'cell_value': '44.16'},\n",
              "     {'cell_value': '21.28'},\n",
              "     {'cell_value': '40.90'},\n",
              "     {'cell_value': '45.14'},\n",
              "     {'cell_value': '22.27'},\n",
              "     {'cell_value': '37.25'}],\n",
              "    'type': 'table_data_row'}],\n",
              "  'tag': 'table',\n",
              "  'top': 205.41},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 128,\n",
              "  'level': 3,\n",
              "  'page_idx': 5,\n",
              "  'sentences': ['Table 3: Results on two standard summarization datasets.',\n",
              "   'BART outperforms previous work on summarization on two tasks and all metrics, with gains of roughly 6 points on the more abstractive dataset.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 129,\n",
              "  'level': 3,\n",
              "  'page_idx': 5,\n",
              "  'sentences': ['on the CNN/DM summarization dataset, we hypothesised that larger pre-trained models may be better able to learn from this task.',\n",
              "   'To help the model better ﬁt the data, we disabled dropout for the ﬁnal 10% of training steps.',\n",
              "   'We use the same pre-training data as Liu et al.',\n",
              "   '(2019), consisting of 160Gb of news, books, stories, and web text.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_11',\n",
              "  'block_idx': 130,\n",
              "  'level': 3,\n",
              "  'page_idx': 5,\n",
              "  'sentences': ['5.2 Discriminative Tasks'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 131,\n",
              "  'level': 5,\n",
              "  'page_idx': 5,\n",
              "  'sentences': ['Table 2 compares the performance of BART with several recent approaches on the well-studied SQuAD and GLUE tasks (Warstadt et al., 2018; Socher et al., 2013; Dolan & Brockett, 2005; Agirre et al., 2007; Williams et al., 2018; Dagan et al., 2006; Levesque et al., 2011).'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 132,\n",
              "  'level': 5,\n",
              "  'page_idx': 5,\n",
              "  'sentences': ['The most directly comparable baseline is RoBERTa, which was pre-trained with the same resources, but a different objective.',\n",
              "   'Overall, BART performs similarly, with only small differences between the models on most tasks.',\n",
              "   'suggesting that BART’s improvements on generation tasks do not come at the expense of classiﬁcation performance.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_11',\n",
              "  'block_idx': 133,\n",
              "  'level': 3,\n",
              "  'page_idx': 5,\n",
              "  'sentences': ['5.3 Generation Tasks'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 134,\n",
              "  'level': 5,\n",
              "  'page_idx': 5,\n",
              "  'sentences': ['We also experiment with several text generation tasks.',\n",
              "   'BART is ﬁne-tuned as a standard sequence-to-sequence model from the input to the output text.',\n",
              "   'During ﬁnetuning we use a label smoothed cross entropy loss (Pereyra et al., 2017), with the smoothing parameter set to 0.1.',\n",
              "   'During generation, we set beam size as 5, remove duplicated trigrams in beam search, and tuned the model with min-len, max-len, length penalty on the validation set (Fan et al., 2017).'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 135,\n",
              "  'left': 414.62,\n",
              "  'level': 6,\n",
              "  'name': '5.3 Generation Tasks',\n",
              "  'page_idx': 5,\n",
              "  'table_rows': [{'block_idx': 135,\n",
              "    'cells': [{'cell_value': '', 'col_span': 1},\n",
              "     {'cell_value': 'ConvAI2', 'col_span': 2},\n",
              "     {'cell_value': 'Valid F1 Valid PPL', 'col_span': 0}],\n",
              "    'type': 'table_header'},\n",
              "   {'block_idx': 136,\n",
              "    'cells': [{'cell_value': 'Seq2Seq + Attention'},\n",
              "     {'cell_value': '16.02'},\n",
              "     {'cell_value': '35.07'}],\n",
              "    'type': 'table_header'},\n",
              "   {'block_idx': 137,\n",
              "    'cells': [{'cell_value': 'Best System'},\n",
              "     {'cell_value': '19.09'},\n",
              "     {'cell_value': '17.51'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 138,\n",
              "    'cells': [{'cell_value': 'BART'},\n",
              "     {'cell_value': '20.72'},\n",
              "     {'cell_value': '11.85'}],\n",
              "    'type': 'table_data_row'}],\n",
              "  'tag': 'table',\n",
              "  'top': 382.91},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 139,\n",
              "  'level': 5,\n",
              "  'page_idx': 5,\n",
              "  'sentences': ['Table 4: BART outperforms previous work on conversational response generation.',\n",
              "   'Perplexities are renormalized based on ofﬁcial tokenizer for ConvAI2.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 140,\n",
              "  'level': 5,\n",
              "  'page_idx': 5,\n",
              "  'sentences': ['Summarization To provide a comparison with the state-of-the-art in summarization, we present results on two summarization datasets, CNN/DailyMail and XSum, which have distinct properties.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 141,\n",
              "  'level': 5,\n",
              "  'page_idx': 5,\n",
              "  'sentences': ['Summaries in the CNN/DailyMail tend to resemble source sentences.',\n",
              "   'Extractive models do well here, and even the baseline of the ﬁrst-three source sentences is highly competitive.',\n",
              "   'Nevertheless, BART outperforms all existing work.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 142,\n",
              "  'level': 5,\n",
              "  'page_idx': 5,\n",
              "  'sentences': ['In contrast, XSum is highly abstractive, and extractive models perform poorly.',\n",
              "   'BART outperforms the best previous work, which leverages BERT, by roughly 6.0 points on all ROUGE metrics—representing a signiﬁcant advance in performance on this problem.',\n",
              "   'Qualitatively, sample quality is high (see §6).'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 143,\n",
              "  'level': 5,\n",
              "  'page_idx': 5,\n",
              "  'sentences': ['Dialogue We evaluate dialogue response generation on CONVAI2 (Dinan et al., 2019), in which agents must generate responses conditioned on both the previous context and a textually-speciﬁed persona.',\n",
              "   'BART outperforms previous work on two automated metrics.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 144,\n",
              "  'level': 3,\n",
              "  'page_idx': 6,\n",
              "  'sentences': ['R2 RL'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 145,\n",
              "  'left': 98.03,\n",
              "  'level': 4,\n",
              "  'name': 'R2 RL',\n",
              "  'page_idx': 6,\n",
              "  'table_rows': [{'block_idx': 145,\n",
              "    'cells': [{'cell_value': 'Best Extractive'},\n",
              "     {'cell_value': '23.5'},\n",
              "     {'cell_value': '3.1'},\n",
              "     {'cell_value': '17.5'}],\n",
              "    'type': 'table_header'},\n",
              "   {'block_idx': 146,\n",
              "    'cells': [{'cell_value': 'Language Model Seq2Seq'},\n",
              "     {'cell_value': '27.8 28.3'},\n",
              "     {'cell_value': '4.7 5.1'},\n",
              "     {'cell_value': '23.1 22.8'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 147,\n",
              "    'cells': [{'cell_value': 'Seq2Seq Multitask BART'},\n",
              "     {'cell_value': '28.9 30.6'},\n",
              "     {'cell_value': '5.4 6.2'},\n",
              "     {'cell_value': '23.1 24.3'}],\n",
              "    'type': 'table_data_row'}],\n",
              "  'tag': 'table',\n",
              "  'top': 93.71},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 148,\n",
              "  'level': 4,\n",
              "  'page_idx': 6,\n",
              "  'sentences': ['Table 5: BART achieves state-of-the-art results on the challenging ELI5 abstractive question answering dataset.',\n",
              "   'Comparison models are from Fan et al.',\n",
              "   '(2019).'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 149,\n",
              "  'level': 4,\n",
              "  'page_idx': 6,\n",
              "  'sentences': ['RO-EN'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 150,\n",
              "  'left': 133.58,\n",
              "  'level': 5,\n",
              "  'name': 'RO-EN',\n",
              "  'page_idx': 6,\n",
              "  'tag': 'table',\n",
              "  'top': 234.47},\n",
              " {'block_class': 'cls_1',\n",
              "  'block_idx': 161,\n",
              "  'left': 307.28,\n",
              "  'level': 0,\n",
              "  'name': 'RO-EN',\n",
              "  'page_idx': 6,\n",
              "  'table_rows': [{'block_idx': 150,\n",
              "    'cells': [{'cell_value': 'Baseline'}, {'cell_value': '36.80'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 151,\n",
              "    'cells': [{'cell_value': 'Fixed BART 36.29 Tuned BART 37.96'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 152,\n",
              "    'cells': [{'cell_value': 'Table 6: The performance (BLEU) of baseline and BART on WMT’16 RO-EN augmented with backtranslation data. BART improves over a strong backtranslation (BT) baseline by using monolingual English pre-training.'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 153,\n",
              "    'cells': [{'cell_value': 'Abstractive QA We use the recently proposed ELI5 dataset to test the model’s ability to generate long freeform answers. We ﬁnd BART outperforms the best previous work by 1.2 ROUGE-L, but the dataset remains a challenging, because answers are only weakly speciﬁed by the question.'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 154,\n",
              "    'cells': [{'cell_value': '5.4 Translation'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 155,\n",
              "    'cells': [{'cell_value': 'We also evaluated performance on WMT16 RomanianEnglish, augmented with back-translation data from Sennrich et al. (2016). We use a 6-layer transformer source encoder to map Romanian into a representation that BART is able to de-noise into English, following the approach introduced in §3.4. Experiment results are presented in Table 6. We compare our results against a baseline Transformer architecture (Vaswani et al., 2017) with Transformerlarge settings (the baseline row). We show the performance of both steps of our model in the ﬁxed BART and tuned BART rows. For each row we experiment on the original WMT16 Romanian-English augmented with back-translation data. We use a beam width of 5 and a length penalty of α = 1. Preliminary results suggested that our approach was less effective without back-translation data, and prone to overﬁtting—future work should explore additional regularization techniques.'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 156,\n",
              "    'cells': [{'cell_value': '6 Qualitative Analysis'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 157,\n",
              "    'cells': [{'cell_value': 'BART shows large improvements on summarization metrics, of up to 6 points over the prior state-of-the-art. To understand BART’s performance beyond automated metrics, we analyse its generations qualitatively.'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 158,\n",
              "    'cells': [{'cell_value': 'Table 7 shows example summaries generated by BART. Examples are taken from WikiNews articles published after the creation of the pre-training corpus, to eliminate the possibility of the events described being present in the model’s training data. Following Narayan et al. (2018), we remove the ﬁrst sentence of the article prior to summarizing it, so there is no easy extractive summary of the document.'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 159,\n",
              "    'cells': [{'cell_value': 'Unsurprisingly, model output is ﬂuent and grammatical English. However, model output is also highly abstractive, with few phrases copied from the input. The output is also generally factually accurate, and integrates supporting evidence from across the input document with background knowledge (for example, correctly completing names, or inferring that PG&E operates in California). In the ﬁrst example, inferring that ﬁsh are protecting reefs from global warming requires non-trivial inference from the text. However, the claim that the work was published in Science is not supported by the source.'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 160,\n",
              "    'cells': [{'cell_value': 'These samples demonstrate that the BART pretraining has learned a strong combination of natural language understanding and generation.'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 161,\n",
              "    'cells': [{'cell_value': '7 Related Work'}, {'cell_value': ''}],\n",
              "    'type': 'table_header'},\n",
              "   {'block_idx': 162,\n",
              "    'cell_value': 'Early methods for pretraining were based on language models. GPT (Radford et al., 2018) only models left- ward context, which is problematic for some tasks. ELMo (Peters et al., 2018) concatenates left-only and right-only representations, but does not pre-train inter- actions between these features. Radford et al. (2019) demonstrated that very large language models can act as unsupervised multitask models.',\n",
              "    'col_span': 2,\n",
              "    'type': 'full_row'},\n",
              "   {'block_idx': 163,\n",
              "    'cell_value': 'BERT (Devlin et al., 2019) introduced masked lan- guage modelling, which allows pre-training to learn in- teractions between left and right context words. Re- cent work has shown that very strong performance can be achieved by training for longer (Liu et al., 2019), by tying parameters across layers (Lan et al., 2019), and by masking spans instead of words (Joshi et al., 2019). Predictions are not made auto-regressively, re- ducing the effectiveness of BERT for generation tasks.',\n",
              "    'col_span': 2,\n",
              "    'type': 'full_row'},\n",
              "   {'block_idx': 164,\n",
              "    'cell_value': 'UniLM (Dong et al., 2019) ﬁne-tunes BERT with an ensemble of masks, some of which allow only leftward context. Like BART, this allows UniLM to be used for both generative and discriminative tasks. A difference is that UniLM predictions are conditionally indepen- dent, whereas BART’s are autoregressive. BART re- duces the mismatch between pre-training and genera- tion tasks, because the decoder is always trained on un- corrupted context.',\n",
              "    'col_span': 2,\n",
              "    'type': 'full_row'},\n",
              "   {'block_idx': 165,\n",
              "    'cell_value': 'MASS (Song et al., 2019) is perhaps the most similar model to BART. An input sequence where a contiguous span of tokens is masked is mapped to a sequence con- sisting of the missing tokens. MASS is less effective for discriminative tasks, because disjoint sets of tokens are fed into the encoder and decoder.',\n",
              "    'col_span': 2,\n",
              "    'type': 'full_row'},\n",
              "   {'block_idx': 166,\n",
              "    'cell_value': 'XL-Net (Yang et al., 2019) extends BERT by pre-',\n",
              "    'col_span': 2,\n",
              "    'type': 'full_row'},\n",
              "   {'block_idx': 167,\n",
              "    'cells': [{'cell_value': 'Source Document (abbreviated)'},\n",
              "     {'cell_value': 'BART Summary'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 168,\n",
              "    'cells': [{'cell_value': 'The researchers examined three types of coral in reefs off the coast of Fiji The researchers found when ﬁsh were plentiful, they would eat algae and seaweed off the corals, which appeared to leave them more resistant to the bacterium Vibrio coralliilyti- cus, a bacterium associated with bleaching. The researchers sug- gested the algae, like warming temperatures, might render the corals’ chemical defenses less effective, and the ﬁsh were pro- tecting the coral by removing the algae.'},\n",
              "     {'cell_value': 'Fisheries off the coast of Fiji are protect- ing coral reefs from the effects of global warming, according to a study in the jour- nal Science.'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 169,\n",
              "    'cells': [{'cell_value': 'Sacoolas, who has immunity as a diplomat’s wife, was involved in a trafﬁc collision Prime Minister Johnson was questioned about the case while speaking to the press at a hospital in Wat- ford. He said, “I hope that Anne Sacoolas will come back if we can’t resolve it then of course I will be raising it myself personally with the White House.”'},\n",
              "     {'cell_value': 'Boris Johnson has said he will raise the is- sue of US diplomat Anne Sacoolas’ diplo- matic immunity with the White House.'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 170,\n",
              "    'cells': [{'cell_value': 'According to Syrian state media, government forces began de- ploying into previously SDF controlled territory yesterday. On October 6, US President Donald Trump and Turkish Presi- dent Recep Tayyip Erdoan spoke on the phone. Then both na- tions issued statements speaking of an imminent incursion into northeast Syria . On Wednesday, Turkey began a military offensive with airstrikes followed by a ground invasion. Syrian government forces have entered territory held by the US-backed Syrian Democratic Forces (SDF) in response to Turkey’s incursion into the region.'},\n",
              "     {'cell_value': ''}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 171,\n",
              "    'cells': [{'cell_value': 'This is the ﬁrst time anyone has been recorded to run a full marathon of 42.195 kilometers (approximately 26 miles) under this pursued landmark time. It was not, however, an ofﬁcially sanctioned world record, as it was not an”open race” of the IAAF. His time was 1 hour 59 minutes 40.2 seconds. Kipchoge ran in Vienna, Austria. It was an event speciﬁcally designed to help Kipchoge break the two hour barrier.'},\n",
              "     {'cell_value': 'Kenyan runner Eliud Kipchoge has run a marathon in less than two hours.'}],\n",
              "    'type': 'table_data_row'},\n",
              "   {'block_idx': 172,\n",
              "    'cells': [{'cell_value': 'PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the risk of wildﬁres. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.'},\n",
              "     {'cell_value': 'Power has been turned off to millions of customers in California as part of a power shutoff plan.'}],\n",
              "    'type': 'table_data_row'}],\n",
              "  'tag': 'table',\n",
              "  'top': 348.11},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 173,\n",
              "  'level': 0,\n",
              "  'page_idx': 7,\n",
              "  'sentences': ['Table 7: Example summaries from the XSum-tuned BART model on WikiNews articles.',\n",
              "   'For clarity, only relevant excerpts of the source are shown.',\n",
              "   'Summaries combine information from across the article and prior knowledge.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 174,\n",
              "  'level': 0,\n",
              "  'page_idx': 7,\n",
              "  'sentences': ['dicting masked tokens auto-regressively in a permuted order.',\n",
              "   'This objective allows predictions to condition on both left and right context.',\n",
              "   'In contrast, the BART decoder works left-to-right during pre-training, matching the setting during generation.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 175,\n",
              "  'level': 0,\n",
              "  'page_idx': 7,\n",
              "  'sentences': ['Several papers have explored using pre-trained representations to improve machine translation.',\n",
              "   'The largest improvements have come from pre-training on both source and target languages (Song et al., 2019; Lample & Conneau, 2019), but this requires pretraining on all languages of interest.',\n",
              "   'Other work has shown that encoders can be improved using pre-trained representations (Edunov et al., 2019), but gains in decoders are more limited.',\n",
              "   'We show how BART can be used to improve machine translation decoders.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_1',\n",
              "  'block_idx': 176,\n",
              "  'level': 0,\n",
              "  'page_idx': 7,\n",
              "  'sentences': ['8 Conclusions'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 177,\n",
              "  'level': 1,\n",
              "  'page_idx': 7,\n",
              "  'sentences': ['introduced BART, a pre-training approach that learns to map corrupted documents to the original.',\n",
              "   'BART achieves similar performance to RoBERTa on discriminative tasks, while achieving new state-of-theart results on a number of text generation tasks.',\n",
              "   'Future work should explore new methods for corrupting documents for pre-training, perhaps tailoring them to speciﬁc end tasks.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_1',\n",
              "  'block_idx': 178,\n",
              "  'level': 0,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['References'],\n",
              "  'tag': 'header'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 179,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Eneko Agirre, Llu’is M‘arquez, and Richard Wicentowski (eds.).',\n",
              "   'Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval2007).',\n",
              "   'Association for Computational Linguistics, Prague, Czech Republic, June 2007.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 180,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Ido Dagan, Oren Glickman, and Bernardo Magnini.',\n",
              "   'The PASCAL recognising textual entailment challenge.',\n",
              "   'In Machine learning challenges.',\n",
              "   'evaluating predictive uncertainty, visual object classiﬁcation, and recognising tectual entailment, pp.',\n",
              "   '177– 190.',\n",
              "   'Springer, 2006.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 181,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.',\n",
              "   'BERT: Pre-training of deep bidirectional transformers for language understanding.',\n",
              "   'In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp.',\n",
              "   '4171– 4186, Minneapolis, Minnesota, June 2019.',\n",
              "   'Association for Computational Linguistics.',\n",
              "   'doi: 10.18653/ v1/N19-1423.',\n",
              "   'URL https://www.aclweb.',\n",
              "   'org/anthology/N19-1423.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 182,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Emily Dinan, Varvara Logacheva, Valentin Malykh, Alexander Miller, Kurt Shuster, Jack Urbanek, Douwe Kiela, Arthur Szlam, Iulian Serban, Ryan Lowe, et al.',\n",
              "   'The second conversational intelligence challenge (convai2).',\n",
              "   'arXiv preprint arXiv:1902.00098, 2019.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 183,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['William B Dolan and Chris Brockett.',\n",
              "   'Automatically constructing a corpus of sentential paraphrases.',\n",
              "   'In Proceedings of the International Workshop on Paraphrasing, 2005.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 184,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, and Hsiao-Wuen Hon.',\n",
              "   'Uniﬁed language model pretraining for natural language understanding and generation.',\n",
              "   'arXiv preprint arXiv:1905.03197, 2019.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_14',\n",
              "  'block_idx': 185,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Sergey Edunov, Alexei Baevski, and Michael Auli.',\n",
              "   'Pre-trained language model representations for language generation.',\n",
              "   'In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 2019.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 186,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Angela Fan, David Grangier, and Michael Auli.',\n",
              "   'Controllable abstractive summarization.',\n",
              "   'arXiv preprint arXiv:1711.05217, 2017.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 187,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and Michael Auli.',\n",
              "   'Eli5: Long form question answering.',\n",
              "   'arXiv preprint arXiv:1907.09190, 2019.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 188,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Dan Hendrycks and Kevin Gimpel.',\n",
              "   'Gaussian error linear units (gelus).',\n",
              "   'arXiv preprint arXiv:1606.08415, 2016.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 189,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, and Phil Blunsom.',\n",
              "   'Teaching machines to read and comprehend.',\n",
              "   'In Advances in neural information processing systems, pp.',\n",
              "   '1693–1701, 2015.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 190,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S Weld, Luke Zettlemoyer, and Omer Levy.',\n",
              "   'Spanbert: Improving pre-training by representing and predicting spans.',\n",
              "   'arXiv preprint arXiv:1907.10529, 2019.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 191,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Guillaume Lample and Alexis Conneau.',\n",
              "   'Crosslingual language model pretraining.',\n",
              "   'arXiv preprint arXiv:1901.07291, 2019.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 192,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut.',\n",
              "   'Albert: A lite bert for self-supervised learning of language representations.',\n",
              "   'arXiv preprint arXiv:1909.11942, 2019.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 193,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Hector J Levesque, Ernest Davis, and Leora Morgenstern.',\n",
              "   'The Winograd schema challenge.',\n",
              "   'In AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning, volume 46, pp.',\n",
              "   '47, 2011.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 194,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Yang Liu and Mirella Lapata.',\n",
              "   'Text summarization with pretrained encoders.',\n",
              "   'arXiv preprint arXiv:1908.08345, 2019.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 195,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.',\n",
              "   'Roberta: A robustly optimized bert pretraining approach.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_14',\n",
              "  'block_idx': 196,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['arXiv preprint arXiv:1907.11692, 2019.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 197,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.',\n",
              "   'Efﬁcient estimation of word representations in vector space.',\n",
              "   'arXiv preprint arXiv:1301.3781, 2013.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 198,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Shashi Narayan, Shay B Cohen, and Mirella Lapata.',\n",
              "   'Don’t give me the details, just the summary!',\n",
              "   'topicaware convolutional neural networks for extreme summarization.',\n",
              "   'arXiv preprint arXiv:1808.08745, 2018.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 199,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Gabriel Pereyra, George Tucker, Jan Chorowski, Łukasz Kaiser, and Geoffrey Hinton.',\n",
              "   'Regularizing neural networks by penalizing conﬁdent output distributions.',\n",
              "   'arXiv preprint arXiv:1701.06548, 2017.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 200,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer.',\n",
              "   'Deep contextualized word representations.',\n",
              "   'arXiv preprint arXiv:1802.05365, 2018.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 201,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever.',\n",
              "   'Improving language understanding by generative pre-training.',\n",
              "   'URL https://s3-us-west-2.',\n",
              "   'amazonaws.',\n",
              "   'com/openaiassets/researchcovers/languageunsupervised/language understanding paper.',\n",
              "   'pdf, 2018.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 202,\n",
              "  'level': 1,\n",
              "  'page_idx': 8,\n",
              "  'sentences': ['Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever.',\n",
              "   'Language models are unsupervised multitask learners.',\n",
              "   'OpenAI Blog, 1(8), 2019.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 203,\n",
              "  'level': 1,\n",
              "  'page_idx': 9,\n",
              "  'sentences': ['Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang.',\n",
              "   'Squad: 100,000+ questions for machine comprehension of text.',\n",
              "   'arXiv preprint arXiv:1606.05250, 2016.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 204,\n",
              "  'level': 1,\n",
              "  'page_idx': 9,\n",
              "  'sentences': ['Abigail See, Peter J Liu, and Christopher D Manning.',\n",
              "   'Get to the point: Summarization with pointer-generator networks.',\n",
              "   'arXiv preprint arXiv:1704.04368, 2017.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 205,\n",
              "  'level': 1,\n",
              "  'page_idx': 9,\n",
              "  'sentences': ['Rico Sennrich, Barry Haddow, and Alexandra Birch.',\n",
              "   'Edinburgh neural machine translation systems for WMT 16.',\n",
              "   'In Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers, 2016.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 206,\n",
              "  'level': 1,\n",
              "  'page_idx': 9,\n",
              "  'sentences': ['Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Ng, and Christopher Potts.',\n",
              "   'Recursive deep models for semantic compositionality over a sentiment treebank.',\n",
              "   'In Proceedings of EMNLP, pp.',\n",
              "   '1631–1642, 2013.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 207,\n",
              "  'level': 1,\n",
              "  'page_idx': 9,\n",
              "  'sentences': ['Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and TieYan Liu.',\n",
              "   'Mass: Masked sequence to sequence pretraining for language generation.',\n",
              "   'In International Conference on Machine Learning, 2019.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 208,\n",
              "  'level': 1,\n",
              "  'page_idx': 9,\n",
              "  'sentences': ['Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin.',\n",
              "   'Attention is all you need.',\n",
              "   'In Advances in neural information processing systems, pp.',\n",
              "   '5998–6008, 2017.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 209,\n",
              "  'level': 1,\n",
              "  'page_idx': 9,\n",
              "  'sentences': ['Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman.',\n",
              "   'Glue: A multi-task benchmark and analysis platform for natural language understanding.',\n",
              "   'arXiv preprint arXiv:1804.07461, 2018.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 210,\n",
              "  'level': 1,\n",
              "  'page_idx': 9,\n",
              "  'sentences': ['Alex Warstadt, Amanpreet Singh, and Samuel R. Bowman.',\n",
              "   'Neural network acceptability judgments.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_14',\n",
              "  'block_idx': 211,\n",
              "  'level': 1,\n",
              "  'page_idx': 9,\n",
              "  'sentences': ['arXiv preprint 1805.12471, 2018.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 212,\n",
              "  'level': 1,\n",
              "  'page_idx': 9,\n",
              "  'sentences': ['Adina Williams, Nikita Nangia, and Samuel R Bowman.',\n",
              "   'A broad-coverage challenge corpus for sentence understanding through inference.',\n",
              "   'arXiv preprint arXiv:1704.05426, 2017.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 213,\n",
              "  'level': 1,\n",
              "  'page_idx': 9,\n",
              "  'sentences': ['Adina Williams, Nikita Nangia, and Samuel R. Bowman.',\n",
              "   'A broad-coverage challenge corpus for sentence understanding through inference.',\n",
              "   'In Proceedings of NAACL-HLT, 2018.'],\n",
              "  'tag': 'para'},\n",
              " {'block_class': 'cls_7',\n",
              "  'block_idx': 214,\n",
              "  'level': 1,\n",
              "  'page_idx': 9,\n",
              "  'sentences': ['Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V Le.',\n",
              "   'Xlnet: Generalized autoregressive pretraining for language understanding.',\n",
              "   'arXiv preprint arXiv:1906.08237, 2019.'],\n",
              "  'tag': 'para'}]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment these lines if you are using Google Colab.\n",
        "# ! pip install transformers\n",
        "# ! pip install gradio\n",
        "# Import transformers pipeline\n",
        "from transformers import pipeline\n",
        "# Import Gradio\n",
        "import gradio as gr\n",
        "# Initialize the pipeline to generate questions and answers using the distilbert-base-cased-distilled-squad model.\n",
        "#question_answerer = pipeline(\"question-answering\", model='distilbert-base-cased-distilled-squad')\n",
        "# Create a function called `question_answer` that takes two parameters, the text to search and a question.\n",
        "# The function should return the question, answer, probability score, and the starting and ending index of the answer.\n",
        "def question_answer(query):\n",
        "    return query_engine.query(query)\n",
        "# Create the app with two Textbox components.\n",
        "# The first textbox will take the text to search the second will take the question.\n",
        "# The output should show the question, answer, probability score, and the starting and ending index of the answer.\n",
        "\n",
        "app = gr.Interface(\n",
        "    fn=question_answer,\n",
        "    inputs = [\n",
        "        gr.Textbox(label=\"What is your query?\")],\n",
        "    outputs=gr.Textbox(lines=10, label=\"ChatBot Answer\", show_copy_button=True))\n",
        "\n",
        "# Launch the app.\n",
        "app.launch(show_error=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
